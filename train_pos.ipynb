{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f321ee2faef6404b804df22d9de70ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b0507cf39474925be5542a79646283a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3cf7427c461d43b1a44d22f520cb9143",
              "IPY_MODEL_b70d75b771214c5196962bdc3abde254",
              "IPY_MODEL_d812f5fc34564e528c9c29f55b964819"
            ]
          }
        },
        "3b0507cf39474925be5542a79646283a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cf7427c461d43b1a44d22f520cb9143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_baa04d77b0c5411ca37c0d5aa541a1cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4353a6c30ae4f96935315e966476601"
          }
        },
        "b70d75b771214c5196962bdc3abde254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd00d17611f84362aee54fbdfecc888c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 502885341,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 502885341,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e8e1b0503af4795a64c271f8e5b70a6"
          }
        },
        "d812f5fc34564e528c9c29f55b964819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08b6ca94013b41cc9e1da78a9420a1e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 480M/480M [00:22&lt;00:00, 24.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2a18164fb744f8c9a9598b63bfcc8a8"
          }
        },
        "baa04d77b0c5411ca37c0d5aa541a1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4353a6c30ae4f96935315e966476601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd00d17611f84362aee54fbdfecc888c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e8e1b0503af4795a64c271f8e5b70a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08b6ca94013b41cc9e1da78a9420a1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2a18164fb744f8c9a9598b63bfcc8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b049657f99064e9b8d9d0df27f538713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f90351af3fa84f0ab44b7792387361eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_753cfd3762be445e8653c0aa1d5d1792",
              "IPY_MODEL_25e3887180394359a8f2a2fd10ac990a",
              "IPY_MODEL_4922ef937ef34f1f8e2da04be3d77c29"
            ]
          }
        },
        "f90351af3fa84f0ab44b7792387361eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "753cfd3762be445e8653c0aa1d5d1792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3564cabf4b66461ca8d8f559445d426a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b48c52bb8cbf4cc08364e01bb05c5efa"
          }
        },
        "25e3887180394359a8f2a2fd10ac990a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe861820e52a4538b83f9f38db4177b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7a8e0234cc8492e922b3bf9aab1f447"
          }
        },
        "4922ef937ef34f1f8e2da04be3d77c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7959dc83065d4411895d3e064236b759",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 13.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddd76ffcc4dc4dd2b1522d252a7b3a11"
          }
        },
        "3564cabf4b66461ca8d8f559445d426a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b48c52bb8cbf4cc08364e01bb05c5efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe861820e52a4538b83f9f38db4177b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7a8e0234cc8492e922b3bf9aab1f447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7959dc83065d4411895d3e064236b759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddd76ffcc4dc4dd2b1522d252a7b3a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6f7ba3f52c84d2180fd23e233023c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fde825023ee54c0d9ce43f7fcd436428",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f14d709e8a54833ac0bd48ca82b2e62",
              "IPY_MODEL_5f39632b40d949e086a24b670cb1105b",
              "IPY_MODEL_a027b06b097d4586a80c74aaf676be70"
            ]
          }
        },
        "fde825023ee54c0d9ce43f7fcd436428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f14d709e8a54833ac0bd48ca82b2e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bd4f3fe0a0044c8a0a76dd5f86912d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e82fe83c0b54b1ab68d8c918968d7da"
          }
        },
        "5f39632b40d949e086a24b670cb1105b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4ac7390bdfd45f78e3b89e2a4a633fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2aaddd6b17c4ebda55e0bc3834f18e1"
          }
        },
        "a027b06b097d4586a80c74aaf676be70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b5f201595e04682a14740d3bbec02e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.83M/4.83M [00:01&lt;00:00, 4.34MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cf7ab0c964d4ac7a728b0edf73dfb91"
          }
        },
        "9bd4f3fe0a0044c8a0a76dd5f86912d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e82fe83c0b54b1ab68d8c918968d7da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4ac7390bdfd45f78e3b89e2a4a633fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2aaddd6b17c4ebda55e0bc3834f18e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b5f201595e04682a14740d3bbec02e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cf7ab0c964d4ac7a728b0edf73dfb91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5519db681a9243b583d61e1fc1a2c255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d13a34771c6842e9ab73e3a68591e7c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f46fc9e13906498187237c890414ed1f",
              "IPY_MODEL_928d37a2380e4a71b77cd470ec30312c",
              "IPY_MODEL_103cc1365c2946a8870d85e89037fad1"
            ]
          }
        },
        "d13a34771c6842e9ab73e3a68591e7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f46fc9e13906498187237c890414ed1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_201c521be2aa452a9f1e169ef7a6b670",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6e4d88226cf4c4eb771c14793ec8741"
          }
        },
        "928d37a2380e4a71b77cd470ec30312c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d5488a78ef44266b481b9634b824048",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_935ac2b4a48148adbd7402646bf39f07"
          }
        },
        "103cc1365c2946a8870d85e89037fad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5a8ea041ad344d7a97af0487dc75485",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.68M/8.68M [00:01&lt;00:00, 8.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_875f67c3949545a68422ed576898e530"
          }
        },
        "201c521be2aa452a9f1e169ef7a6b670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6e4d88226cf4c4eb771c14793ec8741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d5488a78ef44266b481b9634b824048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "935ac2b4a48148adbd7402646bf39f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5a8ea041ad344d7a97af0487dc75485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "875f67c3949545a68422ed576898e530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "063b05161ee84d54880785e3e39d6402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad804445d69d41babaf91fc752b68f2b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1750dcfaafaa4ea78b84c79717e7001f",
              "IPY_MODEL_255870e8800649839b527c81a403226d",
              "IPY_MODEL_c095eb2d71c44987b422711f972e1f2d"
            ]
          }
        },
        "ad804445d69d41babaf91fc752b68f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1750dcfaafaa4ea78b84c79717e7001f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f29ae3f2de0e4b418758fbb213f92525",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec74d6611b9d462493bd56193860f912"
          }
        },
        "255870e8800649839b527c81a403226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bb9b738e61f043e4a0ab99b9307a7da8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47d293a256ec4005b75909db4d0d3fb9"
          }
        },
        "c095eb2d71c44987b422711f972e1f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bb74d8e43eb47378cb63124df9ac567",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04G/1.04G [00:50&lt;00:00, 32.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8f899e07e2a452388b68d73c845586d"
          }
        },
        "f29ae3f2de0e4b418758fbb213f92525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec74d6611b9d462493bd56193860f912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb9b738e61f043e4a0ab99b9307a7da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47d293a256ec4005b75909db4d0d3fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bb74d8e43eb47378cb63124df9ac567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8f899e07e2a452388b68d73c845586d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPNhvuWX9B3B"
      },
      "source": [
        "# African POS Notebook [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/masakhane-io/masakhane-pos/blob/main/train_pos.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwhZ4QI79B3H"
      },
      "source": [
        "This notebook is designed to be able to train a pre-trained model on an African NER dataset.\n",
        "\n",
        "##### Sections:\n",
        "\n",
        "There are four sections in this notebook:\n",
        "\n",
        "1. Installations: this is where we do installation for relevant dependencies\n",
        "2. Imports: here, we perform imports for all the dependencies needed\n",
        "3. Utility Classes and Functions: here, we define utility classes and functions that will help us train\n",
        "4. Training: Here, the actual training process is done\n",
        "\n",
        "### NB: Please run the entire cells in the notebooks as they are. The only section that can be modified is the training section. The parts of the code that can be modified are clearly explained in the the training section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ501XNt9B3H"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKfz7mR89B3I"
      },
      "source": [
        "### 1. Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTCoH9Gc9B3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad48ec6-ddbe-4d67-dd9a-3126ea5b966f"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval\n",
        "!pip install ptvsd\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: ptvsd in /usr/local/lib/python3.7/dist-packages (4.3.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTGGpVtw9B3I"
      },
      "source": [
        "### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ndhvHBq9B3J"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from scipy.sparse import save_npz, load_npz\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "from torch import LongTensor\n",
        "from torch import nn, optim\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AdamW,\n",
        "    BertConfig,\n",
        "    BertForTokenClassification,\n",
        "    BertTokenizer,\n",
        "    CamembertConfig,\n",
        "    CamembertForTokenClassification,\n",
        "    CamembertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertForTokenClassification,\n",
        "    DistilBertTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaForTokenClassification,\n",
        "    RobertaTokenizer,\n",
        "    XLMRobertaConfig,\n",
        "    XLMRobertaForTokenClassification,\n",
        "    XLMRobertaTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    get_constant_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "logger = logging.getLogger(\"Afri_NER_Log\")\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"bert\": (BertConfig, BertForTokenClassification, BertTokenizer),\n",
        "    \"roberta\": (RobertaConfig, RobertaForTokenClassification, RobertaTokenizer),\n",
        "    \"distilbert\": (DistilBertConfig, DistilBertForTokenClassification, DistilBertTokenizer),\n",
        "    \"camembert\": (CamembertConfig, CamembertForTokenClassification, CamembertTokenizer),\n",
        "    \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForTokenClassification, XLMRobertaTokenizer),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfJTUufG9B3K"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GEXMAae9B3K"
      },
      "source": [
        "### 3. Utility classes and functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lALg4Sgh9B3K"
      },
      "source": [
        "Here, we write utility classes and functions that we will use for training. You can just run all the cells below.\n",
        "\n",
        "**PLEASE DO NOT MAKE ANY CHANGES IN THIS SECTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X6F3x1N9B3K"
      },
      "source": [
        "We begin by writing custom datasets for our NER task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "U91WEgUJ9B3L"
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for token classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, words, labels):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            words: list. The words of the sequence.\n",
        "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.words = words\n",
        "        self.labels = labels\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFF8SN6M9B3L"
      },
      "source": [
        "Next, we define the train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp4sC5Ve9B3L"
      },
      "source": [
        "def train(args, train_dataset, model, tokenizer, labels, pad_token_label_id):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "            os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        # set global_step to gobal_step of last saved checkpoint from model path\n",
        "        try:\n",
        "            global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])\n",
        "        except ValueError:\n",
        "            global_step = 0\n",
        "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "        logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
        "            if args.model_type != \"distilbert\":\n",
        "                inputs[\"token_type_ids\"] = (\n",
        "                    batch[2] if args.model_type in [\"bert\", \"xlnet\"] else None\n",
        "                )  # XLM and RoBERTa don\"t use segment_ids\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if (\n",
        "                            args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results, _ = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=\"dev\")\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
        "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hswQj18T9B3R"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVvIrNaf9B3W"
      },
      "source": [
        "def evaluate(args, model, tokenizer, labels, pad_token_label_id, mode, prefix=\"\"):\n",
        "    eval_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=mode)\n",
        "\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "    eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "    # multi-gpu evaluate\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation %s *****\", prefix)\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    model.eval()\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
        "            if args.model_type != \"distilbert\":\n",
        "                inputs[\"token_type_ids\"] = (\n",
        "                    batch[2] if args.model_type in [\"bert\", \"xlnet\"] else None\n",
        "                )  # XLM and RoBERTa don\"t use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "            tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                tmp_eval_loss = tmp_eval_loss.mean()  # mean() to average on multi-gpu parallel evaluating\n",
        "\n",
        "            eval_loss += tmp_eval_loss.item()\n",
        "        nb_eval_steps += 1\n",
        "        if preds is None:\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "        else:\n",
        "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    preds = np.argmax(preds, axis=2)\n",
        "\n",
        "    label_map = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "    out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "    preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "\n",
        "    for i in range(out_label_ids.shape[0]):\n",
        "        for j in range(out_label_ids.shape[1]):\n",
        "            if out_label_ids[i, j] != pad_token_label_id:\n",
        "                out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
        "                preds_list[i].append(label_map[preds[i][j]])\n",
        "\n",
        "    results = {\n",
        "        \"loss\": eval_loss,\n",
        "        \"precision\": precision_score(out_label_list, preds_list),\n",
        "        \"recall\": recall_score(out_label_list, preds_list),\n",
        "        \"f1\": f1_score(out_label_list, preds_list),\n",
        "    }\n",
        "\n",
        "    logger.info(\"***** Eval results %s *****\", prefix)\n",
        "    for key in sorted(results.keys()):\n",
        "        logger.info(\"  %s = %s\", key, str(results[key]))\n",
        "\n",
        "    return results, preds_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtQTswKH9B3W"
      },
      "source": [
        "Next, we define functions that will help us load and preprocess the examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1KDlPF-9B3X"
      },
      "source": [
        "def load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode):\n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Load data features from cache or dataset file\n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cached_{}_{}_{}\".format(\n",
        "            mode, list(filter(None, args.model_name_or_path.split(\"/\"))).pop(), str(args.max_seq_length)\n",
        "        ),\n",
        "    )\n",
        "    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        examples = read_examples_from_file(args.data_dir, mode)\n",
        "        features = convert_examples_to_features(\n",
        "            examples,\n",
        "            labels,\n",
        "            args.max_seq_length,\n",
        "            tokenizer,\n",
        "            cls_token_at_end=bool(args.model_type in [\"xlnet\"]),\n",
        "            # xlnet has a cls token at the end\n",
        "            cls_token=tokenizer.cls_token,\n",
        "            cls_token_segment_id=2 if args.model_type in [\"xlnet\"] else 0,\n",
        "            sep_token=tokenizer.sep_token,\n",
        "            sep_token_extra=bool(args.model_type in [\"roberta\"]),\n",
        "            # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
        "            pad_on_left=bool(args.model_type in [\"xlnet\"]),\n",
        "            # pad on the left for xlnet\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
        "            pad_token_label_id=pad_token_label_id,\n",
        "        )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "\n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "    return dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj1gcr729B3X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgFJWzlX9B3X"
      },
      "source": [
        "def read_examples_from_file(data_dir, mode):\n",
        "    file_path = os.path.join(data_dir, \"{}.txt\".format(mode))\n",
        "    guid_index = 1\n",
        "    examples = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        words = []\n",
        "        labels = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if len(line) < 2  or line == \"\\n\":\n",
        "                print(line, words)\n",
        "                if words:\n",
        "                    examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index), words=words, labels=labels))\n",
        "                    guid_index += 1\n",
        "                    words = []\n",
        "                    labels = []\n",
        "            else:\n",
        "                splits = line.split(\" \")\n",
        "                words.append(splits[0])\n",
        "                if len(splits) > 1:\n",
        "                    labels.append(splits[-1].replace(\"\\n\", \"\"))\n",
        "                else:\n",
        "                    # Examples could have no label for mode = \"test\"\n",
        "                    labels.append(\"O\")\n",
        "        if words:\n",
        "            examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index), words=words, labels=labels))\n",
        "    return examples\n",
        "\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    label_list,\n",
        "    max_seq_length,\n",
        "    tokenizer,\n",
        "    cls_token_at_end=False,\n",
        "    cls_token=\"[CLS]\",\n",
        "    cls_token_segment_id=1,\n",
        "    sep_token=\"[SEP]\",\n",
        "    sep_token_extra=False,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    pad_token_label_id=-100,\n",
        "    sequence_a_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        #print(ex_index, len(example.words))\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d of %d\", ex_index, len(examples))\n",
        "\n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "        for word, label in zip(example.words, example.labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_tokens)\n",
        "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
        "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
        "\n",
        "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
        "        special_tokens_count = 3 if sep_token_extra else 2\n",
        "        if len(tokens) > max_seq_length - special_tokens_count:\n",
        "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
        "            label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids:   0   0   0   0  0     0   0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens += [sep_token]\n",
        "        label_ids += [pad_token_label_id]\n",
        "        if sep_token_extra:\n",
        "            # roberta uses an extra separator b/w pairs of sentences\n",
        "            tokens += [sep_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "        if cls_token_at_end:\n",
        "            tokens += [cls_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "            segment_ids += [cls_token_segment_id]\n",
        "        else:\n",
        "            tokens = [cls_token] + tokens\n",
        "            label_ids = [pad_token_label_id] + label_ids\n",
        "            segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if pad_on_left:\n",
        "            input_ids = ([pad_token] * padding_length) + input_ids\n",
        "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
        "        else:\n",
        "            input_ids += [pad_token] * padding_length\n",
        "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
        "            segment_ids += [pad_token_segment_id] * padding_length\n",
        "            label_ids += [pad_token_label_id] * padding_length\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        try:\n",
        "            assert len(label_ids) == max_seq_length\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\", example.guid)\n",
        "            logger.info(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label_ids: %s\", \" \".join([str(x) for x in label_ids]))\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids)\n",
        "        )\n",
        "    return features\n",
        "\n",
        "def get_labels(path):\n",
        "    if path:\n",
        "        with open(path, \"r\") as f:\n",
        "            labels = f.read().splitlines()\n",
        "        if \"X\" not in labels:\n",
        "            labels = [\"X\"] + labels\n",
        "        return labels\n",
        "    else:\n",
        "        return [\"X\", \"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xnJAcio9B3Y"
      },
      "source": [
        "Next, we define a function to set the seed and the function to start the actual training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O1wtQm89B3Y"
      },
      "source": [
        "def set_seed(args):\n",
        "    \"\"\"Set seed for training\"\"\"\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "278eAhtI9B3Y"
      },
      "source": [
        "def start_training(args):\n",
        "    \"\"\"\n",
        "    Start the actual training process\n",
        "    \"\"\"\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Prepare CONLL-2003 task\n",
        "    labels = get_labels(args.labels)\n",
        "    num_labels = len(labels)\n",
        "    # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
        "    pad_token_label_id = CrossEntropyLoss().ignore_index\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    args.model_type = args.model_type.lower()\n",
        "    config_class, model_class, tokenizer_class = AutoConfig, AutoModelForTokenClassification, AutoTokenizer #MODEL_CLASSES[args.model_type]\n",
        "\n",
        "    config = config_class.from_pretrained(\n",
        "    args.config_name if args.config_name else args.model_name_or_path,\n",
        "    num_labels=num_labels,\n",
        "    id2label={str(i): label for i, label in enumerate(labels)},\n",
        "    label2id={label: i for i, label in enumerate(labels)},\n",
        "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer = tokenizer_class.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
        "        #do_lower_case=args.do_lower_case,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "        use_fast=True #args.use_fast,\n",
        "    )\n",
        "    model = model_class.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=\"train\")\n",
        "        #train_dataset = load_examples(args, mode=\"train\")\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer, labels, pad_token_label_id)\n",
        "        #global_step, tr_loss = train_ner(args, train_dataset, model, tokenizer, labels, pad_token_label_id)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Fine-tuning\n",
        "    if args.do_finetune:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.input_dir, do_lower_case=args.do_lower_case)\n",
        "        model = model_class.from_pretrained(args.input_dir)\n",
        "        model.to(args.device)\n",
        "        result, predictions = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=\"test\")\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=\"train\")\n",
        "\n",
        "        # train_dataset = load_examples(args, mode=\"train\")\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer, labels, pad_token_label_id)\n",
        "        # global_step, tr_loss = train_ner(args, train_dataset, model, tokenizer, labels, pad_token_label_id)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    if (args.do_train or args.do_finetune) and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = (\n",
        "            model.module if hasattr(model, \"module\") else model\n",
        "        )  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            model = model_class.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            result, _ = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=\"dev\", prefix=global_step)\n",
        "            if global_step:\n",
        "                result = {\"{}_{}\".format(global_step, k): v for k, v in result.items()}\n",
        "            results.update(result)\n",
        "        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            for key in sorted(results.keys()):\n",
        "                writer.write(\"{} = {}\\n\".format(key, str(results[key])))\n",
        "\n",
        "    if args.do_predict and args.local_rank in [-1, 0]:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        model = model_class.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "        result, predictions = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=\"test\")\n",
        "        # Save results\n",
        "        output_test_results_file = os.path.join(args.output_dir, \"test_results.txt\")\n",
        "        with open(output_test_results_file, \"w\") as writer:\n",
        "            for key in sorted(result.keys()):\n",
        "                writer.write(\"{} = {}\\n\".format(key, str(result[key])))\n",
        "        # Save predictions\n",
        "        output_test_predictions_file = os.path.join(args.output_dir, \"test_predictions.txt\")\n",
        "        with open(output_test_predictions_file, \"w\") as writer:\n",
        "            with open(os.path.join(args.data_dir, \"test.txt\"), \"r\") as f:\n",
        "                example_id = 0\n",
        "                for line in f:\n",
        "                    if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
        "                        writer.write(line)\n",
        "                        if not predictions[example_id]:\n",
        "                            example_id += 1\n",
        "                    elif predictions[example_id]:\n",
        "                        output_line = line.split()[0] + \" \" + predictions[example_id].pop(0) + \"\\n\"\n",
        "                        writer.write(output_line)\n",
        "                    else:\n",
        "                        logger.warning(\"Maximum sequence length exceeded: No prediction for '%s'.\", line.split()[0])\n",
        "\n",
        "    logger.info(results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpzKZive9B3Y"
      },
      "source": [
        "### 4. Training\n",
        "\n",
        "Here, we perform the actual training process after defining the training arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yw55HFOKtBo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVEgByJ09B3Z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i42FdcxD9B3Z"
      },
      "source": [
        "import argparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7c2iNO99B3Z"
      },
      "source": [
        "def get_args():\n",
        "    \"\"\"\n",
        "    Get training arguments\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        help=\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_type\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        #help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--input_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=False,\n",
        "        help=\"The input model directory.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--labels\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\",\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "        \"than this will be truncated, sequences shorter will be padded.\",\n",
        "    )\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_finetune\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\"--do_predict\", action=\"store_true\", help=\"Whether to run predictions on the test set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to run evaluation during training at each logging step.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\")\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=500, help=\"Save checkpoint every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "\n",
        "    return parser.parse_known_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSe64OWw9B3Z"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apl1wLp-9B3Z"
      },
      "source": [
        "**CHANGES CAN BE MADE HERE:**\n",
        "\n",
        "Note that the argments with comments may need to be modified. The remaining arguments can be left as they are, as these are good defaults.\n",
        "\n",
        "Hence, you should start by only supplying the data directory and output directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_V3e9vCWKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41b7f5a-e57c-43ad-99ac-354cedf519cd"
      },
      "source": [
        "!git clone https://github.com/masakhane-io/masakhane-pos.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'lacuna_pos_ner' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYecWM6uCnY7"
      },
      "source": [
        "data_path = 'masakhane-pos/data/yor'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Riz_n3s9B3Z"
      },
      "source": [
        "BERT model training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmkahPVe9B3a"
      },
      "source": [
        "args, _ = get_args()\n",
        "args.data_dir = data_path  # to-change: supply data directory\n",
        "args.output_dir = \"yor_model\" # to-change: supply output directory\n",
        "args.model_type = \"xlmroberta\" #\"bert\"\n",
        "args.model_name_or_path = \"Davlan/afro-xlmr-mini\" #\"bert-base-multilingual-cased\"\n",
        "args.max_seq_length = 200\n",
        "args.num_train_epochs = 10\n",
        "args.per_gpu_train_batch_size = 32\n",
        "args.save_steps = 10000\n",
        "args.seed = 1\n",
        "args.do_train = True\n",
        "args.do_eval = True\n",
        "args.do_predict = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JcOdW109B3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f321ee2faef6404b804df22d9de70ae5",
            "3b0507cf39474925be5542a79646283a",
            "3cf7427c461d43b1a44d22f520cb9143",
            "b70d75b771214c5196962bdc3abde254",
            "d812f5fc34564e528c9c29f55b964819",
            "baa04d77b0c5411ca37c0d5aa541a1cd",
            "a4353a6c30ae4f96935315e966476601",
            "dd00d17611f84362aee54fbdfecc888c",
            "3e8e1b0503af4795a64c271f8e5b70a6",
            "08b6ca94013b41cc9e1da78a9420a1e7",
            "f2a18164fb744f8c9a9598b63bfcc8a8"
          ]
        },
        "outputId": "768bf3a1-e249-48d9-e0d6-0aba77440176"
      },
      "source": [
        "# confirm your cuda devices before setting this command\n",
        "#!export CUDA_VISIBLE_DEVICES=1,2,3\n",
        "start_training(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/castorini/afriberta_large HTTP/1.1\" 200 797\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/sentencepiece.bpe.model HTTP/1.1\" 302 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /castorini/afriberta_large/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140463746628496 on /root/.cache/huggingface/transformers/ec50ae8e9bd80267bb819ca60cc0f55ca35532b2173d7c44f029f6a155e05311.8ee7ca5a175d608644a851a0e59c41b7a56ba0ba867fbdb9dda0f17dce45fb0e.lock\n",
            "DEBUG:filelock:Lock 140463746628496 acquired on /root/.cache/huggingface/transformers/ec50ae8e9bd80267bb819ca60cc0f55ca35532b2173d7c44f029f6a155e05311.8ee7ca5a175d608644a851a0e59c41b7a56ba0ba867fbdb9dda0f17dce45fb0e.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /castorini/afriberta_large/0d0a3c04de0206b6ec857cb19f320eb1c8737c67c4b4cd5cb56fd7b64c5d277b HTTP/1.1\" 200 502885341\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f321ee2faef6404b804df22d9de70ae5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140463746628496 on /root/.cache/huggingface/transformers/ec50ae8e9bd80267bb819ca60cc0f55ca35532b2173d7c44f029f6a155e05311.8ee7ca5a175d608644a851a0e59c41b7a56ba0ba867fbdb9dda0f17dce45fb0e.lock\n",
            "DEBUG:filelock:Lock 140463746628496 released on /root/.cache/huggingface/transformers/ec50ae8e9bd80267bb819ca60cc0f55ca35532b2173d7c44f029f6a155e05311.8ee7ca5a175d608644a851a0e59c41b7a56ba0ba867fbdb9dda0f17dce45fb0e.lock\n",
            "Some weights of the model checkpoint at castorini/afriberta_large were not used when initializing XLMRobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at castorini/afriberta_large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:Afri_NER_Log:Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='lacuna_pos_ner/data/yor', device=device(type='cuda'), do_eval=True, do_finetune=False, do_lower_case=False, do_predict=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, gradient_accumulation_steps=1, input_dir=None, labels='', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=200, max_steps=-1, model_name_or_path='castorini/afriberta_large', model_type='xlmroberta', n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='yor_model_', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=32, save_steps=10000, seed=1, server_ip='', server_port='', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
            "INFO:Afri_NER_Log:Creating features from dataset file at lacuna_pos_ner/data/yor\n",
            "INFO:Afri_NER_Log:Writing example 0 of 100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: train-1\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁A bẹ ́ rẹ ́ ▁tó ▁ló kùn ▁ni wá ▁ , ▁a ▁kìí ▁ja lè ▁ , ▁a ▁kìí ▁ṣ ̣ e ▁gbọ ́ mọ - gbọ ́ mọ ▁* ▁Oní f àá jì ▁taa ▁jẹ ́ ▁ni ▁wọ ́ n ▁ṣe ▁ń ▁pè ▁wá ▁lọ ́ kọ ▁aṣẹ ́ wó ▁- ▁Ààrẹ ▁ẹgbẹ ́ ▁oní ta k sí </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 320 4409 291 1063 291 597 1380 8866 286 13107 261 262 273 6493 1660 14156 261 262 273 6493 19302 1677 330 2483 291 1842 271 3609 291 1842 3586 46369 403 9248 10317 1584 591 291 286 595 291 278 446 558 8738 1683 535 291 1188 14353 291 8768 339 10389 1330 291 7946 359 559 5854 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 -100 -100 -100 14 16 -100 11 -100 13 -100 11 4 16 -100 13 -100 11 4 16 -100 -100 8 -100 -100 -100 -100 -100 -100 13 8 -100 -100 -100 14 16 -100 16 11 -100 -100 16 4 16 11 8 -100 -100 8 -100 -100 13 8 8 -100 8 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: train-2\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ọ ̀ tún ba ▁T á í wò ▁Ọmọ ́ lé kan ▁À jà dí ▁ni ▁Ààrẹ ▁ẹgbẹ ́ ▁àwọn ▁awakọ ̀ ▁ta k sí ▁ní pín lẹ ̀ ▁Èkó ▁ , ▁wọ ́ n ▁ti ▁bá ▁ OL Ú WA T Ó Y Ì N ▁MA TH NU EL ▁sọ ̀ rọ ̀ ▁nípa ▁àwọn ▁ì lé pa ▁wọn ▁ , ▁à to hun ▁tí ▁wọn ▁ń ▁retí ▁lọ ́ dọ ▁ìjọba ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 547 294 19961 409 1234 2740 1248 5823 5087 291 2249 908 2846 6523 12421 286 10389 1330 291 444 18854 294 288 559 5854 429 27011 1048 294 15416 261 262 595 291 278 335 776 261 17865 4 3429 1305 27208 2648 19043 971 3071 12757 15047 12253 618 294 725 294 2141 444 1530 2249 1187 410 261 262 1714 582 5607 388 410 558 47676 535 291 2204 3202 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 -100 -100 12 -100 -100 -100 12 -100 -100 -100 12 -100 -100 16 8 8 -100 11 8 -100 8 -100 -100 8 -100 -100 -100 8 13 -100 11 -100 -100 4 4 12 -100 -100 -100 -100 -100 -100 -100 -100 12 -100 -100 -100 16 -100 -100 -100 2 11 8 -100 -100 6 13 -100 8 -100 -100 14 11 4 16 2 -100 -100 8 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ['Abẹ́rẹ́', 'tó', 'lókùn', 'niwá', ',', 'a', 'kìí', 'jalè', ',', 'a', 'kìí', 'ṣ̣e', 'gbọ́mọ-gbọ́mọ', '*', 'Onífàájì', 'taa', 'jẹ́', 'ni', 'wọ́n', 'ṣe', 'ń', 'pè', 'wá', 'lọ́kọ', 'aṣẹ́wó', '-', 'Ààrẹ', 'ẹgbẹ́', 'onítaksí']\n",
            " ['Ọ̀túnba', 'Táíwò', 'Ọmọ́lékan', 'Àjàdí', 'ni', 'Ààrẹ', 'ẹgbẹ́', 'àwọn', 'awakọ̀', 'taksí', 'nípínlẹ̀', 'Èkó', ',', 'wọ́n', 'ti', 'bá', 'OLÚWATÓYÌN', 'MATHNUEL', 'sọ̀rọ̀', 'nípa', 'àwọn', 'ìlépa', 'wọn', ',', 'àtohun', 'tí', 'wọn', 'ń', 'retí', 'lọ́dọ', 'ìjọba', '.']\n",
            " ['Ohun', 'tí', 'wọ́n', 'sọ', 'rèé', '.']\n",
            " ['Àṣejèrè', ':', 'Ẹ', 'káàsán', 'Alàgbà', ',', 'ǹjẹ́', 'a', 'lè', 'mọ̀', 'yín', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Bẹ́ẹ̀', 'ni', '!']\n",
            " ['Orúkọ', 'tèmi', 'ni', 'Ọ̀túnba', 'Táíwò', 'Ọmọ́lékan', 'Àjàdí', '.']\n",
            " ['Mo', 'jẹ', 'ààrẹ', 'ẹgbẹ́', 'yìí', 'lọ́gbọ̀njọ́', ',', 'oṣù', 'karùn-ún', ',', 'ọdún', 'yìí', ',', 'nígbà', 'tí', 'ààrẹ', 'àná', ';', 'Olóògbé', 'Tajudeen', 'Adétòrò', 'jáde', 'láyé', 'láì', 'parí', 'àkókò', 'wọn', 'lórí', 'oyè', 'ààrẹ', ',', 'lẹ́yìn', 'oṣù', 'mẹ́sàn-án', 'lẹgbẹ́', 'ṣe', 'ìyànsípò', 'ìdákọ́ńkọ́', 'aláìláriwo', 'nítorí', 'àrùn', 'Kòrónà', 'tó', 'gbòde', 'kan', 'yìí', '.']\n",
            " ['Àṣejèrè', ':', 'Ọdún', 'kelòó', 'rèé', 'tẹ́yin', 'tí', 'ń', 'wa', 'taksí', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Láti', 'ọdún', '1990', ',', 'ọgbọ̀n', 'ọdún', 'rèé', 'tí', 'mo', 'ti', 'jẹ́', 'dẹ́rẹ́bà', 'awakọ̀', 'taksí', 'ní', 'Adéṣínà', 'Taxi', 'Park', ',', 'ní', 'Sùúrùlérè', ',', 'ẹnu', 'ẹ̀', 'ni', 'mo', 'di', 'akọ̀wé', 'ẹgbẹ́', 'yìí', ',', 'mo', 'lo', 'ọdún', 'mẹ́jọ', 'gẹ́gẹ́', 'bí', 'akọ̀wé', 'Sùúrùlérè', 'Branch', ',', '2007', 'ni', 'mo', 'jẹ', 'akápò', 'ẹgbẹ́', 'ní', 'olú', 'iléeṣẹ́', 'ẹgbẹ́', 'wa', 'lábẹ́', 'Àlàájì', 'Tati', 'Useeni', 'kí', 'n', 'tóó', 'wá', 'di', 'akọ̀wé', 'àgbà', 'ẹgbẹ́', 'fọ́dún', 'mẹ́jọ', 'mííràn', 'lábẹ́', 'Àlàájì', 'Tajudeen', 'Adétòrò', ',', 'pẹ̀lú', 'gbogbo', 'ìrìnàjò', 'mi', 'nínú', 'iṣẹ́', 'awakọ̀', 'taksí', 'yìí', 'làwọn', 'ẹgbẹ́', 'kúkú', 'rò', 'ó', 'pé', 'òdú', 'ni', 'ohun', 'gbogbo', 'tó', 'ní', 'i', 'ṣe', 'pẹ̀lú', 'iṣ̣ẹ́', 'awakọ̀', 'taksí', 'Èkó', ';', 'kìí', 'ṣàìmò', 'fólóko', 'mi', ',', 'ni', 'wọ́n', 'bá', 'kúkú', 'pa', 'oókan', 'pọ̀', 'mọ́', 'eéjì', ',', 'ni', 'wọ́n', 'bá', 'lémi', 'nipò', 'ààrẹ', 'tọ́', 'sí', ',', 'fún', 'oríṣìí', 'ìrírí', 'mi', 'lẹ́gbẹ́', '.']\n",
            " ['Àṣejèrè', ':', 'Bí', 'mo', 'ṣe', 'ń', 'wò', 'yín', ',', 'ẹni', 'tó', 'kàwé', 'dáadáa', 'ni', 'yín', ',', 'báwo', 'ni', 'ètò', 'ẹ̀kọ́', 'kíkà', 'yín', 'ṣe', 'lọ', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Mo', 'ka', 'ilé-ẹ̀kọ́', 'alákọ̀ọ́bẹ̀rẹ̀', 'ní', 'Kàdúná', ',', 'ilé', 'ẹ̀kọ́', 'gíga', 'ní', 'Òyun', 'Baptist', 'High', 'School', 'ní', 'Ìjágbó', ',', 'Kwara', '.']\n",
            " ['Lẹ́yìn', 'iṣẹ́', 'díẹ̀', ',', 'mo', 'tẹ̀', 'síwájú', 'nínú', 'ẹ̀kọ́', 'ìmọ̀', 'nípa', 'iṣẹ́', 'ìránṣẹ́', ',', 'tí', 'wọn', 'ń', 'pè', 'ní', 'Theology', ',', 'ni', 'Holy', 'Ghost', 'Christain', 'Center', ',', 'níléèwé', 'gbogbonìṣe', 'ti', 'Kàdúná', ',', 'mo', 'kàwé', 'nípa', 'ìṣàkóso', 'níbẹ̀', 'kí', 'n', 'tóó', 'wáá', 'parí', 'HND', 'nínú', 'ètò', 'ẹ̀kọ́', 'iṣẹ́', 'ìránṣẹ́', 'ní', 'Kàdúná', 'Polytecnic', '.']\n",
            " ['Bí', 'ẹ', 'ṣe', 'ń', 'wò', 'mí', 'yìí', ',', 'ojúlówó', 'àlúfáà', 'ìránṣẹ́', 'Ọlọ́run', 'tí', 'a', 'fi', 'àmì', 'òróró', 'yàn', 'ni', 'mí', ',', 'ṣùgbọ́n', 'mo', 'kàn', 'ní', 'ìfẹ́', 'sí', 'iṣẹ́', 'awakọ̀', 'taksí', 'ni', ',', 'mo', 'sì', 'ti', 'ní', 'oore', '-', 'ọ̀fẹ́', 'láti', 'rìnrìnàjò', 'lọ', 'sílùú', 'London', ',', 'South', ',', 'Germany', ',', 'Holand', 'lọọ', 'bá', 'wọn', 'ṣiṣẹ́', 'taksí', 'lọ́hùn', 'ún', '.']\n",
            " ['Ìrírí', 'mi', 'nílùú', 'òyìnbó', 'wú', 'mi', 'lórí', 'púpọ̀', ',', 'mo', 'dẹ̀', 'pinnu', 'láti', 'yí', 'ìgbé', 'ayé', 'taksí', 'wíwà', 'padà', 'sí', 'rere', 'ní', 'àsìkò', 'tí', 'mo', 'jẹ́', 'ààrẹ', 'yìí', '.']\n",
            " ['Bó', 'tiẹ̀', 'jẹ́', 'pé', 'àrùn', 'Kòrónà', 'fẹ́ẹ́', 'dáwa', 'lọ́wọ́', 'kọ̀', 'díẹ̀', ',', 'ṣùgbọ́n', 'ìtẹ̀síwájú', 'yóò', 'bá', 'iṣẹ́', 'náà', 'láìpẹ́', '.']\n",
            " ['Àṣejèrè', ':', 'Ṣùgbọ́n', ',', 'iṣẹ́', 'ọ̀hún', 'kò', 'fi', 'bẹ́ẹ̀', 'dá', 'bíi', 'ti', 'tẹ́lẹ̀', 'mọ́', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Ọ̀rọ̀', 'lẹ', 'sọ', '!']\n",
            " ['Díẹ̀', 'lọ́wọ́', 'olórí', ',', 'púpọ̀', 'lọ́wọ́', 'àwọn', 'ọmọ', 'ẹgbẹ́', '.']\n",
            " ['Gómìnà', 'Raji', 'Fáṣọlá', 'ṣe', 'gudugudu', 'méje', 'yààyà', 'mẹfà', 'fẹ́gbẹ́', 'onítaksí', \"l'Ékòó\", '.']\n",
            " ['Fáṣọlá', 'kò', 'yá', 'wa', 'lówó', ',', 'ṣùgbọ́n', 'wọ́n', 'pọ̀n', 'wá', 'lẹ́yìn', 'pẹ̀lú', 'ọ̀já', 'tó', 'nípọn', ',', 'wọ́n', 'ṣe', 'onídùúró', 'fún', 'wa', 'láwọn', 'báǹkì', 'kan', ',', 'àìmọye', 'mílíọ̀nù', 'làwọn', 'ilé', 'ìfowópamọ́', 'yá', 'wa', ',', 'tí', 'a', 'sì', 'ti', 'san', '-', 'án', 'tán', ',', 'gbogbo', 'ohun', 'tí', 'mo', 'ń', 'sọ', 'yìí', 'ti', 'le', 'lọ́dún', 'mẹ́wàá', 'o', ',', 'ṣé', 'ẹ', 'mọ̀', 'pé', 'mọ́tò', 'náà', 'máa', 'ń', 'dàgbà', ',', 'bẹ́ẹ', 'sì', 'ni', 'kò', 'sí', 'onídùúró', 'àti', 'báǹkì', 'tó', 'fẹ́ẹ́', 'yá', 'wa', 'lówó', 'bíi', 'ti', 'ìgbà', 'yẹn', 'mọ́', ',', 'àti', 'pé', 'iṣẹ́', 'awakọ̀', 'taksí', 'nínú', 'àwọn', 'estate', 'wa', 'káàkiri', 'Èkó', 'kò', 'dà', 'bíi', 'ti', 'àtẹ̀yìnwá', '.']\n",
            " ['Ọ̀pọ̀lọpọ̀', 'onítaksí', 'ni', 'wọ́n', 'kùn', 'lọ́dà', 'mííràn', 'láti', 'leè', 'ma', 'wọnú', 'estate', 'káàkiri', ',', 'a', 'ò', 'le', 'máa', 'yáwó', 'ra', 'mọ́tò', 'ká', 'má', 'leè', 'san', 'án', 'padà', 'lásìkò', ',', 'ṣùgbọ́n', 'èyí', 'da', 'omitútù', 'sí', 'wa', 'lọ́kàn', ',', 'ló', 'fi', 'dà', 'bíi', 'pé', 'taksí', 'ti', 'ń', 'kú', \"l'Ékòó\", '.']\n",
            " ['Lára', 'ìṣòro', 'táà', 'ń', 'dojú', 'kọ', 'nìyí', ',', 'abẹ́rẹ́', 'tó', 'lókùn', 'nídìí', 'ni', 'wá', ',', 'a', 'kìí', 'ṣe', 'gbọ́mọ', '-', 'gbọ́mọ', 'bẹ́ẹ̀', 'a', 'kìí', 'fi', 'mọto', 'wa', 'jalè', '.']\n",
            " ['Gbogbo', 'àkọsílẹ̀', 'àwọn', 'ọmọ', 'ẹgbẹ́', 'wa', 'pátápátá', 'la', 'ní', '.']\n",
            " ['Ẹ', 'wo', 'káàdì', 'ni', 'mo', 'gbé', 'kọ́', 'ọrùn', 'yìí', ',', 'bí', 'gbogbo', 'ọmọ', 'ẹgbẹ́', 'dẹ̀', 'ṣe', 'ní', 'i', 'nìyí', '.']\n",
            " ['Àwọn', 'tó', 'ń', 'kun', 'taksí', 'wọn', 'lọ́dà', 'mííràn', 'ni', 'wọ́n', 'ń', 'ṣiṣẹ́', 'burúkú', '.']\n",
            " ['Ẹgbẹ́', 'wa', 'nìkan', 'nìjọba', 'fọwọ́', 'sí', ',', 'pẹ̀lú', 'kọ́lọ̀', 'ìdánimò', 'wa', ',', 'tó', 'jẹ́', 'yẹ́lò', '.']\n",
            " ['Ṣùgbọ́n', 'kí', 'ló', 'dé', 'tàwọn', 'estate', 'àti', 'pápákọ̀', 'òfúrufú', 'ń', 'gbógun', 'tì', 'wá', '?']\n",
            " ['Bẹ́ẹ̀', 'ló', 'rí', 'ní', 'Unilag', ',', 'Èkó', 'Hotels', ',', 'bẹ́ẹ̀', 'àm̀básádọ̀', 'la', 'jẹ́', 'káàkiri', 'àgbáyé', ',', 'kò', 'sí', 'ibi', 'tí', 'ẹ', 'máa', 'dé', 'lágbàáyé', ',', 'tí', 'ẹ', 'ò', 'ní', 'rí', 'taksí', '.']\n",
            " ['Lára', 'àwọn', 'ìgbésẹ̀', 'àtúnṣe', 'tí', 'mo', 'fẹ́ẹ́', 'gbé', 'nìyí', 'gẹ́gẹ́', 'bí', 'ààrẹ', ',', 'láti', 'ṣèpàdé', 'pẹ̀lú', 'àwọn', 'adarí', 'estate', 'kọ̀ọ̀kan', \"l'Ékòó\", 'àti', 'FAAN', ',', 'ìyẹn', 'àjọ', 'tó', 'ń', 'ṣàkóso', 'pápákọ̀', 'òfúrufú', ',', 'Airport', 'wa', ',', 'pàápàá', 'Ọ̀gbẹ́ni', 'Rótìmí', 'Amaechi', 'tó', 'jẹ́', 'mínísítà', '.']\n",
            " ['Taksí', 'kò', 'kú', 'rárá', 'o', ',', 'èmí', 'mọ̀', 'pé', 'láìpẹ́', ';', 'a', 'ó', 'débẹ̀', '.']\n",
            " ['Àṣejèrè', ':', 'Irú', 'àwọn', 'àtúntò', 'wo', 'lẹ', 'fẹ́ẹ́', 'mú', 'bá', 'iṣẹ́', 'taksí', ',', 'ǹjẹ́', 'ẹ', 'lèè', 'sọ', 'fún', 'wa', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Kí', 'n', 'tóó', 'dépò', 'ààrẹ', ',', 'a', 'ti', 'ṣèfilọ́lè', 'ohun', 'tí', 'a', 'pè', 'ní', '\"', 'Taxi', '.', '\"']\n",
            " ['Ibi', 'táyé', 'bá', 'yí', 'sí', ',', 'làwa', 'náà', 'gbọdọ̀', 'báwọn', 'yí', 'sí', ',', 'ìrọ̀rùn', 'làwọn', 'aráàlú', 'ń', 'fẹ́', '.']\n",
            " ['Bẹ́ẹ̀', 'làwa', 'onítaksí', 'náà', 'ti', 'ní', '\"', 'Èkó', 'Cab', '\"', 'tó', 'wà', 'lórí', 'ẹ̀rọ', 'ayélujára', ',', 'fún', 'ìgbáyé-gbádùn', 'àwọn', 'èèyàn', '.']\n",
            " ['Nígbà', 'tí', 'a', 'bá', 'kó', 'mọ́tò', 'tuntun', 'wọlé', 'pẹ̀lú', 'ẹ̀rọ', 'ọlọ́yẹ́', ',', 'bíi', 'ọgbọ̀n', 'ti', 'wà', 'nílẹ̀', 'báyìí', ',', 'ṣùgbọ́n', 'a', 'ń', 'fẹ́', 'ìrànwọ́', 'owó', 'láti', 'báǹkì', '.']\n",
            " ['Àṣejèrè', ':', 'Kí', 'ló', 'fà', 'á', 'tí', 'kò', 'fi', 'sí', 'àwọn', 'ọ̀dọ́', 'nínú', 'iṣẹ́', 'taksí', 'mọ́', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Ọmọọdún', 'márùndínlọ́gbọ̀n', '(', '25', ')', 'ni', 'mí', 'nígbà', 'tí', 'mo', 'darapọ̀', 'mọ́', 'ẹgbẹ́', 'yìí', 'gẹ́gẹ́', 'bí', 'awakọ̀', ',', 'àwọn', 'ọ̀dọ́', 'wà', 'lẹ́nu', 'iṣẹ́', 'wa', 'yìí', ',', 'wọn', 'ń', 'dàgbà', 'sẹ́nu', 'ẹ̀', 'ni', ',', 'tí', 'ẹ', 'bá', 'rántí', ',', 'nígbà', 'tí', 'Fáṣọlá', 'kó', 'àwọn', 'Mega', 'Taxi', 'wọlé', ',', 'àwọn', 'ọ̀dọ́', 'pọ̀', 'tí', 'wọn', 'ń', 'wá', 'á', ',', 'nítorí', 'ó', 'jẹ́', 'mọ́tò', 'tuntun', 'pẹ̀lú', 'ọyẹ́', '.']\n",
            " ['Ṣé', 'ẹ', 'mọ̀', 'pé', 'àwọn', 'ọ̀dọ́', 'ayé', 'ìsíǹyí', 'fẹ́ràn', 'ǹǹkan', 'tó', 'bá', 'rọrùn', ',', 'ṣùgbọ́n', 'a', 'ti', 'ń', 'gbìyànjú', 'láti', 'rí', 'i', 'pé', 'tọkùnrin', 'tobìnrin', 'àti', 'ọ̀dọ́mọdé', 'tọ́jọ́', 'orí', 'ẹ̀', 'tóó', 'wa', 'ọkọ̀', 'la', 'máá', 'ṣèpolongo', 'fún', ',', 'láti', 'wáá', 'darapọ̀', 'mọ́', 'iṣẹ́', 'yìí', ',', 'nítorí', 'iṣẹ́', 'owó', 'tó', 'níye', 'lórí', 'àti', 'wípé', 'àwọn', 'àgbàlagbà', 'tó', 'wà', 'níbẹ̀', 'máa', 'dògbó', 'lọ́jọ́', 'kan', ',', 'káwọn', 'ọ̀dọ́', 'túnbọ̀', 'leè', 'máa', 'gbé', 'taksí', 'wíwà', 'lárugẹ', '.']\n",
            " ['Àwa', 'awakọ̀', 'kìí', 'ṣiṣẹ́', 'pẹ̀lú', 'goggle', 'map', ',', 'kò', 'sọ́nà', 'tí', 'Ọlọ́run', 'kò', 'fún', 'wa', 'mọ̀', \"l'Ékòó\", ',', 'fún', 'ìdí', 'èyí', 'à', 'ti', 'ṣèpolongo', 'nínú', 'rédíò', 'rí', ',', 'ara', 'ìpolongo', 'náà', 'ni', 'mo', 'ń', 'ṣe', 'pẹ̀lú', 'ẹ̀yin', 'oníìwé', 'ìròyìn', 'yìí', ',', 'láìpẹ́', 'a', 'tún', 'gbé', 'ìgbésẹ̀', 'sí', 'i', '.']\n",
            " ['Àṣejèrè', ':', 'Ẹ', 'jẹ́', 'ká', 'yà', 'díẹ̀', ',', 'ọkọ', 'aṣẹ́wó', 'tí', 'wọn', 'máa', 'ń', 'pè', 'yín', ',', 'kí', 'ló', 'fà', 'á', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', '(', 'Ààrẹ', 'Rẹ́rìn', ')', 'Ọ̀rọ̀', 'lẹ', 'sọ', '.']\n",
            " ['Onífàájì', 'nii', 'wá', ',', 'onífàájì', 'lèmi', 'náà', '.']\n",
            " ['Tẹ́lẹ̀', ',', 'àárín', 'wákàtí', 'mẹ́ta', 'sí', 'mẹ́rin', ',', 'a', 'ti', 'pawó', 'rẹpẹtẹ', ',', 'tẹ́ẹ', 'bá', 'wá', 'rí', 'dẹ́rẹ́bà', 'pẹ̀lú', 'ṣéènì', 'lọ́rùn', 'àti', 'lọ́wọ́', ',', 'ara', 'fàájì', 'náà', 'ni', '.']\n",
            " ['Àwa', 'onítaksí', 'la', 'mọ', 'ilé', 'oúnjẹ', 'tó', 'dára', 'jù', \"l'Ékòó\", '.']\n",
            " ['Owó', 'ojúmọ́', 'tí', 'à', 'ń', 'pa', ',', 'àwọn', 'obìnrin', 'máa', 'ń', 'sá', 'tẹ̀lé', 'wa', 'ni', '.']\n",
            " ['Àwọn', 'kan', 'níyàwó', 'méjì', 'mẹ́ta', 'nínú', 'wa', ',', 'ṣùgbọ́n', 'nǹkan', 'ti', 'yí', 'padà', '.']\n",
            " ['Nítorí', 'náà', ',', 'ọkọ', 'aṣẹ́wó', 'ni', 'mí', 'o', ',', 'a', 'sì', 'ń', 'jẹ́', 'orúkọ', 'yẹn', '.']\n",
            " ['Ẹní', 'bá', 'ń', 'ṣiṣẹ́', 'déédé', ',', 'ó', 'yẹ', 'kó', 'lásìkò', 'ìgbádùn', '.']\n",
            " ['Àṣejèrè', ':', 'Ìrànwọ́', 'wo', 'lẹ', 'wá', 'ń', 'fẹ́', 'lọ́wọ́', 'ìjọba', 'báyìí', 'o', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Mo', 'gbé', 'ìgbésẹ̀', 'láti', 'rí', 'Gómìnà', 'Sanwó', 'ṣùgbọ́n', 'àrùn', 'Kòrónà', 'ló', 'ń', 'dí́', 'wa', 'lọ́wọ́', '.']\n",
            " ['Nǹkan', 'mẹ́ta', 'là', 'ń', 'fẹ́', ',', 'kí', 'wọ́n', 'máá', 'jẹ́', 'kí', 'iṣẹ́', 'taksí', 'parẹ́', 'nílùú', 'Èkó', '.']\n",
            " ['Fáṣọlá', ',', 'Adéfulírẹ', ',', 'Ọpẹ́ifá', 'àti', 'Toríọlá', ',', 'gbogbo', 'àwọn', 'èèyàn', 'wọ̀nyí', 'ni', 'wọ́n', 'sọ', 'nǹkan', 'rere', 'nípa', 'iṣẹ́', 'taksí', '.']\n",
            " ['Ẹ̀kejì', 'lọ̀rọ̀', 'àwọn', 'estate', 'yẹn', ',', 'lóòótọ́', 'ìjọba', 'Fáṣọlá', 'gbìyànjú', ',', 'ṣùgbọ́n', 'bí', 'wọ́n', 'ti', 'kúrò', 'níbẹ̀', 'làwọn', 'estate', 'yẹn', 'tún', 'gbégi', 'dínà', 'wa', '.']\n",
            " ['Kí', 'wọ́n', 'sì', 'tún', 'jọ̀ọ́', ',', 'kí', 'wọ́n', 'ran', 'àwa', 'náà', 'lọ́wọ́', 'pàápàá', 'pẹ̀lú', 'ìrànwọ́', 'tí', 'wọ́n', 'ṣe', 'lásìkò', 'ìgbélé', 'àrùn', 'Kòrónà', ',', 'nípa', 'yíyáwa', 'lówó', 'kí', 'èlé', 'orí', 'ẹ̀', 'má', 'sì', 'pọ̀', 'jù', ',', 'gẹ́gẹ́', 'bí', 'Amọ́sùn', 'àti', 'AbdulFatai', 'ṣe', 'ṣe', 'ní', 'Ògùn', 'àti', 'Kwara', '.']\n",
            " ['Àṣejèrè', ':', 'Kínni', 'ìmọ̀ràn', 'yín', 'fọ́mọ', 'ẹgbẹ́', 'lápapọ̀', '?']\n",
            " ['Ààrẹ', 'Onítaksí', ':', 'Ìgbà', 'ọ̀tun', 'ti', 'dé', ',', 'Ọ̀túnba', 'Táíwò', 'Ọmọ́lékan', 'ló', 'wà', 'lórí', 'ipò', 'ààrẹ', '.']\n",
            " ['Kò', 'síbi', 'tá', 'ò', 'leè', 'lọ', ',', 'kò', 'sẹ́ni', 'tá', 'ò', 'leè', 'bá', 'sọ̀rọ̀', '.']\n",
            " ['Ẹ', 'gba', 'káàdì', 'ìdánimọ̀', 'yín', ',', 'ẹ', 'gba', 'ìwé', 'ìdánimọ̀', 'ara', 'ọkọ̀', ',', 'ẹ', 'ṣe', 'àwọn', 'ìwé', 'mọ́tò', 'yín', 'kó', 'pé', '.']\n",
            " ['Lẹ́yìn', 'taa', 'bá', 'ṣèyí', 'tán', ',', 'ká', 'wáá', 'wo', 'ibi', 'tí', 'Ọlọ́run', 'yóò', 'gbé', 'iṣẹ́', 'taksí', 'wíwà', 'dé', \"l'Ékòó\", '.']\n",
            " ['Ẹ', 'ṣé', 'é', 'o', '!', '.']\n",
            " ['Àwa', 'là', 'ń', 'jà', 'fẹ́tọ̀ọ́', 'àwọn', 'tóhun', 'tí', 'wọ́n', 'fowó', 'rà', 'kò', 'bá', 'tẹ́', 'lọ́rùn', '-', 'Kẹ́mi', 'Olúgbòde']\n",
            " ['Ẹ', 'jẹ́', 'kí', 'á', 'mọ', 'orúkọ', 'yín', 'àti', 'ohun', 'tí', 'ẹ̀', 'ń', 'ṣe', 'níléeṣẹ́', 'yìí', '?']\n",
            " ['Orúkọ', 'mi', 'ni', 'Kẹ́mi', 'Olúgbòde', '.']\n",
            " ['Èmi', 'ni', 'adarí', 'iléeṣẹ́', 'LASCOPA', ',', 'ìyẹn', 'ní', 'Lagos', 'State', 'Consumers', '\"', 'Protection', 'Agency', ',', 'tó', 'jẹ́', 'Ilé', 'iṣẹ́', 'tìjọba', 'dálẹ̀', 'láti', 'jà', 'fún', 'ẹ̀tọ́', 'ọmọ', 'ènìyàn', 'nípa', 'ohun', 'tí', 'wọ́n', 'fowó', 'wọn', 'rà', ',', 'àbí', 'iṣẹ́', 'tí', 'wọ́n', 'sanwó', 'fún', 'tí', 'kò', 'tẹ́', 'wọn', 'lọ́rún', '.']\n",
            " ['Òfin', 'ló', 'dá', 'iléeṣẹ́', 'yìí', 'sílẹ̀', ',', 'láti', 'jà', 'fáráàlú', 'lórí', 'nǹkan', 'táa', 'ń', 'lò', 'sára', 'tàbí', 'táa', 'ń', 'jẹ', 'sẹ́nu', ',', 'àwọn', 'araàlú', 'lábẹ́', 'òfin', 'lẹ́tọ̀ọ́', 'láti', 'ní', 'ìmọ̀', 'tó', 'péye', 'nípa', 'ẹ̀tọ́', 'wọn', 'lábẹ́', 'òfin', ',', 'àti', 'pé', 'kí', 'wọn', 'lè', 'mọ̀', 'pé', 'wọ́n', 'lẹ́ẹ̀tọ́', 'fún', 'ààbò', 'kí', 'gbogbo', 'nǹkan', 'tí', 'wọ́n', 'bá', 'kówó', 'lé', ',', 'le', 'tẹ́', 'wọn', 'lọ́rùn', '.']\n",
            " ['Gbogbo', 'nǹkan', 'tó', 'jẹ́', 'kòṣeémánì', 'fáwọn', 'aráàlú', ',', 'ìbá', 'ṣe', 'omi', ',', 'aṣọ', 'táà', 'ń', 'wọ̀', 'sọ́rùn', ',', 'iná', 'mọ̀nàmọ́ná', ',', 'ilé', 'táa', 'ń', 'gbé', ',', 'àwọn', 'nǹkan', 'tó', 'jẹ́', 'pé', 'owó', 'àpò', 'wọn', 'ni', 'wọ́n', 'fi', 'ń', 'rà', 'á', ',', 'wọ́n', 'gbọ́dọ̀', 'rí', 'ìtẹ́lọ́rùn', 'nínú', 'ẹ̀', ',', 'kó', 'má', 'jẹ́', 'pé', 'wọn', 'sowó', 'nù', '.']\n",
            " ['Bí', 'a', 'bá', 'wá', 'rí', 'ẹni', 'tó', 'fọwọ́', 'ẹ̀', 'ra', 'nǹkan', 'tí', 'kò', 'tẹ́', 'ẹ', 'lọ́rùn', ',', 'irú', 'wọn', 'là', 'ń', 'jà', 'fún', '.']\n",
            " ['Láìpẹ́', 'yìí', 'lẹ', 'lọ', 'sínú', 'ọjà', 'fún', 'ètò', 'kan', ',', 'kínni', 'ìdí', 'tó', 'fi', 'jẹ́', 'pé', 'inú', 'ọjà', 'lẹ', 'lọ', '?']\n",
            " ['A', 'lọọ', 'ṣètò', 'kan', 'níbẹ̀', 'nínú', 'ọjà', 'Ojúwòyè', ',', 'ní', 'Muṣin', '.']\n",
            " ['Ṣùgbọ́n', 'a', 'ò', 'fẹ́', 'káwọn', 'èèyàn', 'ṣì', 'wá', 'mu', 'fún', 'àwọn', 'àjọ', 'ìjọba', 'yòókù', 'tó', 'ní', 'nǹkan', 'ṣe', 'pẹ̀lú', 'ọjà', '.']\n",
            " ['CBD', 'wà', 'níbẹ̀', ',', 'àjọ', 'Taskforce', 'náà', 'wà', 'níbẹ̀', ',', 'àmọ́', 'àwa', 'kìí', 'kó', 'ọjà', 'ọlọ́jà', '.']\n",
            " ['Gbogbo', 'ọjà', 'táa', 'bá', 'lọ', ',', 'la', 'máa', 'ń', 'ní', 'àjọṣepọ̀', 'pẹ̀lú', 'àwọn', 'adarí', 'ọjà', 'wọn', ';', 'ìyálọ́jà', 'àti', 'bàbálọ́jà', '.']\n",
            " ['Wọ́n', 'ṣì', 'máa', 'ń', 'ràn', 'wá', 'lọ́wọ́', ',', 'táa', 'bá', 'gbọ́', 'pé', 'ayédèrú', 'ọjà', 'kan', 'wà', 'níbì', 'kan', ',', 'tàbí', 'ọjà', 'tó', 'ti', 'pé', 'lórí', 'igbá', '.']\n",
            " ['Àwọn', 'la', 'máa', 'pè', 'tí', 'wọ́n', 'sì', 'máa', 'bá', 'wa', 'pe', 'àwọn', 'tó', 'ń', 'ta', 'ọjà', 'yẹn', '.']\n",
            " ['Ìrànlọ́́wọ́', 'ńlá', 'là', 'ń', 'rí', 'gbà', 'lọ́dọ̀', 'àwọn', 'ọlọ́jà', 'lórí', 'iṣẹ́', 'wa', '.']\n",
            " ['Ṣùgbọ́n', 'a', 'kìí', 'kó', 'ẹrù', 'ọjà', 'ọlọ́jà', '.']\n",
            " ['Ẹnìkan', 'fẹjọ́', 'sùn', 'wá', 'nípa', 'ohun', 'mímu', 'kan', 'tó', 'rà', 'lọ́jà', 'láìpẹ́', 'yìí', ',', 'a', 'sì', 'lọ', 'sọ́jà', 'yẹn', 'lọ́dọ̀', 'ẹni', 'tó', 'ń', 'tà', 'á', ',', 'àwọn', 'adarí', 'ọjà', 'náà', 'gbọ́', 'sí', 'i', ',', 'wọ́n', 'sì', 'gba', 'gbogbo', 'ọjà', 'yẹn', 'lọ́wọ́', 'àwọn', 'tó', 'ń', 'tà', 'á', 'lọ́jà', ',', 'ṣùgbọ́n', 'wọ́n', 'fún', 'bàbá', 'tó', 'ra', 'ọjà', 'yẹn', 'ní', 'owó', 'gbà', 'má', 'bínú', '.']\n",
            " ['A', 'láwọn', 'òṣìṣẹ́', 'tó', 'máa', 'ń', 'lọ', 'sí', 'àwọn', 'ọjà', 'ìgbàlódé', 'náà', ',', 'láti', 'wádìí', 'nǹkan', 'tí', 'wọn', 'ń', 'tà', '.']\n",
            " ['Ó', 'tó', 'àwọn', 'mélòó', 'tẹ́ẹ', 'ti', 'fọwọ́', 'òfin', 'mú', '?']\n",
            " ['Àwọn', 'ẹjọ́', 'kan', 'wà', 'ní', 'kóòtù', ',', 'taa', 'ń', 'bá', 'ṣẹjọ́', 'lọ́wọ́', ',', 'àwọn', 'tó', 'ti', 'san', 'owó', 'ìtanràn', 'náà', 'wà', '.']\n",
            " ['Kò', 'sí', 'ọ̀sẹ̀', 'kan', 'taa', 'kí', 'ń', 'mú', 'àwọn', 'èèyàn', 'tó', 'ń', 'ta', 'féèkì', 'tàbí', 'ọjà', 'tó', 'ti', 'pẹ́', 'lórí', 'igbá', ',', 'bó', 'tiẹ̀', 'jẹ́', 'pé', 'ó', 'ti', 'ń', 'dínkù', ',', 'a', 'dé', 'ọjà', 'kan', ',', 'ṣọ́ọ̀bù', 'kan', 'níbẹ̀', ',', 'ìdajì', 'ọjà', 'rẹ̀', 'ló', 'ti', 'bàjẹ́', 'lórí', 'igbá', '.']\n",
            " ['Báwo', 'lẹ', 'ṣe', 'ń', 'ṣe', 'é', 'tí', 'iṣẹ́', 'yín', 'pẹ̀lú', 'àwọn', 'iléeṣẹ́', 'ìjọba', 'yòókù', 'kò', 'fi', 'tako', 'ara', 'wọn', '?']\n",
            " ['Iléeṣẹ́', 'ìjọba', 'ni', 'gbogbo', 'wa', ',', 'táwọn', 'èèyàn', 'bá', 'ti', 'wáá', 'fẹjọ́', 'sùn', ',', 'a', 'kàn', 'máa', 'gbé', 'ọ̀rọ̀', 'yẹn', 'lọ', 'sí', 'ọ̀dọ̀', 'ẹni', 'tó', 'kàn', 'ni', ',', 'a', 'kìí', 'tako', 'ara', 'wa', ',', 'òṣìṣẹ́', 'ìjọba', 'náà', 'ni', 'gbogbo', 'wa', ',', 'ṣùgbọ́n', 'òfin', 'ló', 'gbé', 'iléeṣẹ́', 'yìí', 'kalẹ̀', '.']\n",
            " ['Bí', 'àwọn', 'èèyàn', 'bá', 'mú', 'ẹ̀sùn', 'wá', 'sọ́dọ̀', 'wa', ',', 'a', 'máa', 'ṣèwádìí', 'rẹ̀', 'dáadáa', ',', 'àwọn', 'lọ́ọ́yà', 'wà', 'níbí', ',', 'àwọn', 'onímọ̀', 'sáyẹ́ǹsì', 'wà', 'níbẹ̀', ',', 'iléeṣẹ́', 'SON', 'wà', 'pẹ̀lú', 'wa', ',', 'bẹ́ẹ̀', 'náà', 'ni', 'NAFDAC', 'àti', 'FIIRO', '.']\n",
            " ['Àwọn', 'tó', 'ra', 'irinṣẹ́', 'tí', 'kò', 'bá', 'dára', 'lọ́jà', ',', 'a', 'ní', 'àwọn', 'òṣìṣẹ́', 'tó', 'máa', 'ṣéwàdìí', 'bóyá', 'lóòótọ́', 'ni', 'ọjà', 'yẹn', 'kò', 'dáa', '.']\n",
            " ['Bẹ́ẹ̀', 'náà', 'la', 'ní', 'iléẹjọ́', 'mẹ́fà', 'báyìí', ',', 'ẹyọ', 'kan', 'la', 'fi', 'bẹ̀rẹ̀', 'tẹ́lẹ̀', '.']\n",
            " ['Àwọn', 'tí', 'ìjọba', 'fẹ̀tọ́', 'wọn', 'dù', 'ńkọ́', ',', 'ṣé', 'ẹ', 'máa', 'ń', 'jà', 'fáwọn', 'yẹn', 'náà', '?']\n",
            " ['Bẹ́ẹ̀', 'ni', ',', 'ìjọba', 'ta', 'ilẹ́', 'fẹ́nìkan', ',', 'wọ́n', 'tún', 'gba', 'ilẹ̀', 'yẹn', 'lọ́wọ́', 'ẹ̀', ',', 'a', 'sì', 'dá', 'sí', 'i', ',', 'wọ́n', 'fẹ́ẹ́', 'dá', 'owó', 'rẹ̀', 'padà', ',', 'ṣùgbọ́n', 'a', 'ti', 'sọ', 'fún', 'wọn', 'pé', 'bí', 'ayé', 'míì', 'n', 'bá', 'ti', 'yọ', 'kí', 'wọ́n', 'fún', 'ẹni', 'yẹn', 'nílẹ̀', 'míìn', '.']\n",
            " ['Ẹnìkan', 'náà', ';', 'àwọn', 'VIO', 'mú', 'u', ',', 'wọ́n', 'sì', 'fáìnì', 'rẹ̀', ',', 'ó', 'wáá', 'bá', 'wa', ',', 'a', 'dá', 'sọ́rọ̀', 'yẹn', ',', 'a', 'sí', 'yanjú', 'ẹ̀', ',', 'torí', 'obìnrin', 'yẹn', 'kò', 'jẹ̀bi', ',', 'àwọn', 'iléeṣẹ́', 'ìnṣọ́ráǹsì', 'tó', 'sanwó', 'fún', 'ló', 'jẹ̀bi', '.']\n",
            " ['Wọ́n', 'dá', 'owó', 'padà', 'fún', 'obìnrin', 'yẹn', 'o', '.']\n",
            " ['Pẹ̀lú', 'àwọn', 'onímọ́tò', 'ńkọ́', '.', '.', '.', '?']\n",
            " ['A', 'ti', 'pè', 'wọ́n', 'sípàdé', 'náà', ',', 'wọn', 'kò', 'wá', ',', 'ṣùgbọ́n', 'wọ́n', 'ti', 'kọ', 'lẹ́tà', 'síwa', 'pé', 'àwọn', 'máa', 'wá', '.']\n",
            " ['A', 'ṣèpàdé', 'pẹ̀lú', 'iléeṣẹ́', 'tó', 'ń', 'fi', 'bọ́ọ̀sì', 'kó', 'èrò', 'láti', 'Ìkòròdú', 'lọ', 'sí', 'Èkó', 'náà', '.']\n",
            " ['Àwọn', 'èèyàn', 'wá', 'fẹjọ́', 'wọn', 'sùn', 'wá', 'lórí', 'bí', 'wọ́n', 'ṣe', 'fowó', 'kún', 'owó', 'mọ́tò', '.']\n",
            " ['A', 'pè', 'wọ́n', ',', 'wọ́n', 'sì', 'ṣàlàyé', 'fún', 'wa', 'ìdí', 'táwọn', 'fi', 'ṣe', 'bẹ́ẹ̀', '.']\n",
            " ['Kí', 'làwọn', 'àfojúsùn', 'yín', '?']\n",
            " ['A', 'ṣì', 'ń', 'tẹ̀', 'síwájú', ',', 'àṣeyọrí', 'wa', 'pọ̀', ',', 'a', 'ti', 'lọ́fììsì', 'ní', 'Ìkòròdú', 'báyìí', ',', 'àníyàn', 'wa', 'ni', 'pé', 'ká', 'ní', 'ọ́fììsì', 'tó', 'pọ̀', 'káàkiri', 'àwọn', 'káńsù', ',', 'káwọn', 'èèyàn', 'le', 'tètè', 'rí', 'wa', '.']\n",
            " ['Ká', 'le', 'túbọ̀', 'máa', 'ṣèpolongo', 'lọ', 'sọ́dọ̀', 'àwọn', 'aráàlú', 'nípa', 'ẹ̀tọ́', 'wọn', '.']\n",
            " ['Lára', 'àṣeyọrí', 'wa', 'náà', 'ni', 'pé', 'owó', 'táa', 'ti', 'gbà', 'fún', 'àwọn', 'èèyàn', 'ti', 'lé', 'ní', 'mílíọ́nù', 'mẹ́rìnlélọ́gbọ̀n', '.']\n",
            " ['Ojoojúmọ́', 'láwọn', 'èèyàn', 'ń', 'fẹjọ́', 'sùn', 'wá', ',', 'tí', 'wọn', 'ń', 'gbé', 'ọ̀rọ̀', 'wáá', 'bá', 'wa', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: train-3\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ohun ▁tí ▁wọ ́ n ▁sọ ▁rèé ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 9917 388 595 291 278 618 5426 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 14 11 -100 -100 16 16 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: train-4\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Àṣe j èrè ▁ : ▁Ẹ ▁káà sán ▁Al àgbà ▁ , ▁ ǹ jẹ ́ ▁a ▁lè ▁mọ ̀ ▁yín ▁ ? </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 49899 1659 10681 261 274 1655 38680 18173 758 50129 261 262 261 8758 2248 291 273 1982 646 294 1945 261 317 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 -100 13 -100 11 16 -100 8 -100 13 -100 16 -100 -100 -100 11 4 16 -100 11 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: train-5\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ààrẹ ▁Oní ta k sí ▁ : ▁Bẹ ́ ẹ ̀ ▁ni ▁! </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 10389 46369 359 559 5854 261 274 18205 291 753 294 286 5773 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 8 -100 -100 -100 13 -100 8 -100 -100 -100 16 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:Saving features into cached file lacuna_pos_ner/data/yor/cached_train_afriberta_large_200\n",
            "INFO:Afri_NER_Log:***** Running training *****\n",
            "INFO:Afri_NER_Log:  Num examples = 100\n",
            "INFO:Afri_NER_Log:  Num Epochs = 10\n",
            "INFO:Afri_NER_Log:  Instantaneous batch size per GPU = 32\n",
            "INFO:Afri_NER_Log:  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "INFO:Afri_NER_Log:  Gradient Accumulation steps = 1\n",
            "INFO:Afri_NER_Log:  Total optimization steps = 40\n",
            "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.76s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.70s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.69s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]\n",
            "Epoch:  10%|█         | 1/10 [00:05<00:48,  5.44s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:04,  1.65s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.67s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.67s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
            "Epoch:  20%|██        | 2/10 [00:10<00:43,  5.39s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.67s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
            "Epoch:  30%|███       | 3/10 [00:16<00:37,  5.39s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.67s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
            "Epoch:  40%|████      | 4/10 [00:21<00:32,  5.40s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.69s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
            "Epoch:  50%|█████     | 5/10 [00:27<00:27,  5.40s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.69s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
            "Epoch:  60%|██████    | 6/10 [00:32<00:21,  5.41s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
            "Epoch:  70%|███████   | 7/10 [00:37<00:16,  5.40s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.68s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
            "Epoch:  80%|████████  | 8/10 [00:43<00:10,  5.40s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
            "Epoch:  90%|█████████ | 9/10 [00:48<00:05,  5.40s/it]\n",
            "Iteration:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
            "Iteration: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
            "Epoch: 100%|██████████| 10/10 [00:54<00:00,  5.40s/it]\n",
            "INFO:Afri_NER_Log: global_step = 40, average loss = 0.8565729834139347\n",
            "INFO:Afri_NER_Log:Saving model checkpoint to yor_model_\n",
            "INFO:Afri_NER_Log:Evaluate the following checkpoints: ['yor_model_']\n",
            "INFO:Afri_NER_Log:Creating features from dataset file at lacuna_pos_ner/data/yor\n",
            "INFO:Afri_NER_Log:Writing example 0 of 318\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: dev-1\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ní ▁ìbẹ ̀ rẹ ̀ ▁ohun ▁gbogbo ▁Ọlọ ́ run ▁dá ▁àwọn ▁ọ ̀ run ▁àti ▁ayé ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 7149 29356 294 1063 294 991 1043 5422 291 1788 2355 444 349 294 1788 1031 4884 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 2 8 -100 -100 -100 8 6 8 -100 -100 16 6 8 -100 -100 5 8 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: dev-2\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁A yé ▁sì ▁wà ▁ní ▁rú du rù du ▁ , ▁ó ▁sì ▁ ṣó fo ▁ , ▁òkùnkùn ▁sì ▁wà ▁lójú ▁i bú ▁omi ▁ , ▁Ẹ ̀ mí ▁Ọlọ ́ run ▁sì ▁ń ▁ rá b àbà ▁lójú ▁omi ▁gbogbo ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 320 15639 860 1041 429 14676 890 6241 890 261 262 484 860 261 41076 3056 261 262 26506 860 1041 7094 391 15000 3988 261 262 1655 294 3692 5422 291 1788 860 558 261 9494 740 46354 7094 3988 1043 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 5 16 2 8 -100 -100 -100 13 -100 11 5 1 -100 -100 13 -100 8 5 16 2 1 -100 8 13 -100 8 -100 -100 8 -100 -100 5 4 16 -100 -100 -100 2 8 6 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ['Ní', 'ìbẹ̀rẹ̀', 'ohun', 'gbogbo', 'Ọlọ́run', 'dá', 'àwọn', 'ọ̀run', 'àti', 'ayé', '.']\n",
            " ['Ayé', 'sì', 'wà', 'ní', 'rúdurùdu', ',', 'ó', 'sì', 'ṣófo', ',', 'òkùnkùn', 'sì', 'wà', 'lójú', 'ibú', 'omi', ',', 'Ẹ̀mí', 'Ọlọ́run', 'sì', 'ń', 'rábàbà', 'lójú', 'omi', 'gbogbo', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', ',', '“', 'Jẹ́', 'kí', 'ìmọ́lẹ̀', 'kí', 'ó', 'wà', ',', '”', 'ìmọ́lẹ̀', 'sì', 'wà', '.']\n",
            " ['Ọlọ́run', 'rí', 'i', 'pé', 'ìmọ́lẹ̀', 'náà', 'dára', ',', 'ó', 'sì', 'ya', 'ìmọ́lẹ̀', 'náà', 'sọ́tọ̀', 'kúrò', 'lára', 'òkùnkùn', '.']\n",
            " ['Ọlọ́run', 'sì', 'pe', 'ìmọ́lẹ̀', 'náà', 'ní', '“', 'Ọ̀sán', '”', 'àti', 'òkùnkùn', 'ní', '“', 'Òru', '.', '”', 'Àsálẹ́', 'àti', 'òwúrọ̀', 'sì', 'jẹ́', 'ọjọ́', 'kìn-ín-ní', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', '“', 'Jẹ́', 'kí', 'òfurufú', 'kí', 'ó', 'wà', 'ní', 'àárin', 'àwọn', 'omi', 'láti', 'pààlà', 'sí', 'àárin', 'àwọn', 'omi', '.', '”']\n",
            " ['Ọlọ́run', 'sì', 'dá', 'òfurufú', 'láti', 'ya', 'omi', 'tí', 'ó', 'wà', 'ní', 'òkè', 'òfurufú', 'kúrò', 'lára', 'omi', 'tí', 'ó', 'wà', 'ní', 'orí', 'ilẹ̀', '.', 'Ó', 'sì', 'rí', 'bẹ́ẹ̀', '.']\n",
            " ['Ọlọ́run', 'sì', 'pe', 'òfúrufú', 'ní', '“', 'Ọ̀run', ',', '”', 'àsálẹ́', 'àti', 'òwúrọ̀', 'sì', 'jẹ́', 'ọjọ́', 'kejì', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', ',', '“', 'Jẹ́', 'kí', 'omi', 'abẹ́', 'ọ̀run', 'wọ́', 'papọ̀', 'sí', 'ojúkan', ',', 'kí', 'ilẹ̀', 'gbígbẹ', 'sì', 'farahàn', '.', '”', 'Ó', 'sì', 'rí', 'bẹ́ẹ̀', '.']\n",
            " ['Ọlọ́run', 'sì', 'pe', 'ilẹ̀', 'gbígbẹ', 'náà', 'ní', '“', 'Ilẹ̀', '”', 'àti', 'àpapọ̀', 'omi', 'ní', '“', 'Òkun', ':', '”', 'Ọlórun', 'sì', 'rí', 'i', 'wí', 'pé', 'ó', 'dára', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', ',', '“', 'Jẹ́', 'kí', 'ilẹ̀', 'kí', 'ó', 'hu', 'ọ̀gbìn', ':', 'ewéko', 'tí', 'yóò', 'máa', 'mú', 'èṣo', 'wá', 'àti', 'igi', 'tí', 'yóò', 'máa', 'so', 'èṣo', 'ní', 'irú', 'tirẹ̀', ',', 'tí', 'ó', 'ní', 'irúgbìn', 'nínú', '.', '”', 'Ó', 'sì', 'rí', 'bẹ́ẹ̀', '.']\n",
            " ['Ilẹ̀', 'sì', 'hù', 'ọ̀gbìn', ':', 'ewéko', 'tí', 'ó', 'ń', 'so', 'èṣo', 'ní', 'irú', 'tirẹ̀', ',', 'àti', 'igi', 'tí', 'ń', 'so', 'èṣo', ',', 'tí', 'ó', 'ní', 'irúgbìn', 'nínú', 'ní', 'irú', 'tirẹ̀', '.', 'Ọlọ́run', 'sì', 'ri', 'pé', 'ó', 'dára', '.']\n",
            " ['Àsálẹ́', 'àti', 'òwúrọ̀', 'jẹ́', 'ọjọ́', 'kẹta', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', '“', 'Jẹ́', 'kí', 'ìmọ́lẹ̀', 'kí', 'ó', 'wà', 'ní', 'ojú', 'ọ̀run', ',', 'làti', 'pààlà', 'sí', 'àárin', 'ọ̀sán', 'àti', 'òru', ',', 'kí', 'wọn', 'ó', 'sì', 'máa', 'wà', 'fún', 'àmì', 'láti', 'mọ', 'àwọn', 'àsìkò', ',', 'àti', 'àwọn', 'ọjọ́', 'àti', 'àwọn', 'ọdún', ',']\n",
            " ['Kí', 'wọn', 'ó', 'jẹ́', 'ìmọ́lẹ̀', 'ní', 'ojú', 'ọ̀run', ',', 'láti', 'tan', 'ìmọ́lẹ̀', 'sí', 'orí', 'ilẹ̀', '.', '”', 'Ó', 'sì', 'rí', 'bẹ́ẹ̀', '.']\n",
            " ['Ọlọ́run', 'dá', 'ìmọ́lẹ̀', 'ńlá', '-', 'ńlá', 'méjì', ',', 'ìmọ́lẹ̀', 'tí', 'ó', 'tóbi', 'láti', 'ṣe', 'àkóso', 'ọ̀sán', 'àti', 'ìmọ́lẹ̀', 'tí', 'ó', 'kéré', 'láti', 'ṣe', 'àkóso', 'òru', '.', 'Ó', 'sì', 'dá', 'àwọn', 'ìràwọ̀', 'pẹ̀lú', '.']\n",
            " ['Ọlọ́run', 'sì', 'ṣe', 'wọ́n', 'lọ́jọ̀', 'sí', 'ojú', 'ọ̀run', 'láti', 'máa', 'tan', 'ìmọ́lẹ̀', 'si', 'orí', 'ilẹ̀', ',']\n",
            " ['láti', 'ṣàkóso', 'ọ̀sán', 'àti', 'òru', 'àti', 'láti', 'pààlà', 'sí', 'àárin', 'ìmọ́lẹ̀', 'àti', 'òkùnkùn', ':', 'Ọlọ́run', 'sì', 'rí', 'i', 'pé', 'ó', 'dára', '.']\n",
            " ['Àsálẹ́', 'àti', 'òwúrọ', 'jẹ́', 'ọjọ́', 'kẹrin', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', ',', '“', 'Jẹ́', 'kí', 'omi', 'kí', 'ó', 'kún', 'fún', 'àwọn', 'ohun', 'alààyè', ',', 'kí', 'àwọn', 'ẹyẹ', 'kí', 'ó', 'sì', 'máa', 'fò', 'ní', 'òfurufú', '.', '”']\n",
            " ['Nítorí', 'náà', 'Ọlọ́run', 'dá', 'àwọn', 'ẹ̀dá', 'alààyè', 'ńlá', '-', 'ńlá', 'sí', 'inú', 'òkun', ',', 'àwọn', 'ohun', 'ẹlẹ́mìí', 'àti', 'àwọn', 'ohun', 'tí', 'ń', 'rìn', 'ní', 'onírúurú', 'tiwọn', ',', 'àti', 'àwọn', 'ẹyẹ', 'abìyẹ́', 'ní', 'onírúurú', 'tiwọn', '.', 'Ọlọ́run', 'sì', 'rí', 'i', 'pé', 'ó', 'dára', '.']\n",
            " ['Ọlọ́run', 'súre', 'fún', 'wọn', ',', 'ó', 'sì', 'wí', 'pé', ',', '“', 'Ẹ', 'máa', 'bí', 'sí', 'i', ',', 'ẹ', 'sì', 'máa', 'pọ̀', 'sí', 'i', ',', 'ẹ', 'kún', 'inú', 'omi', 'òkun', ',', 'kí', 'àwọn', 'ẹyẹ', 'náà', 'sì', 'máa', 'pọ̀', 'sí', 'i', 'ní', 'orí', 'ilẹ̀', '.', '”']\n",
            " ['Àsálẹ́', 'àti', 'òwúrọ̀', 'jẹ́', 'ọjọ́', 'kárùn-ún', '.']\n",
            " ['Ọlọ́run', 'sì', 'wí', 'pé', ',', '“', 'Kí', 'ilẹ̀', 'kí', 'ó', 'mú', 'ohun', 'alààyè', 'jáde', 'ní', 'onírúurú', 'wọn', ':', 'ẹran', 'ọ̀sìn', ',', 'àwọn', 'ohun', 'afàyàfà', 'àti', 'àwọn', 'ẹran', 'inú', 'igbó', ',', 'ọ̀kọ̀ọ̀kan', 'ní', 'irú', 'tirẹ̀', '.', '”', 'Ó', 'sì', 'rí', 'bẹ́ẹ̀', '.']\n",
            " ['Ọlọ́run', 'sì', 'dá', 'ẹranko', 'inú', 'igbó', 'àti', 'ẹran', 'ọ̀sìn', 'gbogbo', 'ní', 'irú', 'tirẹ̀', 'àti', 'gbogbo', 'ohun', 'alààyè', 'tí', 'ń', 'rìn', 'ní', 'ilẹ̀', 'ní', 'irú', 'tirẹ̀', '.', 'Ọlọ́run', 'sì', 'rí', 'i', 'pé', 'ó', 'dára', '.']\n",
            " ['Lẹ́yìn', 'náà', 'ni', 'Ọlọ́run', 'wí', 'pé', ',', '“', 'Ẹ', 'jẹ́', 'kí', 'a', 'dá', 'ènìyàn', 'ní', 'àwòrán', 'ara', 'wa', ',', 'gẹ́gẹ́', 'bí', 'àwa', 'ti', 'rí', ',', 'kí', 'wọn', 'kí', 'ó', 'jọba', 'lórí', 'ẹja', 'òkun', ',', 'ẹyẹ', 'ojú', 'ọ̀run', ',', 'ohun', 'ọ̀sìn', ',', 'gbogbo', 'ilẹ̀', 'àti', 'lórí', 'ohun', 'gbogbo', 'tí', 'ń', 'rìn', 'lórí', 'ilẹ̀', '.', '”']\n",
            " ['“', 'Lóòótọ́', ',', 'lóòótọ́', 'ni', 'mo', 'wí', 'fún', 'yín', ',', 'Ẹni', 'tí', 'kò', 'bá', 'gba', 'ẹnu', 'ọ̀nà', 'wọ', 'inú', 'agbo', 'àgùntàn', ',', 'ṣùgbọ́n', 'tí', 'ó', 'bá', 'gba', 'ibòmíràn', 'gun', 'òkè', ',', 'Òun', 'náà', 'ni', 'olè', 'àti', 'ọlọ́sà', '.']\n",
            " ['Ṣùgbọ́n', 'ẹni', 'tí', 'ó', 'bá', 'ti', 'ẹnu', '-', 'ọ̀nà', 'wọlé', ',', 'Òun', 'ni', 'olùṣọ́', 'àwọn', 'àgùntàn', '.']\n",
            " ['Òun', 'ni', 'osọ́nà', 'yóò', 'ṣí', 'ìlẹ̀kùn', 'fún', ';', 'àwọn', 'àgùntàn', 'gbọ́', 'ohùn', 'rẹ̀', ':', 'ó', 'sì', 'pe', 'àwọn', 'àgùntàn', 'tirẹ̀', 'ní', 'órúkọ', ',', 'ó', 'sì', 'se', 'amọ̀nà', 'wọn', 'jáde', '.']\n",
            " ['Nígbà', 'tí', 'ó', 'bá', 'sì', 'ti', 'mú', 'àwọn', 'àgùntàn', 'tirẹ̀', 'jáde', ',', 'yóò', 'ṣíwájú', 'wọn', ',', 'àwọn', 'àgùntàn', 'yóò', 'sì', 'máa', 'tọ̀', 'ọ́', 'lẹ́yìn', ':', 'nítorí', 'tí', 'wọ́n', 'mọ', 'ohùn', 'rẹ̀', '.']\n",
            " ['Wọn', 'kò', 'jẹ́', 'tọ', 'àlejò', 'lẹ́yìn', ',', 'ṣùgbọ́n', 'wọn', 'a', 'sá', 'kúrò', 'lọ́dọ̀', 'rẹ̀', ':', 'nítorí', 'tí', 'wọn', 'kò', 'mọ', 'ohùn', 'àlejò', '.', '”']\n",
            " ['Òwe', 'yìí', 'ni', 'Jésù', 'pa', 'fún', 'wọn', ':', 'ṣùgbọ́n', 'òye', 'ohun', 'tí', 'nǹkan', 'wọ̀nyí', 'jẹ́', 'tí', 'ó', 'ń', 'sọ', 'fún', 'wọn', 'kò', 'yé', 'wọn', '.']\n",
            " ['Nítorí', 'náà', 'Jésù', 'tún', 'wí', 'fún', 'wọn', 'pé', ',', '“', 'Lóòótọ́', ',', 'lóòótọ́', 'ni', 'mo', 'wí', 'fún', 'yín', ',', 'Èmi', 'ni', 'ìlẹ̀kùn', 'àwọn', 'àgùntàn', '.']\n",
            " ['Olè', 'àti', 'ọlọ́sà', 'ni', 'gbogbo', 'àwọn', 'tí', 'ó', 'ti', 'wà', 'ṣáájú', 'mi', ':', 'ṣùgbọ́n', 'àwọn', 'àgùntàn', 'kò', 'gbọ́', 'ti', 'wọn', '.']\n",
            " ['Èmi', 'ni', 'ìlẹ̀kùn', ':', 'bí', 'ẹnìkan', 'bá', 'bá', 'ọ̀dọ̀', 'mi', 'wọlé', ',', 'Òun', 'ni', 'a', 'ó', 'gbà', 'là', ',', 'yóò', 'wọlé', ',', 'yóò', 'sì', 'jáde', ',', 'yóò', 'sì', 'rí', 'koríko', '.']\n",
            " ['Olè', 'kìí', 'wá', 'bí', 'kò', 'ṣe', 'láti', 'jalè', ',', 'láti', 'pa', ',', 'àti', 'láti', 'parun', ':', 'èmi', 'wá', 'kí', 'wọn', 'lè', 'ní', 'ìyè', ',', 'àní', 'kí', 'wọn', 'lè', 'ní', 'i', 'lọ́pọ̀lọpọ̀', '.']\n",
            " ['“', 'Èmi', 'ni', 'olùṣọ́', 'àgùntàn', 'rere', ':', 'olùṣọ́', '-', 'àgùntàn', 'rere', 'fi', 'ọkàn', 'rẹ̀', 'lélẹ̀', 'nítorí', 'àwọn', 'àgùntàn', '.']\n",
            " ['Ṣùgbọ́n', 'alágbàṣe', ',', 'tí', 'kìí', 'ṣe', 'olùṣọ́', 'àgùntàn', ',', 'ẹni', 'tí', 'àwọn', 'àgùntàn', 'kìí', 'ṣe', 'tirẹ̀', ',', 'ó', 'rí', 'ìkokò', 'ń', 'bọ̀', ',', 'ó', 'sì', 'fi', 'àgùntàn', 'sílẹ̀', ',', 'ó', 'sì', 'fọ́n', 'wọn', 'ká', 'kiri', '.']\n",
            " ['Òun', 'sá', 'lọ', 'nítorí', 'tí', 'ó', 'jẹ́', 'alágbàṣe', ',', 'kò', 'sì', 'náání', 'àwọn', 'àgùntàn', '.']\n",
            " ['Èmi', 'sì', 'ní', 'àwọn', 'àgùntàn', 'mìíràn', ',', 'tí', 'kìí', 'ṣe', 'agbo', 'yìí', ':', 'àwọn', 'ni', 'èmi', 'yóò', 'mú', 'wá', 'pẹ̀lú', ',', 'wọn', 'ó', 'sì', 'gbọ́', 'ohùn', 'mi', ';', 'wọn', 'ó', 'sì', 'jẹ́', 'agbo', 'kan', ',', 'olùsọ́', '-', 'àgùntàn', 'kan', '.']\n",
            " ['Nítorí', 'náà', 'ni', 'Baba', 'mi', 'ṣe', 'fẹ́ràn', 'mi', ',', 'nítorí', 'tí', 'mo', 'fi', 'ẹ̀mí', 'mi', 'lélẹ̀', ',', 'kí', 'èmi', 'lè', 'tún', 'gbà', 'á', '.']\n",
            " ['Ẹnìkan', 'kò', 'gbà', 'á', 'lọ́wọ́', 'mi', ',', 'ṣùgbọ́n', 'mo', 'fi', 'í', 'lélẹ̀', ',', 'mo', 'sì', 'lágbára', 'láti', 'tún', 'gbà', 'á', '.', 'Àṣẹ', 'yìí', 'ni', 'mo', 'ti', 'gbà', 'wá', 'láti', 'ọ̀dọ̀', 'Baba', 'mi', '.', '”']\n",
            " ['Nítorí', 'náà', 'ìyapa', 'tún', 'wà', 'láàrin', 'àwọn', 'Júù', 'nítorí', 'ọ̀rọ̀', 'wọ̀nyí', '.']\n",
            " ['Ọ̀pọ̀', 'nínú', 'wọn', 'sì', 'wí', 'pé', ',', '“', 'Ó', 'ní', 'ẹ̀mí', 'èṣù', ',', 'orí', 'rẹ̀', 'sì', 'dàrú', ';', 'èéṣe', 'tí', 'ẹ̀yin', 'fi', 'ń', 'gbọ́rọ̀', 'rẹ̀', '?', '”']\n",
            " ['Àwọn', 'mìíràn', 'wí', 'pé', ',', '“', 'Ìwọ̀nyí', 'kìí', 'ṣe', 'ọ̀rọ̀', 'ẹni', 'tí', 'ó', 'ní', 'ẹ̀mí', 'èṣù', '.', 'Ẹ̀mi', 'èṣù', 'lè', 'la', 'ojú', 'àwọn', 'afọ́jú', 'bí', '?', '”']\n",
            " ['Ó', 'sì', 'jẹ́', 'àjọ̀dún', 'ìyàsímímọ́', 'ní', 'Jérúsálẹ́mù', ',', 'ìgbà', 'òtútù', 'ni', '.']\n",
            " ['Jésù', 'sì', 'ń', 'rìn', 'ní', 'tẹ́mpílì', ',', 'ní', 'ìloro', 'Sólómónì', ',']\n",
            " ['Nítorí', 'náà', 'àwọn', 'Júù', 'wá', 'dúró', 'yí', 'i', 'ká', ',', 'wọ́n', 'sì', 'wí', 'fún', 'un', 'pé', ',', '“', 'Ìwọ', 'ó', 'ti', 'mú', 'wa', 'ṣe', 'iyèméjì', 'pẹ́', 'tó', '?', 'Bí', 'ìwọ', 'bá', 'ni', 'Kírísítì', 'náà', ',', 'wí', 'fún', 'wa', 'gbangba', '.', '”']\n",
            " ['Jésù', 'dá', 'wọn', 'lóhùn', 'pé', ',', '“', 'Èmi', 'ti', 'wí', 'fún', 'yín', ',', 'ẹ̀yin', 'kò', 'sì', 'gbàgbọ́', ';', 'iṣẹ́', 'tí', 'èmi', 'ń', 'ṣe', 'ní', 'orúkọ', 'Baba', 'mi', ',', 'àwọn', 'ni', 'ó', 'ń', 'jẹ́rìí', 'mi', '.']\n",
            " ['Ṣùgbọ́n', 'ẹ̀yin', 'kò', 'gbàgbọ́', ',', 'nítorí', 'ẹ̀yin', 'kò', 'sí', 'nínú', 'àwọn', 'àgùntàn', 'mi', ',', 'gẹ́gẹ́', 'bí', 'mo', 'tí', 'wí', 'fún', 'yín', '.']\n",
            " ['Baba', 'mi', ',', 'ẹni', 'tí', 'ó', 'fi', 'wọ́n', 'fún', 'mi', 'pọ̀', 'ju', 'gbogbo', 'wọn', 'lọ', ';', 'kò', 'sì', 'sí', 'ẹni', 'tí', 'ó', 'lè', 'já', 'wọn', 'gbà', 'kúrò', 'lọ́wọ́', 'Baba', 'mi', '.']\n",
            " ['Ọ̀kan', 'ni', 'èmi', 'àti', 'Baba', 'mi', '.', '”']\n",
            " ['Àwọn', 'Júù', 'sì', 'tún', 'he', 'òkúta', ',', 'láti', 'sọ', 'lù', 'ú', '.']\n",
            " ['Jésù', 'dá', 'wọn', 'lóhùn', 'pé', ',', '“', 'Ọ̀pọ̀lọpọ̀', 'iṣẹ́', 'rere', 'ni', 'mo', 'fi', 'hàn', 'yín', 'láti', 'ọ̀dọ̀', 'Baba', 'mi', 'wá', ';', 'nítorí', 'èwo', 'nínú', 'iṣẹ́', 'wọ̀nyí', 'ni', 'ẹ̀yin', 'ṣe', 'sọ', 'mí', 'ní', 'òkúta', '?', '”']\n",
            " ['Àwọn', 'Júù', 'sì', 'dá', 'a', 'lóhùn', 'pé', ',', '“', 'Àwa', 'kò', 'sọ', 'ọ́', 'ní', 'òkúta', 'nítorí', 'iṣẹ́', 'rere', ',', 'ṣùgbọ́n', 'nítorí', 'ọ̀rọ̀', '-', 'ọ̀dì', ':', 'àti', 'nítorí', 'ìwọ', 'tí', 'í', 'ṣe', 'ènìyàn', 'ń', 'fi', 'ara', 'rẹ', 'pe', 'Ọlọ́run', '.', '”']\n",
            " ['Jésù', 'dá', 'wọn', 'lóhùn', 'pé', ',', '“', 'A', 'kò', 'ha', 'ti', 'kọ', 'ọ́', 'nínú', 'òfin', 'yín', 'pé', ',', '‘', 'Mo', 'ti', 'wí', 'pé', ',', 'Ọlọ́run', 'ni', 'ẹ̀yin', 'jẹ́', '’', '?']\n",
            " ['Bí', 'èmi', 'kò', 'bá', 'ṣe', 'iṣẹ́', 'Baba', 'mi', ',', 'ẹ', 'má', 'ṣe', 'gbà', 'mí', 'gbọ́', '.']\n",
            " ['Ṣùgbọ́n', 'bí', 'èmi', 'bá', 'ṣe', 'wọ́n', ',', 'bí', 'ẹ̀yin', 'kò', 'tilẹ̀', 'gbà', 'mí', 'gbọ́', ',', 'ẹ', 'gbà', 'iṣẹ́', 'náà', 'gbọ́', ':', 'kí', 'ẹ̀yin', 'baà', 'lè', 'mọ̀', ',', 'kí', 'ó', 'sì', 'lè', 'yé', 'yín', 'pé', ',', 'Baba', 'wà', 'nínú', 'mi', ',', 'èmi', 'sì', 'wà', 'nínú', 'rẹ̀', '.', '”']\n",
            " ['Wọ́n', 'sì', 'tún', 'ń', 'wá', 'ọ̀nà', 'láti', 'mú', 'un', ':', 'ó', 'sì', 'bọ́', 'lọ́wọ́', 'wọn', '.']\n",
            " ['Àwọn', 'ènìyàn', 'púpọ̀', 'sì', 'wá', 'sọ́dọ̀', 'rẹ̀', ',', 'wọ́n', 'sì', 'wí', 'pé', ',', '“', 'Jòhánù', 'kò', 'ṣe', 'iṣẹ́', 'àmì', 'kan', ':', 'Ṣùgbọ́n', 'òtítọ́', 'ni', 'ohun', 'gbogbo', 'tí', 'Jòhánù', 'sọ', 'nípa', 'ti', 'ọkùnrin', 'yìí', '.', '”']\n",
            " ['Àwọn', 'ènìyàn', 'púpọ̀', 'níbẹ̀', 'sì', 'gbà', 'á', 'gbọ́', '.']\n",
            " ['Ara', 'ọkùnrin', 'kan', 'sì', 'ṣe', 'aláìdá', ',', 'Lásárù', ',', 'ará', 'Bẹ́tẹ́nì', ',', 'tí', 'í', 'ṣe', 'ìlú', 'Màríà', 'àti', 'Mátà', 'arábìnrin', 'rẹ̀', '.']\n",
            " ['(', 'Màríà', 'náà', 'ni', 'ẹni', 'tí', 'ó', 'fi', 'òróró', 'ìkunra', 'kun', 'Olúwa', ',', 'tí', 'ó', 'sì', 'fi', 'irun', 'orí', 'rẹ̀', 'nù', 'ún', ',', 'arákùnrin', 'rẹ̀', 'ni', 'Lásárù', 'í', 'ṣe', ',', 'ara', 'ẹni', 'tí', 'kò', 'dá', '.', ')']\n",
            " ['Nítorí', 'náà', ',', 'àwọn', 'arákùnrin', 'rẹ̀', 'ránsẹ́', 'sí', 'i', ',', 'wí', 'pé', ',', '“', 'Olúwa', ',', 'wò', 'ó', ',', 'ara', 'ẹni', 'tí', 'ìwọ', 'fẹ́ràn', 'kò', 'dá', '.', '”']\n",
            " ['Nígbà', 'tí', 'Jésù', 'sì', 'gbọ́', ',', 'ó', 'wí', 'pé', ',', '“', 'Àìsàn', 'yìí', 'kìí', 'ṣe', 'sí', 'ikú', ',', 'ṣùgbọ́n', 'fún', 'Ògo', 'Ọlọ́run', ',', 'kí', 'a', 'lè', 'yin', 'Ọmọ', 'Ọlọ́run', 'lógo', 'nípasẹ̀', 'rẹ̀', '.', '”']\n",
            " ['Ṣùgbọ́n', 'bí', 'ẹnìkan', 'bá', 'rìn', 'ní', 'òru', ',', 'yóò', 'kọsẹ̀', ',', 'nítorí', 'tí', 'kò', 'sí', 'ìmọ́lẹ̀', 'nínú', 'rẹ̀', '.', '”']\n",
            " ['Nǹkan', 'wọ̀nyí', 'ni', 'ó', 'sọ', ':', 'lẹ́yìn', 'èyí', 'nì', 'ó', 'sì', 'wí', 'fún', 'wọn', 'pé', ',', '“', 'Lásárù', 'ọ̀rẹ́', 'wa', 'sùn', ';', 'ṣùgbọ́n', 'èmi', 'ń', 'lọ', 'kí', 'èmi', 'kí', 'ó', 'lè', 'jí', 'i', 'dìde', 'nínú', 'orun', 'rẹ̀', '.', '”']\n",
            " ['Nítorí', 'náà', 'àwọn', 'ọmọ', '-', 'ẹ̀yìn', 'rẹ̀', 'wí', 'fún', 'un', 'pé', ',', '“', 'Olúwa', ',', 'bí', 'ó', 'bá', 'se', 'pé', 'ó', 'sùn', ',', 'yóò', 'sàn', '.', '”']\n",
            " ['Ṣùgbọ́n', 'Jésù', 'ń', 'sọ', 'ti', 'ikú', 'rẹ̀', ':', 'ṣùgbọ́n', 'wọ́n', 'rò', 'pé', ',', 'ó', 'ń', 'sọ', 'ti', 'orun', 'sísùn', '.']\n",
            " ['Nígbà', 'náà', 'ni', 'Jésù', 'wí', 'fún', 'wọn', 'gbangba', 'pé', ',', 'Lásárù', 'kú', ',']\n",
            " ['Èmi', 'sì', 'yọ̀', 'nítorí', 'yín', ',', 'tí', 'èmi', 'kò', 'sí', 'níbẹ̀', ',', 'Kí', 'ẹ', 'le', 'gbàgbọ́', ';', 'ṣùgbọ́n', 'ẹ', 'jẹ́', 'kí', 'a', 'lọ', 'sọ́dọ̀', 'rẹ̀', '.']\n",
            " ['“', 'Nítorí', 'náà', 'Tómásì', ',', 'ẹni', 'tí', 'à', 'ń', 'pè', 'ní', 'Dídímù', ',', 'wí', 'fún', 'àwọn', 'ọmọ', '-', 'ẹ̀yìn', 'ẹgbẹ́', 'rẹ̀', 'pé', ',', 'Ẹ', 'jẹ́', 'kí', 'àwa', 'náà', 'lọ', ',', 'kí', 'a', 'lè', 'bá', 'a', 'kú', 'pẹ̀lú', '.', '”']\n",
            " ['Nítorí', 'náà', 'nígbà', 'tí', 'Jésù', 'dé', ',', 'ó', 'rí', 'i', 'pé', 'a', 'ti', 'tẹ́', 'ẹ', 'sínú', 'ibojì', 'ní', 'ijọ́', 'mẹ́rin', 'ná', ',']\n",
            " ['Ǹjẹ́', 'Bétanì', 'súnmọ́', 'Jérúsálẹ́mù', 'tó', 'ibùsọ', 'Mẹ́ẹ̀dógún', ':']\n",
            " ['Ọ̀pọ̀', 'nínú', 'àwọn', 'Júù', 'sì', 'wá', 'sọ́dọ̀', 'Mátà', 'àti', 'Màríà', 'láti', 'tù', 'wọ́n', 'nínú', 'nítorí', 'ti', 'arákùnrin', 'wọn', '.']\n",
            " ['Nítorí', 'náà', ',', 'nígbà', 'tí', 'Mátà', 'gbọ́', 'pé', 'Jésù', 'ń', 'bọ̀', 'wá', ',', 'ó', 'jáde', 'lọ', 'pàdé', 'rẹ̀', ':', 'ṣùgbọ́n', 'Màríà', 'jòkó', 'nínú', 'ilé', '.']\n",
            " ['Nígbà', 'náà', ',', 'ni', 'Mátà', 'wí', 'fún', 'Jésù', 'pé', ',', '“', 'Olúwa', ',', 'ì', 'bá', 'ṣe', 'pé', 'ìwọ', 'ti', 'wà', 'níhìn-ín', ',', 'arákùnrin', 'mi', 'kì', 'bá', 'kú', '.']\n",
            " ['Jésù', 'wí', 'fún', 'un', 'pé', ',', '“', 'Arákùnrin', 'rẹ', 'yóò', 'jíǹde', '.', '”']\n",
            " ['Mátà', 'wí', 'fún', 'un', 'pé', ',', '“', 'Mo', 'mọ̀', 'pé', 'yóò', 'jíǹde', 'ní', 'àjíǹde', 'ìkẹyìn', '.', '”']\n",
            " ['Jésù', 'wí', 'fún', 'un', 'pé', ',', '“', 'Èmi', 'ni', 'àjíǹde', 'àti', 'ìyè', ':', 'ẹni', 'tí', 'ó', 'bá', 'gbà', 'mí', 'gbọ́', ',', 'bí', 'ó', 'tilẹ̀', 'kú', ',', 'yóò', 'yè', ':']\n",
            " ['Ẹnikẹ́ni', 'tí', 'ó', 'ń', 'bẹ', 'láàyè', ',', 'tí', 'ó', 'sì', 'gbà', 'mí', 'gbọ́', ',', 'kì', 'yóò', 'kú', 'láéláé', 'ìwọ', 'gbà', 'èyí', 'gbọ́', '?', '”']\n",
            " ['Ó', 'wí', 'fún', 'un', 'pé', ',', '“', 'Bẹ́ẹ̀', 'ni', ',', 'Olúwa', ':', 'èmi', 'gbàgbọ́', 'pé', ',', 'ìwọ', 'ni', 'Kírísítì', 'náà', 'Ọmọ', 'Ọlọ́run', ',', 'ẹni', 'tí', 'ń', 'bọ̀', 'wá', 'sí', 'ayé', '.', '”']\n",
            " ['Nígbà', 'tí', 'ó', 'sì', 'ti', 'wí', 'èyí', 'tán', ',', 'ó', 'lọ', ',', 'ó', 'sì', 'pe', 'Màríà', 'arábìnrin', 'rẹ̀', 'sẹ́yìn', 'wí', 'pé', ',', '“', 'Olùkọ́', 'dé', ',', 'ó', 'sì', 'ń', 'pè', 'ọ́', '.', '”']\n",
            " ['Nígbà', 'tí', 'ó', 'gbọ́', ',', 'ó', 'dìde', 'lọ́gán', ',', 'ó', 'sì', 'wá', 'sọ́dọ̀', 'rẹ̀', '.']\n",
            " ['Jésù', 'kò', 'tíì', 'wọ', 'ìlú', ',', 'ṣùgbọ́n', 'ó', 'wà', 'ní', 'ibi', 'kan', 'náà', 'tí', 'Mátà', 'ti', 'pàdé', 'rẹ̀', '.']\n",
            " ['Nígbà', 'tí', 'àwọn', 'Júù', 'tí', 'ó', 'wà', 'lọ́dọ̀', 'rẹ̀', 'nínú', 'ilé', ',', 'tí', 'wọ́n', 'ń', 'tù', 'ú', 'nínú', 'rí', 'Màríà', 'tí', 'ó', 'dìde', 'kánkán', ',', 'tí', 'ó', 'sì', 'jáde', ',', 'wọ́n', 'tẹ̀lé', ',', 'wọ́n', 'ṣebí', 'ó', 'ń', 'lọ', 'sí', 'ibojì', 'láti', 'sọkún', 'níbẹ̀', '.']\n",
            " ['Nígbà', 'tí', 'Màríà', 'sì', 'dé', 'ibi', 'tí', 'Jésù', 'wà', ',', 'tí', 'ó', 'sì', 'rí', 'i', ',', 'ó', 'wólẹ̀', 'lẹ́bàá', 'ẹsẹ̀', 'rẹ̀', ',', 'ó', 'wí', 'fún', 'un', 'pé', ',', '“', 'Olúwa', ',', 'ìbáṣe', 'pé', 'ìwọ', 'ti', 'wà', 'níhín-ín', ',', 'arákùnrin', 'mi', 'kì', 'bá', 'kú', '.', '”']\n",
            " ['Ó', 'sì', 'wí', 'pé', ',', '“', 'Níbo', 'ni', 'ẹ̀yin', 'gbé', 'tẹ́', 'ẹ', 'sí', '?', '”', 'Wọ́n', 'sì', 'wí', 'fún', 'un', 'pé', ',', '“', 'Olúwa', ',', 'wá', 'wò', 'ó', '.', '”']\n",
            " ['Jésù', 'sọkún', '.']\n",
            " ['Nítorí', 'náà', 'àwọn', 'Júù', 'wí', 'pé', ',', '“', 'Sá', 'wò', 'ó', 'bí', 'ó', 'ti', 'fẹ́ràn', 'rẹ̀', 'tó', '!', '”']\n",
            " ['Àwọn', 'kan', 'nínú', 'wọn', 'sì', 'wí', 'pé', ',', '“', 'Ọkùnrin', 'yìí', ',', 'ẹni', 'tí', 'ó', 'la', 'ojú', 'afọ́jú', ',', 'kò', 'lè', 'ṣeé', 'kí', 'ọkùnrin', 'yìí', 'má', 'kú', 'bí', '?', '”']\n",
            " ['Nígbà', 'náà', 'ni', 'Jésù', 'tún', 'kérora', 'nínú', 'ara', 'rẹ̀', ',', 'ó', 'wá', 'sí', 'ibojì', ',', 'ó', 'sì', 'jẹ́', 'ihò', ',', 'a', 'sì', 'gbé', 'òkúta', 'lé', 'ẹnu', 'rẹ̀', '.']\n",
            " ['Jésù', 'wí', 'pé', ',', '“', 'Ẹ', 'gbé', 'òkúta', 'náà', 'kúrò', '!', '”', 'Màtá', ',', 'arábìnrin', 'ẹni', 'tí', 'ó', 'kú', 'náà', 'wí', 'fún', 'un', 'pé', ',', '“', 'Olúwa', ',', 'ó', 'ti', 'ń', 'rùn', 'nísinsin', 'yìí', ':', 'nítorí', 'pé', 'ó', 'di', 'ijọ́', 'kẹrin', 'tí', 'ó', 'tí', 'kú', '.', '”']\n",
            " ['Jésù', 'wí', 'fún', 'un', 'pé', ',', '“', 'Èmi', 'kò', 'ti', 'wí', 'fún', 'ọ', 'pé', ',', 'bí', 'ìwọ', 'bá', 'gbàgbọ́', ',', 'ìwọ', 'ó', 'rí', 'ògo', 'Ọlọ́run', '?', '”']\n",
            " ['Nígbà', 'náà', 'ni', 'wọ́n', 'gbé', 'òkúta', 'náà', 'kúrò', '(', 'níbi', 'tí', 'a', 'tẹ́', 'ẹ', 'sí', ')', '.', 'Jésù', 'sì', 'gbé', 'ojú', 'rẹ̀', 'sókè', ',', 'ó', 'sì', 'wí', 'pé', ',', '“', 'Baba', ',', 'mo', 'dúpẹ́', 'lọ́wọ́', 'rẹ', 'nítorí', 'tí', 'ìwọ', 'gbọ́', 'tèmi', '.']\n",
            " ['Èmi', 'sì', 'ti', 'mọ̀', 'pé', ',', 'ìwọ', 'a', 'máa', 'gbọ́', 'ti', 'èmi', 'nígbà', 'gbogbo', ':', 'ṣùgbọ́n', 'nítorí', 'ìjọ', 'ènìyàn', 'tí', 'ó', 'dúró', 'yìí', 'ni', 'mo', 'ṣe', 'wí', 'i', ',', 'kí', 'wọn', 'baà', 'lè', 'gbàgbọ́', 'pé', 'ìwọ', 'ni', 'ó', 'rán', 'mi', '.', '”']\n",
            " ['Nígbà', 'tí', 'ó', 'sì', 'wí', 'bẹ́ẹ̀', 'tan', ',', 'ó', 'kígbe', 'lóhùn', 'rara', 'pé', ',', '“', 'Lásárù', ',', 'jáde', 'wá', '.', '”']\n",
            " ['Ẹni', 'tí', 'ó', 'kú', 'náà', 'sì', 'jáde', 'wá', ',', 'tí', 'a', 'fi', 'aṣọ', 'òkú', 'dì', 'tọwọ́', 'tẹsẹ̀', 'a', 'sì', 'fi', 'gèlè', 'dì', 'í', 'lójú', '.', 'Jésù', 'wí', 'fún', 'wọn', 'pé', ',', '“', 'Ẹ', 'tú', 'u', ',', 'ẹ', 'sì', 'jẹ́', 'kí', 'ó', 'má', 'a', 'lọ', '!', '”']\n",
            " ['Nítorí', 'náà', 'ni', 'ọ̀pọ̀', 'àwọn', 'Júù', 'tí', 'ó', 'wá', 'sọ́dọ̀', 'Màríà', ',', 'tí', 'wọ́n', 'rí', 'ohun', 'tí', 'Jésù', 'ṣe', ',', 'ṣe', 'gbà', 'á', 'gbọ́', '.']\n",
            " ['Ṣùgbọ́n', 'àwọn', 'ẹlòmíràn', 'nínú', 'wọn', 'tọ', 'àwọn', 'Farisí', 'lọ', ',', 'wọ́n', 'sì', 'sọ', 'fún', 'wọn', 'ohun', 'tí', 'Jésù', 'ṣe', '.']\n",
            " ['Wọn', 'lọ', 'si', 'apákejì', 'adágún', 'ní', 'ẹba', 'ilẹ̀', 'àwọn', 'ará', 'Gádárà', '.']\n",
            " ['Bí', 'Jésù', 'sì', 'ti', 'ń', 'ti', 'inú', 'ọkọ̀', 'ojú', 'omi', 'jáde', '.', 'Ọkùnrin', 'kan', 'tí', 'ó', 'ní', 'ẹ̀mí', 'àìmọ́', 'jáde', 'ti', 'ibojì', 'wá', 'pàdé', 'rẹ̀', '.']\n",
            " ['Ọkùnrin', 'yìí', 'ń', 'gbé', 'nínú', 'ìbojì', ',', 'kò', 'sí', 'ẹni', 'tí', 'ó', 'lè', 'dè', 'é', 'mọ́', ',', 'kódà', 'ẹ̀wọ̀n', 'kò', 'le', 'dè', 'é', '.']\n",
            " ['Nítorí', 'pé', 'nígbà', 'púpọ̀', 'ni', 'wọn', 'ti', 'ń', 'fi', 'ṣẹ́kẹ́sẹkẹ̀', 'dè', 'é', 'ní', 'ọwọ́', 'àti', 'ẹṣẹ̀', ',', 'tí', 'ó', 'sì', 'ń', 'já', 'a', 'dànù', 'kúrò', 'ni', 'ẹṣẹ', 'rẹ', '.', 'Kò', 'sí', 'ẹnìkan', 'tí', 'ó', 'ní', 'agbára', 'láti', 'káwọ́', 'rẹ̀', '.']\n",
            " ['Tọ̀sán', '-', 'tòru', 'láàrin', 'àwọn', 'ibojì', 'àti', 'ní', 'àwọn', 'òkè', 'ni', 'ó', 'máa', 'ń', 'kígbe', 'rara', 'tí', 'ó', 'sì', 'ń', 'fi', 'òkúta', 'ya', 'ara', 'rẹ̀', '.']\n",
            " ['Nígbà', 'tí', 'ó', 'sì', 'rí', 'Jésù', 'látòkèrè', ',', 'ó', 'sí', 'sáré', 'lọ', 'láti', 'pàdé', 'rẹ̀', '.', 'Ó', 'sì', 'wólẹ̀', 'níwájú', 'rẹ̀', '.']\n",
            " ['Ó', 'sì', 'kígbe', 'ní', 'ohùn', 'rara', 'wí', 'pé', ',', '“', 'Kí', 'ni', 'ṣe', 'tèmi', 'tìrẹ', ',', 'Jésù', 'Ọmọ', 'Ọlọ́run', 'Ọ̀ga', 'Ògo', '?', 'Mo', 'fi', 'Ọlọ́run', 'bẹ̀', 'ọ́', 'má', 'ṣe', 'dá', 'mi', 'ní', 'oró', '.', '”']\n",
            " ['Nítorí', 'tí', 'Ó', 'wí', 'fún', 'un', 'pé', ',', '“', 'Jáde', 'kúrò', 'lára', 'ọkùnrin', 'náà', ',', 'ìwọ', 'ẹ̀mí', 'àìmọ́', '!', '”']\n",
            " ['Jésù', 'sì', 'bi', 'í', 'léèrè', 'pé', ',', '“', 'Kí', 'ni', 'orúkọ', 'rẹ', '?', '”', 'Ẹ̀mí', 'àìmọ́', 'náà', 'sì', 'dáhùn', 'wí', 'pé', ',', '“', 'Líjíọ́nì', ',', 'nítorí', 'àwa', 'pọ̀', '.', '”']\n",
            " ['Nígbà', 'náà', 'ni', 'ẹ̀mí', 'àìmọ́', 'náà', 'bẹ̀rẹ̀', 'sí', 'í', 'bẹ', 'Jésù', 'gidigidi', ',', 'kí', 'ó', 'má', 'ṣe', 'rán', 'àwọn', 'jáde', 'kúrò', 'ní', 'agbègbè', 'náà', '.']\n",
            " ['Agbo', 'ẹlẹ́dẹ̀', 'ńlá', 'kan', 'sì', 'ń', 'jẹ', 'lẹ́bàá', 'òké', '.']\n",
            " ['Àwọn', 'ẹ̀mí', 'àìmọ́', 'náà', 'bẹ', 'Jésù', 'pé', ',', '“', 'Rán', 'wa', 'lọ', 'sínú', 'àwọn', 'ẹlẹ́dẹ̀', 'wọnni', 'kí', 'awa', 'le', 'è', 'wọ', 'inú', 'wọn', 'lọ', '.', '”']\n",
            " ['Jésù', 'fún', 'wọn', 'láàyè', ',', 'àwọn', 'ẹ̀mí', 'àìmọ́', 'náà', 'sì', 'jáde', 'kúrò', 'lára', 'ọkùnrin', 'náà', ',', 'wọ́n', 'sì', 'wọ', 'inú', 'àwọn', 'ẹlẹ́dẹ̀', 'náà', 'lọ', '.', 'Agbo', 'ẹlẹ́dẹ̀', 'náà', 'tí', 'ó', 'tó', 'ìwọ̀n', 'ẹgbàá', 'sì', 'túká', 'lọ́gán', ',', 'wọ́n', 'sì', 'sáré', 'lọ', 'ní', 'gẹ̀rẹ́gẹ̀rẹ́', 'òkè', 'rọ́', 'sínú', 'òkun', ',', 'wọ́n', 'sì', 'ṣègbé', '.']\n",
            " ['Àwọn', 'olùtọ́jú', 'ẹran', 'wọ̀nyí', 'sì', 'sá', 'lọ', 'sí', 'àwọn', 'ìlú', 'ńlá', 'àti', 'ìlú', 'kéékèèkéé', ',', 'wọ́n', 'sì', 'ń', 'tan', 'ìròyìn', 'náà', 'ká', 'bí', 'wọ́n', 'ti', 'ń', 'sáré', '.', 'Àwọn', 'ènìyàn', 'sì', 'tú', 'jáde', 'láti', 'fojú', 'gán-án-ní', 'ohun', 'náà', 'tí', 'ó', 'sẹlẹ̀', '.']\n",
            " ['Nígbà', 'tí', 'wọ́n', 'péjọ', 'sọ́dọ̀', 'Jésù', ',', 'wọ́n', 'rí', 'ọkùnrin', 'náà', ',', 'ẹni', 'tí', 'ó', 'ní', 'ẹ̀mí', '-', 'èṣù', ',', 'tí', 'ó', 'jokòó', 'níbẹ̀', ',', 'ó', 'wọ', 'aṣọ', 'iye', 'rẹ', 'sì', 'bọ̀', 'sípọ', ',', 'ẹ̀rù', 'sì', 'bà', 'wọ́n', '.']\n",
            " ['Àwọn', 'tí', 'ìṣẹ̀lẹ̀', 'yìí', 'ṣojú', 'wọn', 'sì', 'ń', 'ròyìn', 'rẹ̀', 'fún', 'àwọn', 'ènìyàn', 'ohun', 'tí', 'ó', 'sẹlẹ̀', 'sí', 'ọkùnrin', 'ẹlẹ́mí', 'àìmọ́', ',', 'wọn', 'si', 'sọ', 'nípa', 'agbo', 'ẹlẹ́dẹ̀', 'náà', 'pẹ̀lú', '.']\n",
            " ['Nígbà', 'náà', ',', 'àwọn', 'èrò', 'bẹ̀rẹ̀', 'sí', 'ní', 'bẹ', 'Jésù', 'pé', 'kí', 'ó', 'fi', 'agbégbé', 'àwọn', 'sílẹ̀', '.']\n",
            " ['Bí', 'Jésù', 'ti', 'ń', 'wọ', 'inú', 'ọkọ̀', 'ojú', '-', 'omi', 'lọ', ',', 'ọkùnrin', 'náà', 'tí', 'ó', 'ti', 'ní', 'ẹ̀mí', 'àìmọ́', 'tẹ̀lẹ̀', 'bẹ̀', 'Ẹ́', 'pé', 'kí', 'òun', 'lè', 'bá', 'a', 'lọ', '.']\n",
            " ['Jésù', 'kò', 'gbà', 'fún', 'un', ',', 'ṣùgbọ́n', 'ó', 'wí', 'fún', 'un', 'pé', ',', '“', 'Lọ', 'sí', 'ilé', 'sí', 'ọ̀dọ̀', 'àwọn', 'ẹbí', 'rẹ', ',', 'kí', 'o', 'sì', 'sọ', 'fún', 'wọn', 'bí', 'Ọlọ́run', 'ti', 'ṣe', 'ohun', 'ńlá', 'fún', 'ọ', ',', 'àti', 'bí', 'ó', 'sì', 'ti', 'ṣàánú', 'fún', 'ọ', '.', '”']\n",
            " ['Nítorí', 'naà', ',', 'ọkùnrin', 'yìí', 'padà', 'lọ', ',', 'ó', 'bẹ̀rẹ̀', 'sí', 'ròyìn', 'ní', 'Dekapolisi', 'nípa', 'ohun', 'ńlá', 'tí', 'Jésù', 'ṣe', 'fún', 'un', '.', 'Ẹnu', 'sì', 'ya', 'gbogbo', 'ènìyàn', '.']\n",
            " ['Nígbà', 'tí', 'Jésù', 'sì', 'ti', 'inú', 'ọkọ̀', 'rékọjá', 'sí', 'apá', 'kejì', 'òkun', ',', 'ọ̀pọ̀', 'ìjọ', 'ènìyàn', 'péjọ', 'yí', 'i', 'ká', 'ní', 'etí', 'òkun', '.']\n",
            " ['Ọ̀kan', 'nínú', 'àwọn', 'olórí', 'sínágọ́gù', 'tí', 'à', 'ń', 'pè', 'ni', 'Jáírù', 'wá', 'sọ́dọ̀', 'Jésù', ',', 'nígbà', 'tí', 'ó', 'sì', 'rí', 'i', ',', 'ó', 'wólẹ̀', 'níwájú', 'rẹ̀', '.']\n",
            " ['Ó', 'sì', 'bẹ̀', 'ẹ́', 'gidigidi', 'pé', ',', '“', 'Ọmọbìnrin', 'mi', 'wà', 'lójú', 'ikú', ',', 'mo', 'bẹ̀', 'ọ́', ',', 'wá', 'fi', 'ọwọ́', 'rẹ', 'lé', 'e', ',', 'kí', 'ara', 'rẹ̀', 'lè', 'dá', ',', 'kí', 'ó', 'sì', 'yè', '.', '”']\n",
            " ['Jésù', 'sì', 'ń', 'bá', 'a', 'lọ', '.', 'Ọ̀pọ̀', 'ìjọ', 'ènìyàn', 'sì', 'ń', 'tọ̀', 'Ọ́', 'lẹ́yìn', '.']\n",
            " ['Obìnrin', 'kan', 'sì', 'wà', 'láàrin', 'ọ̀pọ̀', 'ènìyàn', 'náà', ',', 'tí', 'ó', 'ti', 'ní', 'ìsun', 'ẹ̀jẹ̀', 'fún', 'odidi', 'ọdún', 'méjìlá', '.']\n",
            " ['Ẹni', 'tí', 'ojú', 'rẹ̀', 'sì', 'ti', 'rí', 'ọ̀pọ̀lọpọ̀', 'ìpọ́njú', 'lọ́dọ̀', 'ọ̀pọ̀', 'àwọn', 'oníṣègùn', ',', 'tí', 'ó', 'sì', 'ti', 'ná', 'gbogbo', 'ohun', 'tí', 'ó', 'ní', ',', 'síbẹ̀', 'kàkà', 'kí', 'ó', 'san', ',', 'ó', 'ń', 'burú', 'sí', 'i', '.']\n",
            " ['Nígbà', 'tí', 'ó', 'sì', 'gburo', 'iṣẹ́', 'ìyanu', 'tí', 'Jésù', 'ṣe', ',', 'ìdí', 'ni', 'èyí', 'tí', 'ó', 'fi', 'wá', 'sẹ́yìn', 'rẹ̀', ',', 'láàrin', 'ọ̀pọ̀', 'ènìyàn', ',', 'ó', 'sì', 'fi', 'ọwọ́', 'kan', 'aṣọ', 'rẹ̀', '.']\n",
            " ['Nítorí', 'ti', 'ó', 'rò', 'ní', 'ọkàn', 'rẹ̀', 'pé', ',', '“', 'Bí', 'mo', 'bá', 'ṣá', 'à', 'lè', 'fi', 'ọwọ́', 'kan', 'aṣọ', 'rẹ̀', ',', 'ara', 'mi', 'yóò', 'dá', '.', '”']\n",
            " ['Ìsun', 'ẹ̀jẹ̀', 'rẹ', 'sì', 'gbẹ', 'lẹṣẹkẹṣẹ', ',', 'òun', 'sì', 'mọ̀', 'lára', 'rẹ̀', 'pé', ',', 'a', 'mú', 'òun', 'ní', 'ara', 'dá', 'kúrò', 'nínú', 'àrùn', 'náà', '.']\n",
            " ['Lọ́gán', ',', 'Jésù', 'sì', 'mọ̀', 'nínú', 'ara', 'rẹ̀', 'pé', 'agbára', 'jáde', 'lára', 'òun', '.', 'Ó', 'yípadà', 'láàrin', 'ọ̀pọ̀', 'ènìyàn', ',', 'ó', 'sì', 'béèrè', ',', '“', 'Ta', 'ni', 'ó', 'fi', 'ọwọ́', 'kan', 'aṣọ', 'mi', '?', '”']\n",
            " ['Àwọn', 'ọmọ', '-', 'ẹ̀yìn', 'rẹ̀', 'wí', 'fún', 'un', 'pé', ',', '“', 'Ìwọ', 'rí', 'ọ̀pọ̀', 'ènìyàn', 'tí', 'ó', 'rọ̀gbà', 'yí', 'ọ', 'ká', ',', 'ìwọ́', 'sì', 'tún', 'ń', 'bèèrè', 'ẹni', 'tí', 'ó', 'fi', 'ọwọ́', 'kàn', 'ọ́', '?', '”']\n",
            " ['Ṣíbẹ̀', ',', 'Jésù', 'bẹ̀rẹ̀', 'sí', 'wò', 'yíká', 'láti', 'rí', 'ẹni', 'náà', ',', 'tí', 'ó', 'fi', 'ọwọ́', 'kan', 'òun', '.']\n",
            " ['Nígbà', 'náà', ',', 'obìnrin', 'náà', 'kún', 'fún', 'ìbẹ̀rù', 'àti', 'ìwárìrì', 'nítorí', 'ó', 'ti', 'mọ', 'ohun', 'tí', 'ó', 'ṣẹlẹ̀', 'ní', 'ara', 'òun', '.', 'Ó', 'sì', 'kúnlẹ̀', 'níwájú', 'rẹ̀', ',', 'ó', 'sì', 'sọ', 'ohun', 'tí', 'òun', 'ti', 'ṣe', '.']\n",
            " ['Jésù', 'sì', 'wí', 'fún', 'un', 'pé', ',', '“', 'Ọmọbìnrin', ',', 'ìgbàgbọ́', 'rẹ', 'mú', 'ọ', 'ní', 'ara', 'dá', ':', 'Má', 'a', 'lọ', 'ní', 'àlàáfíà', ',', 'ìwọ', 'sì', 'ti', 'sàn', 'nínú', 'àrùn', 'rẹ', '.', '”']\n",
            " ['Bí', 'Jésù', 'sì', 'ti', 'ń', 'ba', 'obìnrin', 'náà', 'sọ̀rọ̀', ',', 'àwọn', 'ìránṣẹ́', 'dé', 'láti', 'ilé', 'Jáírù', 'olorí', 'sínágọ́gù', 'wá', ',', 'wọ́n', 'wí', 'fún', 'un', 'pé', ',', 'ọmọbìnrin', 'rẹ', 'ti', 'kú', ',', 'àti', 'pé', 'kí', 'wọn', 'má', 'ṣe', 'yọ', 'Jésù', 'ní', 'ẹnu', 'láti', 'wá', ',', 'nítorí', 'ó', 'ti', 'pẹ́', 'jù', '.']\n",
            " ['Ṣùgbọ́n', 'bi', 'Jésù', 'ti', 'gbọ́', 'ọ̀rọ̀', 'náà', ',', 'ó', 'wí', 'fún', 'Jáírù', 'pé', ',', '“', 'Má', 'bẹ̀rù', ',', 'sá', 'à', 'gbà', 'mí', 'gbọ́', 'nìkan', '.', '”']\n",
            " ['Nígbà', 'náà', ',', 'Jésù', 'dá', 'ọ̀pọ̀', 'ènìyàn', 'náà', 'dúró', '.', 'Kò', 'sì', 'jẹ́', 'kí', 'ẹnikẹ́ni', 'tẹ̀lé', 'òun', 'lẹ́yìn', 'lọ', 'ilé', 'Jáírù', ',', 'bí', 'kò', 'ṣe', 'Pétérù', ',', 'Jákọ́bù', 'àti', 'Jòhánù', '.']\n",
            " ['Nígbà', 'tí', 'wọ́n', 'dé', 'ibẹ̀', ',', 'Jésù', 'rí', 'i', 'pé', 'gbogbo', 'nǹkan', 'ti', 'dàrú', '.', 'Ilé', 'kún', 'fún', 'àwọn', 'tí', 'ń', 'sọkún', ',', 'àti', 'àwọn', 'tí', 'ń', 'pohùnréré', 'ẹkún', '.']\n",
            " ['Ó', 'wọ', 'inú', 'ilé', 'lọ', ',', 'Ó', 'sì', 'bá', 'àwọn', 'ènìyàn', 'sọ̀rọ̀', ',', 'ó', 'béèrè', 'pé', ',', '“', 'Èéṣe', 'tí', 'ẹ̀yin', 'fi', 'ń', 'sọkún', 'tí', 'ẹ', 'sì', 'ń', 'pohunréré', 'ẹkún', '?', 'Ọmọbìnrin', 'náà', 'kò', 'kú', ',', 'ó', 'sùn', 'lásán', 'ni', '.', '”']\n",
            " ['Wọ́n', 'sì', 'fi', 'í', 'rẹ́rín', '.', 'Ṣùgbọ́n', 'ó', 'sọ', 'fún', 'gbogbo', 'wọn', 'láti', 'bọ́', 'sí', 'ìta', ',', 'ó', 'mú', 'baba', 'àti', 'ìyá', 'ọmọ', 'náà', ',', 'àti', 'àwọn', 'ọmọ', 'ẹ̀yin', 'rẹ̀', 'mẹ́ta', '.', 'Ó', 'sì', 'wọ', 'inú', 'yàrá', 'tí', 'ọmọbìnrin', 'náà', 'gbé', 'dùbúlẹ̀', 'sí', '.']\n",
            " ['Ó', 'gba', 'a', 'ní', 'ọwọ́', 'mú', ',', 'ó', 'sì', 'wí', 'pé', ',', '“', 'Tàlítà', 'kúùmì', '”', '(', 'tí', 'ó', 'túmọ̀', 'sí', ',', 'ọmọdébìnrin', ',', 'díde', 'dúró', ')', '.']\n",
            " ['Lẹ́sẹ̀kan', '-', 'náà', ',', 'ọmọbìnrin', 'náà', 'sì', 'dìde', '.', 'Ó', 'sì', 'ń', 'rìn', ',', 'ẹ̀rù', 'sì', 'ba', 'wọn', ',', 'ẹnú', 'sì', 'ya', 'àwọn', 'òbí', 'rẹ̀', 'gidigidi', '.']\n",
            " ['Jésù', 'sì', 'kìlọ̀', 'fún', 'wọn', 'gidigidi', 'pé', 'kí', 'wọn', 'má', 'ṣe', 'sọ', 'ohun', 'tí', 'ó', 'ti', 'ṣẹlẹ̀', '.', 'Ó', 'sì', 'wí', 'fún', 'wọn', 'kí', 'wọn', 'fún', 'ọmọbìnrin', 'náà', 'ní', 'oúnjẹ', '.']\n",
            " ['Nígbà', 'tí', 'ó', 'rí', 'ọ̀pọ̀', 'ènìyàn', ',', 'ó', 'gun', 'orí', 'òkè', 'lọ', 'ó', 'sì', 'jókòó', '.', 'Àwọn', 'ọmọ', '-', 'ẹ̀yìn', 'rẹ̀', 'si', 'tọ̀', 'ọ́', 'wá', '.']\n",
            " ['Ó', 'sì', 'bẹ̀rẹ̀', 'sí', 'kọ́', 'wọn', 'wí', 'pé', ':']\n",
            " ['“', 'Alábùkún', '-', 'fún', 'ni', 'àwọn', 'òtòsì', 'ní', 'ẹ̀mí', ',', 'nítorí', 'tiwọn', 'ni', 'ìjọba', 'ọ̀run', '.']\n",
            " ['Alábùkún', '-', 'fún', 'ni', 'àwọn', 'tí', 'ń', 'ṣọ̀fọ̀', ',', 'nítorí', 'a', 'ó', 'tù', 'wọ́n', 'nínú', '.']\n",
            " ['Alábùkún', '-', 'fún', 'ni', 'àwọn', 'ọlọ́kàn', 'tútù', ',', 'nítorí', 'wọn', 'yóò', 'jogún', 'ayé', '.']\n",
            " ['Alábùkún', 'fún', 'ni', 'àwọn', 'tí', 'ebi', 'ń', 'pa', 'tí', 'òùngbẹ', 'ń', 'gbẹ́', 'nítorí', 'òdodo', ',', 'nítorí', 'wọn', 'yóò', 'yó', '.']\n",
            " ['Alábùkún', '-', 'fún', 'ni', 'àwọn', 'aláàánú', ',', 'nítorí', 'wọn', 'yóò', 'rí', 'àánú', 'gbà', '.']\n",
            " ['Alábùkún', '-', 'fún', 'ni', 'àwọn', 'ọlọ́kàn', 'mímọ́', ',', 'nítorí', 'wọn', 'yóò', 'rí', 'Ọlọ́run', '.']\n",
            " ['Alábùkún', '-', 'fún', 'ni', 'àwọn', 'tonílàjà', ',', 'nítorí', 'ọmọ', 'Ọlọ́run', 'ni', 'a', 'ó', 'máa', 'pè', 'wọ́n', '.']\n",
            " ['Alábùkún', '-', 'fún', 'ni', 'àwọn', 'ẹni', 'tí', 'a', 'ṣe', 'inúnibíni', 'sí', ',', 'nítorí', 'tí', 'wọ́n', 'jẹ́', 'olódodo', 'nítorí', 'tiwọn', 'ní', 'ìjọba', 'ọ̀run', '.']\n",
            " ['“', 'Alábùkún', '-', 'fún', 'ni', 'ẹ̀yin', 'nígbà', 'tí', 'àwọn', 'ènìyàn', 'bá', 'fi', 'àbùkù', 'kàn', 'yín', 'tí', 'wọn', 'bá', 'ṣe', 'inúnibíni', 'sí', 'yín', ',', 'ti', 'wọn', 'fi', 'ètè', 'èké', 'sọ̀rọ̀', 'búburú', 'gbogbo', 'sí', 'yín', 'nítorí', 'mi', '.']\n",
            " ['Ẹ', 'yọ̀', ',', 'kí', 'ẹ̀yin', 'sì', 'fò', 'fún', 'ayọ', ',', 'nítorí', 'ńlá', 'ni', 'èrè', 'yín', 'ní', 'ọ̀run', ',', 'nítorí', 'bẹ́ẹ̀', 'ni', 'wọ́n', 'ṣe', 'ṣe', 'inúnibíni', 'sí', 'àwọn', 'wòlíì', 'tí', 'ń', 'bẹ', 'ṣáájú', 'yín', '.']\n",
            " ['“', 'Ẹ̀yin', 'ni', 'iyọ̀', 'ayé', '.', 'Ṣùgbọ́n', 'bí', 'iyọ̀', 'bá', 'di', 'òbu', 'kí', 'ni', 'a', 'ó', 'fi', 'mú', 'un', 'dùn', '?', 'Kò', 'tún', 'wúlò', 'fún', 'ohunkóhun', 'mọ́', ',', 'bí', 'kò', 'ṣe', 'pé', 'kí', 'a', 'dà', 'á', 'nù', ',', 'kí', 'ó', 'sì', 'di', 'ohun', 'tí', 'ènìyàn', 'ń', 'fi', 'ẹsẹ̀', 'tẹ̀', 'mọ́', 'ilẹ̀', '.']\n",
            " ['“', 'Ẹyin', 'ni', 'ìmọ́lẹ̀', 'ayé', '.', 'Ìlú', 'tí', 'a', 'tẹ̀dó', 'sórí', 'òkè', 'kò', 'lè', 'fara', 'sin', '.']\n",
            " ['Bẹ́ẹ̀', 'ni', 'a', 'kì', 'í', 'tan', 'fìtílà', 'tán', ',', 'kí', 'a', 'sì', 'gbé', 'e', 'sí', 'abẹ́', 'òṣùnwọ̀n', ';', 'bí', 'kò', 'ṣe', 'sí', 'orí', 'ọ̀pá', 'fìtílà', ',', 'a', 'sì', 'tan', 'ìmọ́lẹ̀', 'fún', 'gbogbo', 'ẹni', 'tí', 'ń', 'bẹ', 'nínú', 'ilé', '.']\n",
            " ['Bákan', 'náà', ',', 'ẹ', 'jẹ́', 'kí', 'ìmọ́lẹ̀', 'yín', 'kí', 'ó', 'mọ́lẹ', 'níwájú', 'ènìyàn', ',', 'kí', 'wọ́n', 'lè', 'máa', 'rí', 'iṣẹ́', 'rere', 'yín', ',', 'kí', 'wọn', 'lè', 'máa', 'yin', 'baba', 'yín', 'tí', 'ń', 'bẹ', 'ní', 'ọ̀run', 'ní', 'ògo', '.']\n",
            " ['“', 'Ẹ', 'má', 'se', 'rò', 'pé', ',', 'èmí', 'wá', 'láti', 'pa', 'òfin', 'àwọn', 'wòlíì', 'run', ',', 'èmi', 'kò', 'wá', 'láti', 'pa', 'wọn', 'rẹ́', ',', 'bí', 'kò', 'ṣe', 'láti', 'mú', 'wọn', 'ṣẹ', '.']\n",
            " ['Lóòótọ́', 'ni', 'mo', 'wí', 'fún', 'un', 'yín', ',', 'títí', 'ọ̀run', 'òun', 'ayé', 'yóò', 'fi', 'kọjá', ',', 'àmì', 'kínkínní', 'tí', 'a', 'fi', 'gègé', 'ṣe', 'kan', 'kì', 'yóò', 'parẹ́', 'kúrò', 'nínú', 'gbogbo', 'òfin', 'tó', 'wà', 'nínú', 'ìwé', 'ofin', 'títí', 'gbogbo', 'rẹ̀', 'yóò', 'fi', 'wá', 'sí', 'ìmúṣẹ', '.']\n",
            " ['Ẹnikẹ́ni', 'ti', 'ó', 'bá', 'rú', 'òfin', 'tí', 'ó', 'tilẹ̀', 'kéré', 'jù', 'lọ', ',', 'tí', 'ó', 'sì', 'kọ́', 'ẹlòmíràn', 'láti', 'ṣe', 'bẹ́ẹ̀', ',', 'òun', 'ni', 'yóò', 'kéré', 'jù', 'lọ', 'ní', 'ìjọba', 'ọ̀run', ',', 'ṣùgbọ́n', 'ẹni', 'tí', 'ó', 'bá', 'ń', 'ṣe', 'wọ́n', ',', 'tí', 'ó', 'sì', 'ń', 'kọ́', 'wọn', ',', 'ni', 'yóò', 'jẹ́', 'ẹni', 'ńlá', 'ní', 'ìjọba', 'ọ̀run', '.']\n",
            " ['Nítorì', 'náà', 'ni', 'mọ', 'ti', 'wí', 'fún', 'yín', 'pé', 'àfi', 'bí', 'òdodo', 'yín', 'bá', 'ju', 'ti', 'àwọn', 'Farisí', 'àti', 'ti', 'àwọn', 'olùkọ́', 'òfin', 'lọ', ',', 'dájúdájú', 'ẹ̀yin', 'kì', 'yóò', 'le', 'wọ', 'ìjọba', 'ọ̀run', '.']\n",
            " ['“', 'Ẹ̀yin', 'ti', 'gbọ́', 'bí', 'a', 'ti', 'wí', 'fún', 'àwọn', 'ará', 'ìgbàanì', 'pé', ',', '‘', 'Ìwọ', 'kò', 'gbọdọ̀', 'pa', 'ènìyàn', ',', 'ẹnikẹni', 'tí', 'ó', 'bá', 'pa', 'ènìyàn', 'yóò', 'wà', 'nínú', 'ewu', 'ìdájọ́', '.', '’']\n",
            " ['Ṣùgbọ́n', 'èmi', 'wí', 'fún', 'un', 'yín', 'pé', ',', 'ẹnikẹ́ni', 'tí', 'ó', 'bínú', 'sí', 'arákùnrin', 'rẹ̀', 'yóò', 'wà', 'nínú', 'ewu', 'ìdájọ́', '.', 'Ẹnikẹ́ni', 'ti', 'ó', 'ba', 'wí', 'fun', 'arakùnrin', 'rẹ̀', 'pé', ',', '‘', 'Ráákà', '’', 'yóò', 'fara', 'hàn', 'níwájú', 'Sahẹ́ńdìrì', ';', 'ṣùgbọ́n', 'ẹni', 'tí', 'ó', 'bá', 'wí', 'pé', '‘', 'Ìwọ', 'wèrè', '!', '’', 'yóò', 'wà', 'nínú', 'ewu', 'iná', 'ọ̀run', 'àpáàdì', '.']\n",
            " ['“', 'Nítorí', 'náà', ',', 'nígbà', 'tí', 'ìwọ', 'bá', 'ń', 'mú', 'ẹ̀bùn', 'rẹ', 'wá', 'ṣíwájú', 'pẹpẹ', ',', 'bí', 'ìwọ', 'bá', 'sì', 'rántí', 'níbẹ̀', 'pé', 'arákùnrin', 'rẹ̀', 'ni', 'ohùn', 'kan', 'nínú', 'sí', 'ọ', '.']\n",
            " ['Fi', 'ẹ̀bùn', 'rẹ', 'sí', 'ilẹ̀', 'níwájú', 'pẹpẹ', '.', 'Ìwọ', 'kọ́kọ́', 'lọ', 'ṣe', 'ìlàjà', 'láàrin', 'ìwọ', 'àti', 'arákùnrin', 'rẹ̀', 'na', '.', 'Lẹ́yìn', 'náà', ',', 'wá', 'kí', 'ó', 'sì', 'fi', 'ẹ̀bùn', 'rẹ', 'sí', 'ilẹ̀', '.']\n",
            " ['“', 'Bá', 'ọ̀tá', 'rẹ', 'làjà', 'kánkán', ',', 'ẹni', 'tí', 'ó', 'ń', 'gbé', 'ọ', 'lọ', 'sí', 'ilé', 'ẹjọ́', '.', 'Ṣe', 'é', 'nígbà', 'ti', 'ó', 'wà', 'ní', 'ọ̀nà', 'pẹ̀lú', 'rẹ', ',', 'bí', 'bẹ́ẹ̀', 'kọ́', 'yóò', 'fà', 'ọ́', 'lé', 'onídajọ', 'ní', 'ọwọ́', ',', 'onídájọ́', 'yóò', 'sí', 'fá', 'ọ', 'lé', 'àwọn', 'ẹ̀sọ́', 'ní', 'ọwọ́', ',', 'wọ́n', 'a', 'sì', 'sọ', 'ọ́', 'sínú', 'túbú', '.']\n",
            " ['Lóòótọ', 'ni', 'mo', 'wí', 'fún', 'ọ', ',', 'ìwọ', 'kì', 'yóò', 'jáde', 'kúrò', 'níbẹ̀', 'títítí', 'ìwọ', 'yóò', 'fi', 'san', 'ẹyọ', 'owó', 'kan', 'tí', 'ó', 'kù', '.']\n",
            " ['“', 'Ẹ̀yin', 'ti', 'gbọ́', 'bí', 'òfin', 'ti', 'wí', 'pé', ',', '‘', 'Ìwọ', 'kò', 'gbọdọ̀', 'ṣe', 'panṣágà', '.', '’']\n",
            " ['Ṣùgbọ́n', 'mo', 'wí', 'fún', 'yín', 'pé', ',', 'ẹnikẹ́ni', 'tí', 'ó', 'bá', 'wo', 'obìrinrin', 'kan', 'ní', 'ìwòkuwò', ',', 'ti', 'bà', 'a', 'ṣe', 'panṣágà', 'ná', 'ní', 'ọkàn', 'rẹ̀', '.']\n",
            " ['Bí', 'ojú', 'rẹ', 'ọ̀tún', 'bá', 'mú', 'ọ', 'dẹ́sẹ̀', ',', 'yọ', 'ọ́', 'jáde', ',', 'kí', 'ó', 'sì', 'sọ', 'ọ́', 'nù', '.', 'Ó', 'sàn', 'kí', 'ẹ̀ya', 'ara', 'rẹ', 'kan', 'ṣègbé', ',', 'ju', 'kí', 'a', 'gbé', 'gbogbo', 'ara', 'rẹ', 'jù', 'sínú', 'iná', 'ọ̀run', 'àpáàdì', '.']\n",
            " ['Bí', 'ọwọ́', 'rẹ', 'ọ̀tún', 'bá', 'mú', 'ọ', 'dẹ́ṣẹ̀', 'gé', 'e', 'kúrò', ',', 'kí', 'ó', 'sì', 'sọ', 'ọ́', 'nù', '.', 'Ó', 'sàn', 'kí', 'ẹ̀ya', 'ara', 'rẹ', 'kan', 'ṣègbé', 'ju', 'kí', 'gbogbo', 'ara', 'rẹ', 'lọ', 'sínú', 'iná', 'ọ̀run', 'àpáàdì', '.']\n",
            " ['“', 'A', 'ti', 'wí', 'pẹ̀lú', 'pé', ',', '‘', 'Ẹnikẹ́ni', 'tí', 'ó', 'bá', 'kọ', 'aya', 'rẹ̀', 'sí', 'ilẹ̀', 'gbọdọ̀', 'fún', 'un', 'ní', 'ìwé', '-', 'ẹ̀rí', 'ìkọ̀sílẹ̀', '.', '’']\n",
            " ['Ṣùgbọ́n', 'mo', 'wí', 'fún', 'yín', 'pé', ',', 'ẹnikẹ́ni', 'tí', 'ó', 'bá', 'kọ', 'aya', 'rẹ̀', ',', 'àfi', 'nítorí', 'àgbèrè', ',', 'mú', 'un', 'se', 'àgbèrè', ',', 'ẹnikẹ́ni', 'tí', 'ó', 'bá', 'sì', 'fẹ́', 'obìnrin', 'tí', 'a', 'kọ̀', 'sí', 'ilẹ̀', 'ní', 'ìyàwó', 'ṣe', 'àgbèrè', '.']\n",
            " ['“', 'Ẹ̀yin', 'ti', 'gbọ́', 'bí', 'a', 'ti', 'wí', 'fún', 'àwọn', 'ará', 'ìgbàani', 'pé', ';', '‘', 'Ìwọ', 'kò', 'gbọdọ̀', 'búrá', 'èké', 'bí', 'kò', 'ṣe', 'pé', 'kí', 'ìwọ', 'kí', 'ó', 'mú', 'ìbúra', 'rẹ̀', 'sí', 'Olúwa', 'ṣẹ', '.', '’']\n",
            " ['Ṣùgbọ́n', 'èmi', 'wí', 'fún', 'yín', ',', 'Ẹ', 'má', 'ṣe', 'búra', 'rárá', ',', ':', 'ìbáà', 'ṣe', 'ìfi', '-', 'ọ̀run', '-', 'búra', ',', 'nítorí', 'ìtẹ́', 'Ọlọ́run', 'ni', '.']\n",
            " ['Tàbí', 'ìfi', '-', 'ayé', '-', 'búra', ',', 'nítorí', 'àpótí', 'ìtìsẹ̀', 'Ọlọ́run', 'ni', ';', 'tàbí', 'Jerúsálémù', ',', 'nítorí', 'olórí', 'ìlú', 'Ọba', 'Ńlá', 'ni', '.']\n",
            " ['Má', 'ṣe', 'fi', 'orí', 'rẹ', 'búra', ',', 'nítorí', 'ìwọ', 'kò', 'lè', 'sọ', 'irun', 'ẹyọ', 'kan', 'di', 'funfun', 'tàbí', 'di', 'dúdú', '.']\n",
            " ['Ẹ', 'jẹ́', 'kí', 'bẹ́ẹ̀', 'ni', 'yín', 'jẹ́', 'bẹ́ẹ̀', 'ni', 'àti', 'bẹ́ẹ̀', 'kọ́', 'yín', 'jẹ́', 'bẹ́ẹ̀', 'kọ́', ',', 'ohunkóhun', 'tí', 'ó', 'ba', 'ju', 'ìwọ̀nyí', 'lọ', ',', 'wá', 'láti', 'ọ̀dọ̀', 'ẹni', 'ibi', '.']\n",
            " ['“', 'Ẹ̀yin', 'tí', 'gbọ́', 'bí', 'òfin', 'tí', 'wí', 'pé', ',', '‘', 'Ojú', 'fún', 'ojú', 'àti', 'eyín', 'fún', 'eyín', '.', '’']\n",
            " ['Ṣùgbọ́n', 'èmi', 'wí', 'fún', 'yín', 'pé', ',', '‘', 'Ẹ', 'má', 'ṣe', 'tako', 'ẹni', 'ibi', '.', 'Bí', 'ẹnì', 'kan', 'bá', 'gbá', 'ọ', 'ní', 'ẹ̀rẹ̀kẹ́', 'ọ̀tún', ',', 'yí', 'ẹ̀rẹ̀kẹ́', 'òsì', 'sí', 'olúwa', 'rẹ̀', 'pẹ̀lú', '.']\n",
            " ['Bí', 'ẹnì', 'kan', 'bá', 'fẹ́', 'gbé', 'ọ', 'lọ', 'sí', 'ilé', 'ẹjọ́', ',', 'tí', 'ó', 'sì', 'fẹ́', 'gba', 'ẹ̀wù', 'àwọ̀tẹ́lẹ̀', ',', 'jọ̀wọ́', 'agbádá', 'rẹ', 'fún', 'un', 'pẹ̀lú', '.']\n",
            " ['Bí', 'ẹni', 'kan', 'bá', 'fẹ́', 'fi', 'agbára', 'mú', 'ọ', 'rìn', 'ibùsọ̀', 'kan', ',', 'bá', 'a', 'lọ', 'ní', 'ibùsọ̀', 'méjì', '.']\n",
            " ['Fi', 'fún', 'àwọn', 'tí', 'ó', 'béèrè', 'lọ́wọ́', 'rẹ', ',', 'má', 'ṣe', 'kọ̀', 'fún', 'ẹni', 'tí', 'ó', 'fẹ́', 'ya', 'láti', 'lọ́wọ́', 'rẹ', '.']\n",
            " ['“', 'Ẹ̀yin', 'ti', 'gbọ́', 'bí', 'òfin', 'ti', 'wí', 'pé', ',', '‘', 'Fẹ́ràn', 'aládúgbo', 'rẹ', ',', 'kí', 'ìwọ', 'sì', 'kórírà', 'ọ̀ta', 'rẹ̀', '.', '’']\n",
            " ['Ṣùgbọ́n', 'èmi', 'wí', 'fún', 'yín', 'pé', ',', 'ẹ', 'fẹ́ràn', 'àwọn', 'ọ̀ta', 'yín', 'kí', 'ẹ', 'sì', 'gbàdúrà', 'fún', 'àwọn', 'tí', 'ń', 'ṣe', 'inúnibíni', 'sí', 'yín', ',']\n",
            " ['Kí', 'ẹ̀yin', 'lè', 'jẹ́', 'ọmọ', 'Baba', 'yín', 'bi', 'ń', 'bẹ', 'ní', 'ọ̀run', '.', 'Ó', 'mú', 'kí', 'oòrùn', 'rẹ̀', 'ràn', 'sí', 'ara', 'ènìyàn', 'búburú', 'àti', 'ènìyàn', 'rere', ',', 'ó', 'rọ̀jò', 'fún', 'àwọn', 'olódodo', 'àti', 'fún', 'àwọn', 'aláìṣòdodo', '.']\n",
            " ['Bí', 'ẹ̀yin', 'bá', 'fẹ́ràn', 'àwọn', 'tí', 'ó', 'fẹ́ràn', 'yín', 'nìkan', ',', 'èrè', 'kí', 'ni', 'ẹ̀yin', 'ní', '?', 'Àwọn', 'agbowó', '-', 'òde', 'kò', 'ha', 'ń', 'ṣe', 'bẹ́ẹ̀', 'gẹ́gẹ́', '?']\n",
            " ['Àti', 'bí', 'ó', 'bá', 'sì', 'jẹ́', 'pé', 'kìkì', 'àwọn', 'arákùnrin', 'yín', 'nìkan', 'ni', 'ẹ̀yin', 'ń', 'kí', ',', 'kín', 'ni', 'ẹ̀yin', 'ń', 'ṣe', 'ju', 'àwọn', 'mìíràn', '?', 'Àwọn', 'abọ̀rìṣà', 'kò', 'ha', 'ń', 'ṣe', 'bẹ́ẹ̀', 'bí', '?']\n",
            " ['Nítorí', 'náà', ',', 'ẹ', 'jẹ́', 'pípé', ',', 'gẹ́gẹ́', 'bí', 'Baba', 'yín', 'tí', 'ń', 'bẹ', 'ní', 'ọ̀run', 'ṣe', 'jẹ́', 'pípé', '.']\n",
            " ['Olúwa', 'àyà', 'mí', 'kò', 'gbéga', 'bẹ́ẹ̀', 'ní', 'ojú', 'mi', 'kò', 'gbé', 'sókè', ':', 'bẹ́ẹ̀', 'ni', 'èmi', 'kò', 'fi', 'ọwọ́', 'mi', 'lé', 'ọ̀ràn', 'ńlá', ',', 'tàbí', 'lé', 'ohun', 'tí', 'ó', 'ga', 'jù', 'mí', 'lọ']\n",
            " ['Nítòótọ́', 'èmi', 'mú', 'ọkàn', 'mi', 'sinmi', ',', 'mo', 'sì', 'mú', '-', 'un', 'dákẹ́jẹ́ẹ́', ',', 'bí', 'ọmọ', 'tí', 'a', 'fi', 'ọwọ', 'ìyá', 'Rẹ̀', 'gbà', 'ní', 'ẹnu', 'ọmú', ':', 'ọkàn', 'mí', 'rí', 'gẹ́gẹ́', 'bí', 'ọmọ', 'tí', 'a', 'já', 'ní', 'ẹnu', 'ọmú', '.']\n",
            " ['Ísírẹ́lì', ',', 'ìwọ', 'ní', 'ìrètí', 'ní', 'ti', 'Olúwa', 'láti', 'ìsinsinyí', 'lọ', 'àti', 'láéláé', '.']\n",
            " ['Kíyèsí', ',', 'ó', 'ti', 'dára', 'ó', 'sì', 'ti', 'dùn', 'tó', 'fún', 'àwọn', 'ará', 'láti', 'máa', 'jùmọ̀', 'gbé', 'ní', 'ìrẹ́pọ̀', '.']\n",
            " ['Ó', 'dàbí', 'òróró', 'ìkúnra', 'iyebíye', 'ní', 'orí', ',', 'tí', 'ó', 'ṣàn', 'dé', 'irungbọ̀n', ',', 'àní', 'irungbọ̀n', 'Árónì', ':', 'tí', 'ó', 'sì', 'ṣàn', 'sí', 'etí', 'aṣọ', 'sórí', 'Rẹ̀', ';']\n",
            " ['Bí', 'irì', 'Hémónì', 'tí', 'o', 'ṣàn', 'sórí', 'òke', 'Síónì', ':', 'nítorí', 'níbẹ̀', 'ní', 'Olúwa', 'gbé', 'pàṣẹ', 'ìbùkún', ',', 'àni', 'ìyè', 'láéláé', '.']\n",
            " ['Ẹ', 'kíyèsí', 'i', ',', 'ẹ', 'fi', 'ìbùkún', 'fún', 'Olúwa', ',', 'gbogbo', 'ẹ̀yin', 'ìránṣẹ́', 'Olúwa', ',', 'tí', 'ó', 'dúró', 'ní', 'ilé', 'Olúwa', 'ní', 'òru', '.']\n",
            " ['Ẹ', 'gbé', 'ọwọ́', 'yín', 'sókè', 'sí', 'ibi', 'mímọ́', ',', 'kí', 'ẹ', 'sì', 'fi', 'ìbùkún', 'fún', 'Olúwa', '.']\n",
            " ['Olúwa', 'tí', 'ó', 'dá', 'ọ̀run', 'Òun', 'ayé', ',', 'kí', 'ó', 'bùsí', 'i', 'fún', 'ọ', 'láti', 'Síónì', 'wá', '.']\n",
            " ['Ẹ̀gbà', 'ọrùn', 'bí', 'ìbòju', 'tí', 'Benin', 'jẹ́', 'ẹ̀gbà', 'ọrùn', 'tí', 'wọ́n', 'gbẹ́', 'lére', 'tí', 'ó', 'sì', 'jẹ́', 'àwòrán', 'akọni', 'obìrin', 'tí', 'a', 'mọ̀', 'si', 'ìyá', 'wa', 'Olorì', 'Idia', 'ti', 'ọ̀rundún', 'mẹ́rìndínlógún', 'ṣẹ́yìn', '.']\n",
            " ['Ọmọ', 'rẹ̀', 'Esigie', 'tí', 'ó', 'jẹ́', 'ọba', 'ti', 'Benin', 'maa', 'ń', 'wọ́', 'èyí', 'tí', 'ó', 'jọọ́', 'fún', 'àwọn', 'ọmọ', 'ogun', 'ẹ̀yìn', 'ìya', 'olorì', '.']\n",
            " ['Ibojú', 'yìí', 'pé', 'méjì', 'tí', 'ó', 'jọ', 'ara', 'wọn', ':', 'Ìkan', 'wà', 'ní', 'Ilé', 'ọnà', 'ti', 'a', 'mọ̀', 'sí', 'British', 'Museum', 'ní', 'ìlú', 'London', 'tí', 'ìkejì', 'sì', 'wà', 'ní', 'ilé', 'ọnà', 'tí', 'a', 'mọ̀', 'sí', 'Metropolitan', 'Museum', 'of', 'Art', 'ní', 'ìlú', 'New', 'York', '.']\n",
            " ['Àwọn', 'àpẹẹrẹ', 'rẹ̀', 'lórí', 'àkọ́lé', 'kan', 'náà', 'wà', 'ní', 'Seattle', 'Art', 'Museum', 'àti', 'Linden', 'Museum', ',', 'tí', 'ìkan', 'ná', 'sì', 'wà', 'ní', 'ilé', 'ibi', 'tí', 'wọ́n', 'kò', 'gba', 'òpò', 'eniyan', 'láyè', 'láti', 'wọ̀', ',', 'gbogbo', 'rẹ̀', 'ní', 'wọ́n', 'kó', 'nígbà', 'ìwádí', 'lọ', 'sí', 'ìlú', 'Benin', 'ní', 'ọdún', '1897', '.']\n",
            " ['Ìbojú', 'yìí', 'ti', 'di', 'àmì', 'ìdánimọ̀', 'lóde', 'òní', 'ní', 'orílẹ̀', 'èdè', 'Nàìjíríà', 'láti', 'ìgbà', 'ìpéjọ', '-', 'pọ̀', 'kan', 'tí', 'a', 'mọ̀', 'sí', 'FESTA', 'C', '77', 'tí', 'ó', 'wáyé', 'ní', 'ọdún', '1977', '.']\n",
            " ['Ìrísí', 'àti', 'Ìwúlò', 'rẹ̀', '.']\n",
            " ['Bí', 'ó', 'tilẹ̀', 'jẹ́', 'wípé', 'ó', 'ní', 'ìrísí', 'èyí', 'tí', 'ó', 'jọ', 'Ìbojú', 'Ìbílẹ̀', 'Aláwọ̀dúdú', ',', 'ībòjú', 'kékeré', 'òhún', 'tí', 'kò', 'gígùn', 'rẹ̀', 'kò', 'ju', 'ìwòn', '24cm', 'lọ', 'kìí', 'ṣé', 'fún', 'wíwọ̀', 'sójú', ',', 'Ọba', 'lè', 'wọ̀ọ́', 'sọ́rùn', '(', 'tí', 'ó', 'sì', 'maa', 'bá', 'mu', ')', 'tàbí', 'bi', '\"', 'ìlẹ̀kẹ̀', 'ìbàdí', '\"', '(', 'èyí', 'tí', 'ó', 'sì', 'maa', 'bá', 'ayẹyẹ', 'tí', 'ó', 'fẹ́', 'sẹe', 'mu', ')', '.']\n",
            " ['Èyí', 'tí', 'ó', 'wà', 'ní', 'ilé', 'ọnà', 'Met', 'àti', 'èyí', 'tí', 'ó', 'wà', 'ní', 'ilé', 'ọnà', 'British', 'fẹ́', 'jọ', 'ara', 'wọn', ',', 'méjèèjì', 'ni', 'ó', 'jẹ́', 'àwòràn', 'Olorì', 'Idia', '.']\n",
            " ['Wọn', 'dárà', 'ìlẹ̀kẹ̀', 'si', 'lórí', ',', 'lọ́rùn', ',', 'ègbẹ́', 'níwájú', 'orí', 'àti', 'gbígbẹ́', 'èyí', 'tí', 'ó', 'fàyè', 'ọ̀nà', 'méjì', 'tí', 'wọ́n', 'lè', 'fi', 'ẹ̀gbà', 'kọ́', '.']\n",
            " ['Lóde', 'òní', 'àwọn', 'ènìyàn', 'máa', 'ń', 'gbé', 'onírú', 'irú', 'àworan', 'tí', 'ó', 'jọ́ọ', 'níbi', 'ayẹyẹ', 'láti', 'lé', 'ẹbọra', 'búrúkú', ',', 'ṣùgbọ́n', 'ní', 'bí', 'ọrundún', 'mẹ́rìndínlógún', 'sẹ́yìn', ',', 'wọ́n', 'lè', 'maa', 'lòó', 'fún', 'ayẹyẹ', 'ìya', 'ọba', '.']\n",
            " ['Ó', 'dàbí', 'wípé', 'ní', 'bí', 'ìbẹ̀rẹ̀', 'ọrúndún', 'mẹ́rìndínlógún', 'sẹ́yìn', 'ni', 'wọ́n', 'gbẹ́', 'àwọn', 'Ìbòjú', 'méjèèjì', ',', 'bóya', 'ní', 'ọdún', '1520', ',', 'nígbà', 'tí', 'Olorì', 'Idia', ',', 'ìyá', 'ọba', 'Oba', 'Esigie', ',', 'jẹ́', 'aládájọ́', 'ní', 'ilé', 'ẹjọ́', 'ti', 'Benin', '.']\n",
            " ['Akọni', 'obìnrin', '.']\n",
            " ['Irú', 'àwòrán', 'yìí', 'kò', 'wọ́pọ̀', 'ní', 'iṣẹ́', 'ọnà', 'ilẹ̀', 'Benin', ',', 'àti', 'pé', 'ipò', 'Idia', ',', 'tí', 'iṣẹ̀ṣe', 'àwọn', 'Edo', 'mọ̀', 'sí', '\"', 'obìnrin', 'kan', 'ṣoṣo', 'tó', 'lọ', 'sógun', '\"', ',', 'tí', 'ó', 'da', 'yàtọ̀', ',', 'tí', 'wọ́n', 'sí', 'dá', 'oyèIyoba', 'tàbí', 'Ìyá', 'Olori', '̀́n', 'sílẹ̀', 'fun', 'Ìwérí', 'rẹ̀', 'jẹ́', 'ara', 'irú', 'irun', 'tí', 'wọ́n', 'ń', 'pè', 'ní', 'ẹnu', 'àparò', ',', 'tí', 'a', 'lè', 'rí', 'dáadára', 'ní', 'àfihàn', 'orí', 'edẹ', 'Olorì', 'Idia', '.']\n",
            " ['Ìwérí', 'rẹ̀', 'tí', 'ó', 'rẹwà', 'àti', 'ìlẹ̀kẹ̀', 'ọrùn', 'rẹ̀', 'bí', 'ìlẹ̀kẹ̀', 'roboto', '(', '\"', 'ọlà', '\"', ')', ',', 'tí', 'wọ́n', 'fún', 'ìya', 'wa', 'olorì', 'láàfàní', 'láti', 'máa', 'wọ̀', ',', 'léyí', 'tí', 'ó', 'jẹ́', 'pé', 'olóyè', 'ni', 'ówà', 'fún', '.']\n",
            " ['Ìlẹ̀kẹ̀', 'pupa', 'yìí', 'àti', 'aṣọ', 'pupa', ',', 'ti', 'fìgbàkan', 'wà', 'fún', 'àwọn', 'olókìkí', ',', 'tí', 'wọ́n', 'sì', 'ti', 'ri', 'lóde', 'òní', 'gẹ́gẹ́', 'bi', 'ara', 'imùra', 'ìbílẹ̀', 'ní', 'Edo', '.']\n",
            " ['Ní', 'iwájú', 'orí', 'ìbòjú', 'méjì', 'yìí', ',', 'ìlà', 'mẹ́rin', 'wà', 'níbẹ̀', ',', 'tí', 'ó', 'sì', 'dúro', 'ṣangílítí', 'sí', 'òkè', 'ojú', 'kànkan', ',', 'irin', 'méjì', 'sì', 'ṣe', 'àpèjúwe', 'ilà', 'yìí', '.']\n",
            " ['Irin', 'ni', 'wọ́n', 'fi', 'ṣe', 'ibi', 'ojú', 'rẹ̀', '.']\n",
            " ['Àmì', 'fún', 'okùn', 'òwò', '.']\n",
            " ['Ibi', 'funfun', 'ìwò', 'ẹ̀fọ̀', 'tí', 'wọ́n', 'fi', 'ṣe', 'ìwòjú', 'yìí', 'jẹ́', 'àpẹẹrẹ', 'òòṣà', 'Olokun', '.']\n",
            " ['Bí', 'ó', 'ṣe', 'rí', 'yìí', ',', 'kò', 'wọ́n', 'nìkan', 'nítórí', 'wọ́n', 'lọ', 'ìwo', 'ẹfọ̀', 'tí', 'ó', 'wúlò', 'tí', 'ó', 'sì', 'ṣeétà', 'lówó', 'gọbọhi', ',', 'ṣùgbọ́n', 'àwọ̀', 'rẹ̀', 'tún', 'jẹ́', 'àpẹ́ẹrẹ', 'òòṣà', 'tí', 'ó', 'ní', 'ṣ', 'pẹ̀lú', 'olá', 'Oba', 'Benin', '.']\n",
            " ['Ihò', 'tí', 'ó', 'wà', 'ní', 'ibi', 'oun', 'ẹ̀ṣọ́', 'rẹ̀', 'àti', 'ibi', 'ọrùn', 'rẹ̀', 'jẹ́', 'àpẹẹrẹ', 'ìlẹ̀kẹ̀', 'ọrùn', 'tí', 'àwọn', 'ọkùnrin', 'Àgùdà', 'maa', 'ń', 'fi', 'ṣẹ̀ṣọ́', ',', 'tí', 'ó', 'sì', 'jẹ́', 'wípé', 'àwòrán', 'mọ́kànlá', 'bẹ́ẹ̀', 'wà', 'ní', 'ilé', 'ọnà', 'ìbòjú', 'tí', 'Bìrìtìkó', 'àti', 'pé', 'mẹ́tàlá', 'wà', 'ní', 'ilé', 'ọnà', 'Met', 'tí', 'ó', 'ṣe', 'àfihàn', 'àwọn', 'ọkùnrin', 'Àgùdá', 'tí', 'wọ́n', 'múra', 'bí', 'àwọn', 'ènìyàn', 'dúdú', '.']\n",
            " ['Orùn', 'ìwòjú', 'tí', 'ó', 'wà', 'ní', 'ilé', 'ọnà', 'Metropolitant', '(', 'Met', ')', 'jọ', 'mọ́', 'èyí', 'tí', 'wọ́n', 'fi', 'àwọn', 'ọkùnrin', 'Àgùdà', 'ṣẹ̀ṣọ́', 'rẹ̀', '(', 'ẹ̀gbẹ́', 'rẹ̀', 'ti', 'bàjẹ́', 'díẹ̀', ')', ',', 'Bí', 'ó', 'tilẹ̀', 'jẹ́', 'pé', ',', 'ọrùn', 'ìwòjú', 'èyí', 'tí', 'ó', 'wà', 'ní', 'ilé', 'ọnà', 'Bìrìtìkó', 'jẹ́', 'èyí', 'tí', 'wọ́n', 'fi', 'igi', 'tàbí', 'irin', 'gbẹ́', '.']\n",
            " ['Àwọn', 'Àgùdà', 'jẹ́', 'oníṣòwò', 'pẹ̀lú', 'àwọn', 'Benin', 'nígbàyẹn', 'gẹ́gẹ́', 'bí', 'wọ́n', 'ti', 'ṣàpèjúwe', 'rẹ̀', ',', 'ó', 'jẹ́', 'àpẹrẹ́', 'àjọṣepọ̀', 'láàrin', 'omi', 'àti', 'ilẹ̀', '.']\n",
            " ['Ẹ', 'ti', 'tẹ̀lé', 'ìjápọ̀', 'mọ́', 'ojúewé', 'tí', 'kò', 'sí', '.']\n",
            " ['Láti', 'dá', 'ojúewé', 'yí', 'ẹ', 'bẹ̀rẹ̀', 'síní', 'tẹ́kọ', 'sí', 'inú', 'àpótí', 'ìsàlẹ̀', 'yí', '(', 'ẹ', 'wo', 'ojúewé', 'ìrànlọ́wọ́', 'fun', 'ẹ̀kúnrẹ́rẹ́', ')', '.']\n",
            " [\"T'\", 'óbá', 'sepé', 'àsìse', 'ló', 'gbé', 'yin', 'dé', 'bi', ',', 'ẹ', 'kọn', 'bọ́tìnì', 'ìpadàsẹ́yìn', '.']\n",
            " ['O', 'órúkọ', 'dàbí', 'àmì', 'ìdánimọ̀', 'tí', 'a', 'fi', 'ń', 'dá', 'ẹnìkọ̀ọ̀kan', 'mọ̀', 'o', 'órúkọ', 'ló', 'jẹ́', 'kí', 'á', 'dá', 'Táyé', 'mọ̀', 'yàtọ̀', 'sí', 'Kẹ́hìndé', ',', 'káàkiri', 'àgbáyé', 'ní', 'a', 'sì', 'tí', 'ń', 'lo', 'o', 'órúkọ', ',', 'ní', 'ọ̀pọ̀', 'ìgbà', 'o', 'órúkọ', 'sì', 'máa', 'ń', 'fi', 'bí', 'ènìyàn', 'ṣe', 'jẹ́', 'láwùjọ', 'hàn', 'àti', 'wí', 'pe', 'o', 'órúkọ', 'ẹni', 'le', 'buyì', 'fún', 'ènìyàn', 'láwùjọ', '.']\n",
            " ['Ìṣọmọlí', 'órúkọ', 'láàárín', 'àwọn', 'Yorùbá', 'dàbí', 'ìgbà', 'tí', 'a', 'ń', 'ṣe', 'ọdún', 'ní', 'torí', 'pé', 'tọmọ', ',', 'taya', ',', 'tẹbí', ',', 'tará', ',', 'tìyekan', 'àti', 'àwọn', 'alábáse', 'gbogbo', 'ní', 'yóò', 'pésẹ̀', 'sí', 'ibẹ̀', '.']\n",
            " ['Láyé', 'àtijọ́', 'ọjọ́', 'keje', 'ní', 'wọ́n', 'máa', 'ń', 'sọ', 'ọmọ', 'obìnrin', 'ní', 'órúkọ', 'nígbà', 'tí', 'tọmọ', 'kùnrin', 'sì', 'jẹ́', 'ọjọ́', 'kẹsàn', '-', 'án', 'èyí', 'wà', 'ní', 'ìbámu', 'pẹ̀lú', 'èrò', 'àti', 'ìgbàgbọ́', 'wọn', 'pé', 'eegun', 'méje', 'ni', 'obìnrin', 'ní', 'nígbà', 'tí', 'tọkùnrin', 'jẹ́', 'mẹ́sàn-án', '.']\n",
            " ['ṣùgbọ́n', 'lóde', '-', 'òní', 'ohun', 'gbogbo', 'ti', 'yí', 'padà', 'àti', 'obìnrin', 'àti', 'ọkùnrin', 'ni', 'wọ́n', 'ń', 'sọ', 'ní', 'órúkọ', 'lọ́jẹ́', 'kẹjọ', '.']\n",
            " ['Bí', 'a', 'ṣe', 'ń', 'ṣe', 'ìṣọmọlí', 'órúkọ', 'yàtọ̀', 'láti', 'idílẹ́', 'sí', 'ìdílé', 'ṣùgbọ́n', 'ní', 'ọjọ́', 'ìṣọmọlí', 'órúkọ', 'yìí', 'àgbà', 'ilé', 'lóbìnrin', 'yóò', 'gbé', 'ọmọ', 'yìí', 'lọ́wọ́', 'yóò', 'sì', 'fí', 'ẹsẹ̀', 'rẹ̀', 'tẹ', 'ilẹ̀', '.']\n",
            " ['Orísìírísìí', 'nǹkan', 'ní', 'wọ́n', 'ń', 'lò', 'níbi', 'ìsọmọlí', 'órúkọ', 'bíi', 'Oyin', ',', 'Epo', ',', 'Iṣu', ',', 'Ẹja', ',']\n",
            " ['Iyọ̀', ',', 'Omi', ',', 'abbl', 'láti', 'jẹ́', 'kí', 'ọmọ', 'yìí', 'mọ', 'bí', 'ayé', 'se', 'rí', 'wọn', 'yóò', 'fí', 'gbogbo', 'ohun', 'tí', 'a', 'kà', 'sókè', 'yìí', 'tọ́', 'ọmọ', 'lẹ́nu', 'wò', ',', 'wọ́n', 'sì', 'máa', 'ń', 'wọ́n', 'omi', 'sí', 'ọmọ', 'yìí', 'lára', 'tàbí', 'kí', 'wọ́n', 'da', 'omi', 'sí', 'orí', 'páànù', 'kí', 'wọn', 'ó', 'wá', 'jẹ́', 'kí', 'ó', 'kán', 'si', 'ọmọ', 'yìí', 'lára', '.']\n",
            " ['O', 'órúkọ', 'dabí', 'fèrèsé', 'tí', 'ó', 'fi', 'ÀṢÀ,', 'Èsìn', ',', 'Iṣé', 'àti', 'ìgbàgbọ́', 'àwọn', 'Yorùbá', 'hàn', '.']\n",
            " ['Oríṣìíríṣìí', 'nǹkan', 'la', 'fi', 'ń', 'sọmọ', 'ní', 'órúkọ', 'bíi', 'OYIN,', 'EPO', ',', 'IYỌ', ',', 'ẸJA', ',', 'OMI', 'abbl', '.']\n",
            " ['Oríṣìíríṣìí', 'nǹkan', 'ló', 'le', 'yọrí', 'sí', 'o', 'órúkọ', 'tí', 'a', 'sọ', 'ọmọ', '.']\n",
            " ['Genevieve', 'Nnaji', 'ọjọ́', 'ìbí', 'May', '3', ',', '1979', 'ní', 'Mbaise', ',', 'Ipinle', 'Imo', ',', 'jẹ́', 'òṣeré', 'filmu', 'ọmọ', 'ilẹ̀', 'Nàìjíríà', '.']\n",
            " ['Ní', '2005', 'ó', 'gba', 'Ẹ̀bùn', 'Akadẹ́mì', 'Filmu', 'ilẹ̀', 'Áfríkà', 'gẹ́gẹ́', 'bíi', 'Òṣeré', 'Obìnrin', 'Dídárajùlọ', '.']\n",
            " ['Ìgbà', 'èwe', ':', 'Ìlú', 'Èkó', 'ni', 'Genevieve', 'Nnaji', 'ti', 'dàgbà', '.']\n",
            " ['Ìkẹrin', 'nínú', 'àwọn', 'ọmọ', 'méjọ', ',', 'ọ̀mọ̀wé', 'ni', 'àwọn', 'òbí', 'rẹ̀', '.']\n",
            " ['Bàbá', 'rẹ̀', 'siṣẹ́', 'gẹ́gẹ́', 'bíi', 'onímọ̀', 'iṣẹ́', '-', 'ẹ̀rọ', '(', 'engineer)', 'nígbàtí', 'ìyá', 'rẹ̀', 'sì', 'jẹ́', 'olùkọ́', '.']\n",
            " ['Ò', 'lọ', 'sí', 'ilé', 'ẹ̀kọ́', 'Methodist', 'Girls', 'College', 'ní', 'Yaba', ',', 'lẹ́yìn', 'rẹ̀', 'ó', 'tẹrísí', 'Yunifásítì', 'ìlú', 'Èkó', '.']\n",
            " ['Níbẹ̀', 'lówà', 'tó', 'ti', 'bẹ̀rẹ̀', 'sí', 'ní', 'ṣiṣẹ́', 'díèdíẹ̀', 'gẹ́gẹ́', 'bíi', 'òṣèré', 'ni', 'Nollywood', '.']\n",
            " ['Nnaji', 'bẹ̀rẹ̀', 'ìṣèré', 'rẹ̀', 'láti', 'ọmọdé', 'ninu', 'eré', 'tẹlifísọ̀n', 'Ripples', 'nígbà', 'tójẹ́', 'ọmọ', 'ọdún', '8', '.']\n",
            " ['Ó', 'tún', 'ṣe', 'ìpolówó', 'ọjà', 'bíi', 'méèló', 'kan', 'nínú', 'èyí', 'tó', 'jẹ́', 'fún', 'Pronto', 'àti', 'ọṣẹ', 'ìfọsọ', 'Omo', '.']\n",
            " ['Ní', '2004', 'ó', 'di', 'aṣojú', 'fún', 'ọsẹ', 'ìwẹ̀', 'Lux', ',', 'ìbáṣe', 'ìgbọ̀wọ́', 'tọ́', 'fa', 'èrè', 'ínlá', 'wá', 'fun', '.']\n",
            " ['Ni', '1998', 'nígbà', 'tójẹ́', 'ọmọ', 'ọdún', '19', 'wọn', 'ṣe', 'àmúhàn', 'rẹ̀', 'sí', 'àwọn', 'olólùfẹ́', 'filmu', 'ni', 'Naijiria', 'pẹ̀lú', 'filmu', 'tó', 'ún', 'jẹ́', 'Most', 'Wanted', '.']\n",
            " ['Lẹ́yìn', 'rẹ̀', 'ó', 'tún', 'ṣe', 'àwọn', 'filmu', 'bíi', 'Last', 'Party', ',', 'Mark', 'of', 'the', 'Beast', 'àti', 'Ijele', '.']\n",
            " ['Ó', 'ti', 'kópa', 'nínúu', 'filmu', 'tó', 'tó', '80', 'ni', 'Nollywood', '.']\n",
            " ['Nnaji', 'ti', 'gba', 'ọ̀pọ̀lọpọ̀', 'ẹ̀bùn', 'fún', 'iṣẹ́', 'rẹ̀', 'ìkan', 'nínú', 'wọn', 'jẹ́', 'gẹ́gẹ́', 'bíi', 'òṣèré', 'obìnrin', 'tó', 'dára', 'jùlọ', 'fún', '2001', 'ní', 'City', 'People', 'Awards', ',', 'ó', 'sì', 'tún', 'gba', 'ẹ̀yẹ', 'gẹ́gẹ́', 'bíi', 'Òṣèré', 'Obìnrin', 'Tódárajùlọ', 'ní', '2005', 'nínú', 'àwọn', 'Ẹ̀bùn', 'Akadẹ́mì', 'Filmu', 'ilẹ̀', 'Áfríkà', '.']\n",
            " ['Ní', '2004', ',', 'ó', 'tọwọ́bọ̀wé', 'pẹ̀lú', 'ilé', 'ìṣẹ́', 'àwo', '-', 'orin', 'ilẹ̀', 'Ghana', ',', 'EKB', 'Records', 'láti', 'gbé', 'àwo', '-', 'orin', 'àkọ́kọ́', 'rẹ̀', 'jáde', 'tó', 'ún', 'jẹ́', 'One', 'Logologo', 'Line', ',', 'àdàlú', 'orin', 'R&B', ',', 'Hip-', 'Hop', 'àti', 'Urban', '.']\n",
            " ['Ní', '2008', 'ni', 'ó', 'ṣí', 'ilé', 'ìránsọ', 'rẹ̀', 'tó', 'ún', 'jẹ́', '\"', 'St', '.']\n",
            " ['Genevieve', '\"', ',', 'èyí', 'tó', 'ún', 'ṣọrẹ', 'ìdámẹ́ẹ̀wá', 'èrè', 'rẹ̀', '.']\n",
            " ['Ní', 'Nollywood,', 'Genevieve', 'Nnaji', 'jẹ́', 'ọ̀kan', 'nínú', 'àwọn', 'tí', 'owó', 'iṣẹ́', 'wọn', 'pọ̀jùlọ', '.']\n",
            " ['Ẹgbẹ́', 'Akọ́mọlédè', 'àti', 'àṣà', 'Yorùbá', 'jẹ́', 'àgbárí-', 'jọ-', 'pọ', 'Àwọn', 'olùkọ́', 'nílé', 'ìwé', 'alákọ̀ọ́bẹ̀rẹ̀', ',', 'girama', 'àti', 'ilé', 'ẹ̀kọ́', 'fásitì', 'ti', 'ìjọba', 'pẹ̀lú', 'aládàáni', 'jákè', 'jádò', 'ilẹ̀', 'Nàjíríà', '.']\n",
            " ['Ẹgbẹ́', 'yìí', 'ń', 'ṣojú', 'Yorùbá', 'níbi', 'ìgbé', 'lárugẹ', 'èdè', ',', 'àṣà', 'àti', 'ìdàgbà', 'sókè', 'ìṣèṣe', 'Yorùbá', '.']\n",
            " ['Alhaji', 'Lukman', 'Ẹ̀bùn', 'Olóyèdé', 'Ọláìyá', 'tí', 'gbogbo', 'ènìyàn', 'mọ̀', 'sí', 'Igwe', 'jẹ́', 'ọmọ', 'orílẹ̀', 'èdè', 'Nàìjíríà', 'àti', 'òṣèré', 'sinimá', 'àgbéléwò', '.']\n",
            " ['Wọ́n', 'bí', 'Ẹ̀bùn', 'Olóyèdé', 'ní', 'ilú', 'Kẹ́nta', ',', 'Òkè', '-', 'Èjìgbò', 'Abẹ́òkúta', '.']\n",
            " ['Ètò', 'ẹ̀kọ́', 'rẹ̀', ':', 'Ọláìyá', 'lọ', 'sí', 'ilé', 'ìwé', 'alákọ̀ọ́bọẹ̀rẹ̀', 'St.Judes', 'ní', 'ìlú', 'Abẹòkúta', 'ní', 'ìpínlẹ̀', 'Ògùn', ',', 'tí', 'ó', 'sì', 'tún', 'tè', 'síwájú', 'nínú', 'ẹ̀kọ́', 'rẹ̀', 'ní', 'ilé', 'ìwé', 'girama', '(', 'Premier)', 'ní', 'Abẹ́òkúta', '.']\n",
            " ['Lẹ́yìn', 'tí', 'ó', 'parí', 'èyí', 'ni', 'ó', 'lọ', 'kẹ́kọ̀ọ́', 'nípa', 'ìbára', 'ẹni', 'sọọ̀rọ̀', 'ní', 'ilé', 'ẹ̀kọ́', 'gbogbo', '-', 'nìṣe', 'tí', 'Moshood', 'Abíọ́lá', 'Òjéèrè', 'ìpínlẹ̀', 'Ògùn', '.']\n",
            " ['Iṣẹ́', 'rè', 'gẹ́gẹ́', 'bí', 'òṣèré', ':', 'Ọláìyá', 'dara', 'pọ̀', 'mọ́', 'ẹgbẹ́', 'òṣèré', 'Musibau', 'Shodimú', 'ní', 'àsìkò', 'ọdún', '1970s', 'tí', 'ó', 'wà', 'ní', 'Abẹ́òkúta', 'nígbà', 'náà', '.']\n",
            " ['Ojúewé', 'yìí', 'ní', 'ìpinu', 'ọ̀nà', 'ìṣiṣẹ́', 'kan', 'Wikipedia', 'nínú', '.']\n",
            " ['Ó', 'jẹ́', 'èso', 'ìfohùnṣọ̀kan', ',', 'bẹ́', 'ẹ̀', 'sì', 'ni', 'ó', 'jẹ́', 'gbígbàgbọ́', 'pé', 'gbogbo', 'àwọn', 'oníṣe', 'gbọ́dọ̀', 'tẹ̀lé', 'wọn', 'gbámúgbámú', '.']\n",
            " ['Ẹ', 'le', 'ṣàtúnṣe', 'àkóónú', 'ojúewé', 'náà', 'sùgbọ́n', 'ẹ', 'jọ̀wọ́', 'ọ', 'mọ́', 'ṣe', 'ìyípadà', 'ìpinu', 'ọ̀nà', 'ìṣiṣẹ́', 'kankan', 'láì', 'kọ́kọ́', 'filọ', 'àwọn', 'oníṣe', 'yìókù', '.']\n",
            " ['Ojú', 'ewé', 'yìí', 'ní', 'kúkurú', ':', 'Ìmúlò', 'àti', 'ìtọ́nisọ́nà', 'Wikipédíà', 'jẹ́', 'Ojú', 'ewé', 'tó', 'tọ́ka', 'sí', 'ìlànà', 'tí', 'a', 'gbọ́dọ̀', 'tẹ̀lé', 'ní', 'àwùjọ', 'Wikipédíà', '.']\n",
            " ['Ìmúlò', 'yìí', 'ṣe', 'àpèjúwe', 'bí', 'a', 'ṣe', 'lè', 'máa', 'mú', 'ìdàgbàsókè', 'bá', 'àwọn', 'Ìmúlò', 'àti', 'ìtọ́nisọ́nà', 'Wikipédíà', '.']\n",
            " ['Àwùjọ', 'Wikipédíà', 'ṣe', 'Ìmúlò', 'àti', 'ìtọ́nisọ́nà', 'yìí', 'lati', 'ṣe', 'àpèjúwe', 'ọ̀nàn', 'tó', 'dára', 'jùlọ', 'lati', 'ṣàgbékalẹ́', 'ọ̀rọ̀', ',', 'yanjú', 'ìjà', 'àti', 'lati', 'mú', 'ìtẹ̀síwájú', 'bá', 'ìlépa', 'wa', 'fún', 'ṣiṣẹda', 'ìmọ', 'ọfẹ', '.']\n",
            " ['Kò', 'pọn', 'dandan', 'lati', 'ka', 'Ìmúlò', 'àti', 'ìtọ́nisọ́nà', 'ojú', 'ewé', 'yìí', 'lati', 'bẹ̀ẹ̀rẹ̀', 'ṣíṣàtúnkọ', '.']\n",
            " ['Orígun', 'máàrún', 'Wikipédíà', 'ṣe', 'àlàyé', 'ránpẹ́', 'nípa', 'ìlànà', 'Wikipédíà', '.']\n",
            " ['Bí', 'ó', 'ti', 'lẹ̀', 'jẹ́', 'wípé', 'Wikipédíà', 'Kò', 'ní', 'gba', 'lílé', 'ati', 'sáré', 'òfin', ',', 'àwọn', 'ojú', 'ewé', 'Ìmúlò', 'àti', 'ìtọ́nisọ́nà', 'ti', 'ṣàgbékalẹ́', 'bí', 'ohun', 'gbogbo', 'ṣe', 'gbọ́dọ̀', 'máa', 'lọ', '.']\n",
            " ['Ìmúlò', 'ṣe', 'àlàyé', 'àwọn', 'ìlànà', 'tí', 'alàtúnkọ', 'gbọ́dọ̀', 'tẹ̀lé', 'ní', 'àwùjọ', 'Wikipédíà', '.']\n",
            " ['Bakan', 'náà', 'ni', 'ìtọ́nisọ́nà', 'ṣe', 'àlàyé', 'ọ̀nàn', 'tí', 'a', 'yàn', 'lááyò', 'lati', 'tẹ̀lé', 'ìlànà', 'yìí', '.']\n",
            " ['A', 'gbọ́dọ̀', 'máa', 'lo', 'ìtọ́nisọ́nà', 'pẹ̀lú', 'láákáyè', '.']\n",
            " ['Àjọ', 'kòsí', 'fún', 'èrè', 'Wikimedia', 'Foundation', 'ni', 'ó', 'n', 'se', 'alàkóso', 'Wikipédíà', 'pẹ̀lú', 'àwọn', 'òfin', 'kan', '(', 'wo', 'ibí', 'fún', 'àkójọ', 'Ìmúlò', ')', '.']\n",
            " ['Tún', 'wo', 'Ipa', 'Jimmy', 'Wales', 'ṣùgbọn', ',', 'Wikipédíà', 'ṣàkóso', 'ara', 'ẹ̀', 'nipase', 'oníwé', 'àwùjọ', '.']\n",
            " ['Ìmúlò', 'jẹ́', 'ohun', 'tí', 'gbogbo', 'alàtúnkọ', 'gbà', '.']\n",
            " ['Osì', 'tún', 'se', 'àpèjúwe', 'ìlànà', 'tí', 'a', 'gbọ́dọ̀', 'tẹ̀lé', 'ní', 'àwùjọ', '.']\n",
            " ['Gbogbo', 'ojú', 'ewé', 'ìmúlò', 'wà', 'ní', 'Wikipédíà', ':']\n",
            " ['Gbogbo', 'ìmúlò', 'àti', 'ìtọ́nisọ́nà', 'àti', '.']\n",
            " ['Fún', 'kúkurú', 'ojúlówó', 'àwọn', 'ìmúlò', ',', 'wo', 'Wikipédíà', ':']\n",
            " ['Àwọn', 'ìmúlò', '.']\n",
            " ['Wikipedia', 'Yorùbá', 'únlo', 'àwọn', 'ìpinu', 'ọ̀nà', 'ìṣiṣẹ́', 'tó', 'wà', 'fún', 'Wikipedia', 'èdè', 'Gẹ̀ẹ́sì', '.']\n",
            " ['Tí', 'ẹ', 'bá', 'fẹ́', 'ẹ', 'lè', 'lọ', 'sí', 'ojúewé', 'ọ̀rọ̀', 'rẹ̀', 'láti', 'fọ̀rọ̀wérọ̀', 'nípa', 'wọn', 'tàbí', 'dámọ̀ràn', 'ìpínu', 'ọ̀nà', 'ìṣiṣẹ́', 'míràn', '.']\n",
            " ['Ṣíṣàtúnṣe', 'ojúewé', 'yìí', 'látọwọ́', 'àwọn', 'oníṣe', 'tuntun', 'tàbí', 'àwọn', 'oníṣe', 'aláìtíìforúkọsílẹ̀', 'jẹ́', 'tí', 'tìpa', 'lọ́wọ́lọ́wọ́', '.']\n",
            " ['Ojúewé', 'yìí', 'lọ́wọ́lọ́wọ́', 'jẹ́', 'dídá', 'àbò', 'bò', 'díẹ̀', 'nítoríẹ̀', 'àwọn', 'oníṣe', 'aforúkọsílẹ̀', 'tí', 'wọ́n', 'ti', 'fẹsẹ̀múlẹ̀', 'nìkan', 'ni', 'wọ́n', 'le', 'ṣàtúnṣe', 'rẹ̀', '.']\n",
            " ['Kílódé', 'tí', 'ojúewé', 'ṣe', 'ní', 'àbò', '?']\n",
            " ['Bó', 'tilẹ', 'jẹ́', 'pé', 'ọ̀pọ̀', 'àwọn', 'àyọkà', 'ni', 'wọ́n', 'le', 'jẹ́', 'títúnṣe', 'látọwọ́', 'olúkúlùkù', ',', 'àbò', 'díẹ̀', 'pọndandan', 'ní', 'gbà', 'míi', 'láti', 'dínà', 'ìbàjẹ́', 'sí', 'àwọn', 'ojúewé', 'tó', 'gbajúmọ̀', '.']\n",
            " ['Ìdí', 'fún', 'àbò', 'wà', 'nínú', 'àkọọ́lẹ̀', 'àbo', '.']\n",
            " ['Tí', 'kò', 'bá', 'sí', 'àkọsílẹ̀', 'abáramu', 'nínú', 'àkọọ́lẹ̀', 'àbò', ',', 'ojúewé', 'náà', 'le', 'ti', 'jẹ́', 'yíyí', 'nípò', 'dà', 'lẹ́yìn', 'ìṣe', 'àbò', 'si', '.']\n",
            " ['Kíni', 'mo', 'le', 'ṣe', '?']\n",
            " ['Tí', 'ẹ', 'bá', 'ní', 'àkópamọ́', 'oníṣe', 'ẹ', 'kọ́kọ́', 'wọlẹ́', '.']\n",
            " ['Tí', 'ẹ', 'kò', 'bá', 'ní', 'àkópamọ́', ',', 'ẹ', 'le', 'dá', 'ìkan', ';', 'lẹ́yìn', 'ọjọ́', '4', 'àti', 'àtúnṣe', '10', ',', 'ẹ', 'ó', 'le', 'ṣàtúnṣe', 'àwọn', 'ojúewé', 'àbò', 'díẹ̀', '.']\n",
            " ['Ẹ', 'sọ̀rọ̀', 'nípa', 'ojúewé', 'yìí', 'pẹ̀lú', 'àwọn', 'ẹlòmíràn', '.']\n",
            " ['Ẹ', 'tọrọ', 'ìjáwọ́', 'àbò', 'ojúewé', 'náà', '.']\n",
            " ['Ẹ', 'ka', 'bí', 'ẹ', 'ṣele', 'bẹ̀rẹ̀', 'síní', 'ṣàtúnṣe', 'Wikipedia', '.']\n",
            " ['Tí', 'ẹ', 'bá', 'ṣàkíyèsí', 'àsìṣe', 'tàbí', 'ẹ', 'ní', 'àbá', 'fún', 'àtúnṣe', ',', 'ẹ', 'le', 'tọrọ', 'àtúnṣe', ',', 'nípa', 'títẹ', 'klik', 'sí', 'àjápọ̀', 'ìsàlẹ̀', ',', 'kí', 'ẹ', 'sì', 'tẹ̀lẹ́', 'àwọn', 'ìlànà', 'ibẹ̀', '.']\n",
            " ['Alámùójútó', 'kan', 'yíò', 'ṣe', 'àtúnṣe', 'náà', 'fun', 'yín', '.']\n",
            " ['Ẹ', 'jọ̀wọ́', 'ẹ', 'kọ́kọ́', 'wọ', 'ojúewé', 'ìfọ̀rọ̀wérọ̀', 'àyọkà', 'náà', ',', 'bóyá', 'ọ̀rọ̀', 'ùnlọ', 'nípa', 'rẹ̀', '.']\n",
            " ['Àdírẹ́ẹ̀sì', 'e', '-', 'mail', 'yín', 'kò', 'ṣe', 'dandan', ',', 'ṣùgbọ́n', 'yíò', 'jẹ́', 'lílò', 'fún', 'ìtúntò', 'ọ̀rọ̀ìpamọ́', ',', 'tí', 'ẹ', 'bá', 'gbàgbé', 'ọ̀rọ̀ìpamọ́', 'yín', '.']\n",
            " ['Ẹ', 'tún', 'le', 'yàn', 'láti', 'jẹ́', 'kí', 'àwọn', 'míràn', 'ó', 'bá', 'a', 'yín', 'pàdé', 'pẹ̀lú', 'e', '-', 'mail', 'láti', 'inú', 'àjápọ̀', 'lórí', 'ojúewé', 'oníṣe', 'tàbí', 'ọ̀rọ̀', 'yín', '.']\n",
            " ['Àdírẹ́ẹ̀sì', 'e', '-', 'mail', 'yín', 'kò', 'ní', 'hàn', 'síta', 'nígbà', 'tí', 'àwọn', 'oníṣe', 'míràn', 'bá', 'a', 'yín', 'pàdé', '.']\n",
            " ['Kò', 'sì', 'áwọ́n', 'iyipada', 'ni', 'akókò', 'yì', 'ti', 'o', 'ba', 'àwon', 'ìlànà', 'yí', 'mu', '.']\n",
            " ['Lọ́wọ́lọ́wọ́', 'kò', 'sí', 'ìkọ̀', 'nínú', 'ojúewé', 'yìí', '.']\n",
            " ['Ẹ', 'le', 'wá', 'àkọlé', 'ojúewé', 'yìí', 'nínú', 'àwọn', 'ojúewé', 'mìíràn', ',', 'tàbí', 'wá', 'àwọn', 'àkọọ́lẹ̀', 'tó', 'bámu', ',', 'sùgbọ́n', 'ẹ', 'kò', 'ní', 'àṣẹ', 'láti', \"ṣ'\", 'ẹ̀dá', 'ojúewé', 'yìí', '.']\n",
            " ['Robert', 'Lavinsky,', 'PhD', ',', 'ti', 'ṣọrẹ', 'ibùdó', 'dátà', 'gbogbo', 'àwọ', 'àwòrán', 'rẹ̀', 'ní', 'mindat.org', '(', 'ó', 'tó', 'bíi', '29', ',', '000', ')', 'àti', 'gbogbo', 'àwọn', 'àwòrán', 'láti', 'ibi', 'ojúewé', 'ìtakùn', 'rẹ̀', 'irocks.com', 'fún', 'Wikimedia', 'Commons.']\n",
            " ['Bákanáà', 'ó', 'tún', 'ti', 'ṣe', 'ìfilọ̀', 'iye', 'àwórán', 'bíi', '20', ',', '000', 'láti', 'inú', 'ìkápamọ́', 'rẹ̀', 'fún', 'lílò', 'bóbá', 'ṣe', 'yẹ', '.']\n",
            " ['À', 'únfẹ́', 'ìrànlọ́wọ́', 'láti', 'ṣe', 'ìyípadà', 'ìjúwe', 'gbogbo', 'àwọn', 'àwòrán', 'náà', ',', 'ṣíṣèyẹ̀wò', 'wọn', 'ní', 'irocks.com', 'bóyá', 'àwòrán', 'kan', 'kò', 'sí', ',', 'àti', 'láti', 'rù', 'wọ́n', 'sókè', 'sí', 'Commons.']\n",
            " ['Ẹ', 'le', 'kà', 'nípa', 'bí', 'ẹ', 'ṣe', 'le', 'ràn', 'wá', 'lọ́wọ́', 'níbí', '.']\n",
            " ['Àyọkà', 'yìí', 'tàbí', 'apá', 'rẹ̀', 'únfẹ́', 'àtúnṣe', 'sí', '.']\n",
            " ['Ẹ', 'le', 'fẹ̀', 'jù', 'báyìí', 'lọ', 'tàbí', 'kí', 'ẹ', 'ṣàtúnṣe', 'rẹ̀', 'lọ́nà', 'tí', 'yíò', 'mu', 'kúnrẹ́rẹ́', '.']\n",
            " ['Ẹ', 'ran', 'Wikipedia', 'lọ́wọ́', 'láti', 'fẹ̀ẹ́', 'jù', 'báyìí', 'lọ', '.']\n",
            " [\"Lát'\", 'ọwọ́', 'Wikipedia', ',', 'ìwé', 'ìmọ̀', 'ọ̀fẹ́', '.']\n",
            " ['Ẹ', 'wo', 'Àwọn', 'Ọ̀rọ̀', 'Àdéhùn', 'Ìlò', 'fún', 'ẹ̀kúnrẹ́rẹ́', '.']\n",
            " ['Ní', 'ayé', 'àtijọ́', 'àwọn', 'onímọ́', 'ìṣirò', 'mọ', 'nọ́mbà', 'tóṣòro', 'gẹ́gẹ́', 'bíi', 'nọ́mbà', 'tí', 'kòsí', '.']\n",
            " ['A', 'lè', 'sọ', 'pé', 'àwón', 'nọ́mbà', 'gidi', 'je', 'nọ́mbà', 'tósòro', 'pelu', 'apá', 'tíkòsi´', 'tó', 'jé', 'òdo', ';', 'eyun', 'pé', 'nọ́mbà', 'gidi', 'a', 'jẹ́', 'bakanna', 'mọ́', 'nọ́mbà', 'tósòro', 'a+0i', '.']\n",
            " ['Fún', 'àpẹrẹ', ',', '3', '+', '2i', 'jé', 'nọ́mbà', 'tósòro', ',', 'pẹ̀lú', 'apá', 'gidi', 'to', 'jẹ', '3', 'ati', 'apá', 'tíkòsi´', 'to', 'jẹ', '2', '.']\n",
            " ['Àwon', 'nọ́mbà', 'tósòro', 'se', 'ròpọ̀', ',', 'yọkúrò', ',', 'sọdipúpọ̀', 'tàbi', 'sèpínpiń', 'gẹ́gẹ́', 'bi', 'a', 'ti', 'n', 'se', 'fun', 'àwon', 'nọ́mbà', 'gidi', ',', 'be', 'ni', 'wón', 'sì', 'ní', 'ìdámọ̀', 'tó', 'lẹ́wà', 'mìíràn', '.']\n",
            " ['Fún', 'àpẹrẹ', ',', 'nọ́mbà', 'gidi', 'nìkan', 'kò', 'ní', 'ojúùtú', 'fún', 'ìdọ́gba', 'aljebra', 'alápọ̀ọ́nlépúpọ̀', '(', 'polynomial', ')', 'pẹ̀lú', 'nọ́mbà', 'àfise', 'gidi', '(', 'coefficient', ')', ',', 'sùgbọ̀n', 'àwọn', 'nọ́mbà', 'tósòro', 'ní', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: dev-3\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ọlọ ́ run ▁sì ▁wí ▁pé ▁ , ▁“ ▁Jẹ ́ ▁kí ▁ìmọ ́ lẹ ̀ ▁kí ▁ó ▁wà ▁ , ▁” ▁ìmọ ́ lẹ ̀ ▁sì ▁wà ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 5422 291 1788 860 4441 694 261 262 336 30474 291 855 11432 291 1048 294 855 484 1041 261 262 1266 11432 291 1048 294 860 1041 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 -100 5 16 14 13 -100 13 16 -100 4 8 -100 -100 -100 4 11 16 13 -100 13 8 -100 -100 -100 5 16 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: dev-4\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ọlọ ́ run ▁rí ▁i ▁pé ▁ìmọ ́ lẹ ̀ ▁náà ▁dára ▁ , ▁ó ▁sì ▁ya ▁ìmọ ́ lẹ ̀ ▁náà ▁sọ ́ tọ ̀ ▁kúrò ▁lára ▁òkùnkùn ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 5422 291 1788 1890 391 694 11432 291 1048 294 871 12130 261 262 484 860 268 11432 291 1048 294 871 618 291 1920 294 4617 5475 26506 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 -100 16 11 14 8 -100 -100 -100 1 1 13 -100 11 5 16 8 -100 -100 -100 1 3 -100 -100 -100 2 2 8 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:*** Example ***\n",
            "INFO:Afri_NER_Log:guid: dev-5\n",
            "INFO:Afri_NER_Log:tokens: <s> ▁Ọlọ ́ run ▁sì ▁pe ▁ìmọ ́ lẹ ̀ ▁náà ▁ní ▁“ ▁Ọ ̀ sán ▁” ▁àti ▁òkùnkùn ▁ní ▁“ ▁Ò ru ▁ . ▁” ▁À sá lẹ ́ ▁àti ▁òwúrọ ̀ ▁sì ▁jẹ ́ ▁ọjọ ́ ▁kì n - ín - ní ▁ . </s>\n",
            "INFO:Afri_NER_Log:input_ids: 0 5422 291 1788 860 481 11432 291 1048 294 871 429 336 547 294 18173 1266 1031 26506 429 336 7081 794 261 263 1266 2846 28164 1048 291 1031 43222 294 860 591 291 1470 291 7958 278 271 15795 271 6139 261 263 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:Afri_NER_Log:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:Afri_NER_Log:label_ids: -100 8 -100 -100 5 16 8 -100 -100 -100 1 4 13 8 -100 -100 13 5 8 4 13 8 -100 13 -100 13 8 -100 -100 -100 5 3 -100 5 4 -100 8 -100 1 -100 -100 -100 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:Afri_NER_Log:Saving features into cached file lacuna_pos_ner/data/yor/cached_dev_afriberta_large_200\n",
            "INFO:Afri_NER_Log:***** Running evaluation  *****\n",
            "INFO:Afri_NER_Log:  Num examples = 318\n",
            "INFO:Afri_NER_Log:  Batch size = 8\n",
            "Evaluating: 100%|██████████| 40/40 [00:07<00:00,  5.71it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "INFO:Afri_NER_Log:***** Eval results  *****\n",
            "INFO:Afri_NER_Log:  f1 = 0.6099642169006331\n",
            "INFO:Afri_NER_Log:  loss = 1.407165239751339\n",
            "INFO:Afri_NER_Log:  precision = 0.6164116828929068\n",
            "INFO:Afri_NER_Log:  recall = 0.6036502315445382\n",
            "INFO:Afri_NER_Log:{'loss': 1.407165239751339, 'precision': 0.6164116828929068, 'recall': 0.6036502315445382, 'f1': 0.6099642169006331}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuIiR6pS9B3a"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH-nduTs9B3a"
      },
      "source": [
        "XLM-Roberta model training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tihHhn019B3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78863c84-4e01-49b7-c79a-4216d4587bf6"
      },
      "source": [
        "args, _ = get_args()\n",
        "args.data_dir = \"data/swahili/\" # to-change: supply data directory\n",
        "args.output_dir = \"swahili_xlmr\" # to-change: supply output directory\n",
        "args.model_type = \"bert\"\n",
        "args.model_name_or_path = \"xlm-roberta-base\"\n",
        "args.max_seq_length = 164\n",
        "args.num_train_epochs = 10\n",
        "args.per_gpu_train_batch_size = 32\n",
        "args.save_steps = 10000\n",
        "args.seed = 1\n",
        "args.do_train\n",
        "args.do_eval\n",
        "args.do_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kytn0etJ9B3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b049657f99064e9b8d9d0df27f538713",
            "f90351af3fa84f0ab44b7792387361eb",
            "753cfd3762be445e8653c0aa1d5d1792",
            "25e3887180394359a8f2a2fd10ac990a",
            "4922ef937ef34f1f8e2da04be3d77c29",
            "3564cabf4b66461ca8d8f559445d426a",
            "b48c52bb8cbf4cc08364e01bb05c5efa",
            "fe861820e52a4538b83f9f38db4177b6",
            "d7a8e0234cc8492e922b3bf9aab1f447",
            "7959dc83065d4411895d3e064236b759",
            "ddd76ffcc4dc4dd2b1522d252a7b3a11",
            "b6f7ba3f52c84d2180fd23e233023c42",
            "fde825023ee54c0d9ce43f7fcd436428",
            "0f14d709e8a54833ac0bd48ca82b2e62",
            "5f39632b40d949e086a24b670cb1105b",
            "a027b06b097d4586a80c74aaf676be70",
            "9bd4f3fe0a0044c8a0a76dd5f86912d0",
            "0e82fe83c0b54b1ab68d8c918968d7da",
            "e4ac7390bdfd45f78e3b89e2a4a633fa",
            "d2aaddd6b17c4ebda55e0bc3834f18e1",
            "2b5f201595e04682a14740d3bbec02e3",
            "3cf7ab0c964d4ac7a728b0edf73dfb91",
            "5519db681a9243b583d61e1fc1a2c255",
            "d13a34771c6842e9ab73e3a68591e7c5",
            "f46fc9e13906498187237c890414ed1f",
            "928d37a2380e4a71b77cd470ec30312c",
            "103cc1365c2946a8870d85e89037fad1",
            "201c521be2aa452a9f1e169ef7a6b670",
            "f6e4d88226cf4c4eb771c14793ec8741",
            "3d5488a78ef44266b481b9634b824048",
            "935ac2b4a48148adbd7402646bf39f07",
            "d5a8ea041ad344d7a97af0487dc75485",
            "875f67c3949545a68422ed576898e530",
            "063b05161ee84d54880785e3e39d6402",
            "ad804445d69d41babaf91fc752b68f2b",
            "1750dcfaafaa4ea78b84c79717e7001f",
            "255870e8800649839b527c81a403226d",
            "c095eb2d71c44987b422711f972e1f2d",
            "f29ae3f2de0e4b418758fbb213f92525",
            "ec74d6611b9d462493bd56193860f912",
            "bb9b738e61f043e4a0ab99b9307a7da8",
            "47d293a256ec4005b75909db4d0d3fb9",
            "7bb74d8e43eb47378cb63124df9ac567",
            "c8f899e07e2a452388b68d73c845586d"
          ]
        },
        "outputId": "01a1b3a8-ce92-45ce-c077-5bbdb8ac5709"
      },
      "source": [
        "# confirm your cuda devices before setting this command\n",
        "!export CUDA_VISIBLE_DEVICES=1,2,3\n",
        "start_training(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140463746716880 on /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6.lock\n",
            "DEBUG:filelock:Lock 140463746716880 acquired on /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b049657f99064e9b8d9d0df27f538713",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140463746716880 on /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6.lock\n",
            "DEBUG:filelock:Lock 140463746716880 released on /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/tokenizer_config.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/xlm-roberta-base HTTP/1.1\" 200 723\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/sentencepiece.bpe.model HTTP/1.1\" 200 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140470060857744 on /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8.lock\n",
            "DEBUG:filelock:Lock 140470060857744 acquired on /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /xlm-roberta-base/resolve/main/sentencepiece.bpe.model HTTP/1.1\" 200 5069051\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6f7ba3f52c84d2180fd23e233023c42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140470060857744 on /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8.lock\n",
            "DEBUG:filelock:Lock 140470060857744 released on /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140470060857744 on /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7.lock\n",
            "DEBUG:filelock:Lock 140470060857744 acquired on /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /xlm-roberta-base/resolve/main/tokenizer.json HTTP/1.1\" 200 9096718\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5519db681a9243b583d61e1fc1a2c255",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140470060857744 on /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7.lock\n",
            "DEBUG:filelock:Lock 140470060857744 released on /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/tokenizer_config.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140470001545360 on /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2.lock\n",
            "DEBUG:filelock:Lock 140470001545360 acquired on /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /xlm-roberta-base/9d83baaafea92d36de26002c8135a427d55ee6fdc4faaa6e400be4c47724a07e HTTP/1.1\" 200 1115590446\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "063b05161ee84d54880785e3e39d6402",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140470001545360 on /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2.lock\n",
            "DEBUG:filelock:Lock 140470001545360 released on /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2.lock\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:Afri_NER_Log:Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='data/swahili/', device=device(type='cuda'), do_eval=False, do_finetune=False, do_lower_case=False, do_predict=False, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, gradient_accumulation_steps=1, input_dir=None, labels='', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=164, max_steps=-1, model_name_or_path='xlm-roberta-base', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='swahili_xlmr', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=32, save_steps=10000, seed=1, server_ip='', server_port='', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
            "INFO:Afri_NER_Log:{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SMoXFlH9B3a"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTnDuXvH9B3b"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}